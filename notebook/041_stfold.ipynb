{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df):\n",
    "    \n",
    "    ###########################\n",
    "    # Functions of preprocess\n",
    "    ###########################\n",
    "    def get_multi_cat_cols(train_df):\n",
    "        tmp = train_df.iloc[:1000]\n",
    "        multi_cols = []\n",
    "        for c in train_df.columns:\n",
    "            sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "            if sep_num > 10:\n",
    "                multi_cols.append(c)\n",
    "        return multi_cols\n",
    "\n",
    "    def add_rank_feature(df):\n",
    "        rank_prefix_list = [\n",
    "            \"AssessBenefits\",\n",
    "            \"AssessJob\",\n",
    "            \"JobContactPriorities\",\n",
    "            \"JobEmailPriorities\",\n",
    "            \"AdsPriorities\",\n",
    "        ]\n",
    "        for prefix in tqdm(rank_prefix_list):\n",
    "            rank_cols = [c for c in df.columns if prefix in c]\n",
    "            col_pairs = itertools.combinations(rank_cols, 2)\n",
    "            for col_a, col_b in col_pairs:\n",
    "                df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "        return df\n",
    "\n",
    "    def get_basic_importance_cols(use_num=50):\n",
    "        # basicなモデルのimportanceを読み込み\n",
    "        importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "        imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "        return imp_feats\n",
    "\n",
    "    def make_agg_feature(train_df, test_df):\n",
    "        imp_feats = get_basic_importance_cols(use_num=50)\n",
    "        imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "        imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "        print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "        #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "        all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "        for cat_col in tqdm(imp_cat_cols):\n",
    "            for nume_col in imp_nume_cols:\n",
    "                # one-hotは同じカテゴリの場合がある\n",
    "                if cat_col == nume_col:\n",
    "                    continue\n",
    "                all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "                all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "                all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "                all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "                all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "                all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "        train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "        test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        del all_df\n",
    "        gc.collect()\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=True)\n",
    "    def target_encoding2(train_df, test_df):\n",
    "        te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "        for c in tqdm(te_cols):\n",
    "            new_col = \"te_\" + c\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=True)\n",
    "    def multiple_target_encoding2(train_df, test_df):\n",
    "         # multiple target encoding\n",
    "        multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "        imp_feats = get_basic_importance_cols(use_num=30)\n",
    "        multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "        combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "        for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "            new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "            test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "            del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "            gc.collect()\n",
    "        return train_df, test_df   \n",
    "    \n",
    "    ################################\n",
    "    # Columns infomation\n",
    "    ################################\n",
    "    original_cols = train_df.columns.tolist()\n",
    "    multi_cat_cols = get_multi_cat_cols(train_df)\n",
    "\n",
    "    nume_cols = [\n",
    "        c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "        if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "    ]\n",
    "\n",
    "    cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]\n",
    "\n",
    "    non_basic_nume_cols = []\n",
    "    non_basic_cat_cols = []\n",
    "    \n",
    "    train_df[\"target_bin\"] = \\\n",
    "        train_df.Salary.map(lambda x: x if x < 250000 else 250000).round(-4)\n",
    "\n",
    "    ################################\n",
    "    #  Make feature\n",
    "    ################################    \n",
    "    \n",
    "    # rank feature\n",
    "    train_df = add_rank_feature(train_df)\n",
    "    test_df = add_rank_feature(test_df)\n",
    "\n",
    "    # multi -category encoding \n",
    "    for c in tqdm(multi_cat_cols):\n",
    "        binarizer = MultiLabelBinarizer()\n",
    "        train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "        test_arr = binarizer.transform(test_multi_srs)\n",
    "        feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "        train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "        test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "        all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "        train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "        test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "        # ohe_featureはcategoryとnumerical両方として扱う\n",
    "        nume_cols += feat_cols\n",
    "        cat_cols += feat_cols\n",
    "        # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "        # SVD\n",
    "        svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "        all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "        train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "        test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # simple category encoding\n",
    "    for c in cat_cols:\n",
    "        train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "        test_df[c] = uniques.get_indexer(test_df[c])\n",
    "    \n",
    "    # reduce memory\n",
    "    # numerical cols\n",
    "    for c in nume_cols:\n",
    "        if train_df[c].nunique() > 1000:\n",
    "            train_df[c] = train_df[c].astype(np.float32)\n",
    "            test_df[c] = test_df[c].astype(np.float32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.float16)\n",
    "            test_df[c] = test_df[c].astype(np.float16)\n",
    "    # category cols\n",
    "    for c in cat_cols:\n",
    "        if train_df[c].max() > 32767:\n",
    "            train_df[c] = train_df[c].astype(np.int32)\n",
    "            test_df[c] = test_df[c].astype(np.int32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.int16)\n",
    "            test_df[c] = test_df[c].astype(np.int16)\n",
    "    \n",
    "    # change columns name\n",
    "    train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "    test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "   \n",
    "    # aggregate feature\n",
    "    train_df, test_df = make_agg_feature(train_df, test_df)\n",
    "\n",
    "    # make train/validation index list for target encoding\n",
    "    folds = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"target_bin\"])]\n",
    "    \n",
    "    # target encoding\n",
    "    train_df, test_df = target_encoding2(train_df, test_df)\n",
    "\n",
    "    # multiple category target encoding \n",
    "    train_df, test_df = multiple_target_encoding2(train_df, test_df)\n",
    "    \n",
    "    # make use columns list\n",
    "    use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\", \"target_bin\"]]\n",
    "    print(len(use_cols))\n",
    "    \n",
    "    return train_df, test_df, use_cols, fold_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, use_cols, fold_idx_list):\n",
    "\n",
    "    lgb_params = {\n",
    "                'objective': 'poisson',\n",
    "                \"metric\": \"rmse\",\n",
    "                \"verbosity\": -1,\n",
    "                \"boosting\": \"gbdt\",\n",
    "                'learning_rate': 0.01,\n",
    "                'num_leaves': 64,\n",
    "                'min_data_in_leaf': 80, \n",
    "                'max_depth': 4,\n",
    "                \"bagging_freq\": 5,\n",
    "                \"bagging_fraction\": 0.8,\n",
    "                \"lambda_l1\": 0.5,\n",
    "                \"lambda_l2\": 0.5,\n",
    "                \"feature_fraction\": 0.1,\n",
    "                \"seed\": 2020,\n",
    "                \"num_threads\": -1,\n",
    "                \"max_bins\": 30\n",
    "    }\n",
    "    def feature_selection(train_df, use_cols, n_features=1000):\n",
    "        df = train_df.sample(30000, random_state=2020)\n",
    "        train_dataset = lgb.Dataset(\n",
    "            df.loc[:, use_cols],\n",
    "            label = df.loc[:, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    2000,\n",
    "                    valid_sets = [train_dataset],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds = None,\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "        return select_features\n",
    "    \n",
    "    importances = pd.DataFrame()\n",
    "    oof_preds = np.zeros(len(train_df))\n",
    "    models = []\n",
    "\n",
    "    # use_cols = feature_selection(train_df, use_cols, n_features=1000)\n",
    "\n",
    "    for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "        print(f\"Fold {fold_i+1}\")\n",
    "        train_dataset = lgb.Dataset(\n",
    "            train_df.loc[trn_idx, use_cols],\n",
    "            label = train_df.loc[trn_idx, \"Salary\"]\n",
    "        )\n",
    "        valid_dataset = lgb.Dataset(\n",
    "            train_df.loc[val_idx, use_cols],\n",
    "            label = train_df.loc[val_idx, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    30000,\n",
    "                    valid_sets = [train_dataset, valid_dataset],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 500,\n",
    "                    #feval = eval_f1,\n",
    "                    #callbacks = [log_callback],\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])\n",
    "        models.append(model)\n",
    "\n",
    "    oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "    print(f\"OOF Score: {oof_score}\")\n",
    "    \n",
    "    display(\n",
    "        importances.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:50]\n",
    "    )\n",
    "\n",
    "    return train_df, test_df, models, oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, models, use_cols, oof_score):\n",
    "    test_pred = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        test_pred += model.predict(test_df[use_cols]) / len(models)\n",
    "    sub_df = pd.read_csv(\"../input/submit.csv\")\n",
    "    sub_df[\"Salary\"] = test_pred\n",
    "    sub_df.to_csv(f\"../predict/{model_title}_{oof_score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = \"041_stfold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb28dfb0e124fdca72beb31d0d76dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3fcfbbe29b42658c24f4d01fd5dd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984ca1d9a1014e31886d6e5b3a01f5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b65e1349e494fd1bc8a9a7125964199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f8e7df26e14a15897d74ce935616ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=229.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08227cfc7ce64835a85475a36da251f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2659\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, use_cols, fold_idx_list = preprocess(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22750.4\tvalid_1's rmse: 22936.3\n",
      "[1000]\ttraining's rmse: 20923.1\tvalid_1's rmse: 21312.4\n",
      "[1500]\ttraining's rmse: 20149.4\tvalid_1's rmse: 20827.8\n",
      "[2000]\ttraining's rmse: 19660.5\tvalid_1's rmse: 20609.2\n",
      "[2500]\ttraining's rmse: 19281.9\tvalid_1's rmse: 20466.7\n",
      "[3000]\ttraining's rmse: 18972.6\tvalid_1's rmse: 20371.5\n",
      "[3500]\ttraining's rmse: 18693.8\tvalid_1's rmse: 20292.9\n",
      "[4000]\ttraining's rmse: 18444.2\tvalid_1's rmse: 20228.1\n",
      "[4500]\ttraining's rmse: 18205.2\tvalid_1's rmse: 20176.3\n",
      "[5000]\ttraining's rmse: 17993\tvalid_1's rmse: 20134.9\n",
      "[5500]\ttraining's rmse: 17793.5\tvalid_1's rmse: 20101\n",
      "[6000]\ttraining's rmse: 17610.7\tvalid_1's rmse: 20077.3\n",
      "[6500]\ttraining's rmse: 17427.9\tvalid_1's rmse: 20057.9\n",
      "[7000]\ttraining's rmse: 17251.5\tvalid_1's rmse: 20041.2\n",
      "[7500]\ttraining's rmse: 17081.2\tvalid_1's rmse: 20028.4\n",
      "[8000]\ttraining's rmse: 16920\tvalid_1's rmse: 20017.8\n",
      "[8500]\ttraining's rmse: 16748.3\tvalid_1's rmse: 20005.5\n",
      "[9000]\ttraining's rmse: 16592.2\tvalid_1's rmse: 19998.3\n",
      "[9500]\ttraining's rmse: 16433.2\tvalid_1's rmse: 19987.4\n",
      "[10000]\ttraining's rmse: 16279.1\tvalid_1's rmse: 19983.9\n",
      "[10500]\ttraining's rmse: 16126.2\tvalid_1's rmse: 19981.2\n",
      "[11000]\ttraining's rmse: 15987\tvalid_1's rmse: 19977.9\n",
      "Early stopping, best iteration is:\n",
      "[10816]\ttraining's rmse: 16038.5\tvalid_1's rmse: 19975.8\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22584.9\tvalid_1's rmse: 23617.8\n",
      "[1000]\ttraining's rmse: 20742.5\tvalid_1's rmse: 22158\n",
      "[1500]\ttraining's rmse: 19966.7\tvalid_1's rmse: 21677.1\n",
      "[2000]\ttraining's rmse: 19491.3\tvalid_1's rmse: 21449.7\n",
      "[2500]\ttraining's rmse: 19126.9\tvalid_1's rmse: 21308.2\n",
      "[3000]\ttraining's rmse: 18815.8\tvalid_1's rmse: 21200.4\n",
      "[3500]\ttraining's rmse: 18546.2\tvalid_1's rmse: 21124.1\n",
      "[4000]\ttraining's rmse: 18299.6\tvalid_1's rmse: 21062.3\n",
      "[4500]\ttraining's rmse: 18067.9\tvalid_1's rmse: 21006.5\n",
      "[5000]\ttraining's rmse: 17863.8\tvalid_1's rmse: 20965.7\n",
      "[5500]\ttraining's rmse: 17667.3\tvalid_1's rmse: 20928.2\n",
      "[6000]\ttraining's rmse: 17481.6\tvalid_1's rmse: 20901.6\n",
      "[6500]\ttraining's rmse: 17305.8\tvalid_1's rmse: 20871.9\n",
      "[7000]\ttraining's rmse: 17135.2\tvalid_1's rmse: 20851.5\n",
      "[7500]\ttraining's rmse: 16972.6\tvalid_1's rmse: 20828.7\n",
      "[8000]\ttraining's rmse: 16806.6\tvalid_1's rmse: 20805.3\n",
      "[8500]\ttraining's rmse: 16638.9\tvalid_1's rmse: 20788.7\n",
      "[9000]\ttraining's rmse: 16487.8\tvalid_1's rmse: 20777.8\n",
      "[9500]\ttraining's rmse: 16341.1\tvalid_1's rmse: 20769.5\n",
      "[10000]\ttraining's rmse: 16187.5\tvalid_1's rmse: 20759.7\n",
      "[10500]\ttraining's rmse: 16037.3\tvalid_1's rmse: 20752.7\n",
      "[11000]\ttraining's rmse: 15889.5\tvalid_1's rmse: 20744.7\n",
      "[11500]\ttraining's rmse: 15747.2\tvalid_1's rmse: 20733\n",
      "[12000]\ttraining's rmse: 15609.6\tvalid_1's rmse: 20724.5\n",
      "[12500]\ttraining's rmse: 15470.6\tvalid_1's rmse: 20718.8\n",
      "[13000]\ttraining's rmse: 15338.8\tvalid_1's rmse: 20716.9\n",
      "[13500]\ttraining's rmse: 15204.3\tvalid_1's rmse: 20707\n",
      "[14000]\ttraining's rmse: 15072.6\tvalid_1's rmse: 20701.9\n",
      "[14500]\ttraining's rmse: 14935.1\tvalid_1's rmse: 20698.2\n",
      "[15000]\ttraining's rmse: 14801.8\tvalid_1's rmse: 20696.4\n",
      "[15500]\ttraining's rmse: 14673.3\tvalid_1's rmse: 20693.9\n",
      "[16000]\ttraining's rmse: 14548.6\tvalid_1's rmse: 20692.3\n",
      "[16500]\ttraining's rmse: 14425.6\tvalid_1's rmse: 20689\n",
      "[17000]\ttraining's rmse: 14297.8\tvalid_1's rmse: 20687.4\n",
      "[17500]\ttraining's rmse: 14172.7\tvalid_1's rmse: 20684.7\n",
      "[18000]\ttraining's rmse: 14057.9\tvalid_1's rmse: 20682.1\n",
      "[18500]\ttraining's rmse: 13938.3\tvalid_1's rmse: 20678.7\n",
      "[19000]\ttraining's rmse: 13818.4\tvalid_1's rmse: 20675\n",
      "[19500]\ttraining's rmse: 13703.8\tvalid_1's rmse: 20672.6\n",
      "Early stopping, best iteration is:\n",
      "[19485]\ttraining's rmse: 13706.9\tvalid_1's rmse: 20672.1\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22805.3\tvalid_1's rmse: 22723.1\n",
      "[1000]\ttraining's rmse: 20955.9\tvalid_1's rmse: 21119.8\n",
      "[1500]\ttraining's rmse: 20180\tvalid_1's rmse: 20626.4\n",
      "[2000]\ttraining's rmse: 19690.9\tvalid_1's rmse: 20383.9\n",
      "[2500]\ttraining's rmse: 19317.8\tvalid_1's rmse: 20243.4\n",
      "[3000]\ttraining's rmse: 18999.6\tvalid_1's rmse: 20142.7\n",
      "[3500]\ttraining's rmse: 18731.2\tvalid_1's rmse: 20075.6\n",
      "[4000]\ttraining's rmse: 18479.7\tvalid_1's rmse: 20018.3\n",
      "[4500]\ttraining's rmse: 18249.8\tvalid_1's rmse: 19977.4\n",
      "[5000]\ttraining's rmse: 18043.8\tvalid_1's rmse: 19946\n",
      "[5500]\ttraining's rmse: 17848.7\tvalid_1's rmse: 19915.6\n",
      "[6000]\ttraining's rmse: 17659.1\tvalid_1's rmse: 19895.6\n",
      "[6500]\ttraining's rmse: 17478.3\tvalid_1's rmse: 19879.9\n",
      "[7000]\ttraining's rmse: 17295.5\tvalid_1's rmse: 19861.1\n",
      "[7500]\ttraining's rmse: 17127.9\tvalid_1's rmse: 19848.9\n",
      "[8000]\ttraining's rmse: 16959.7\tvalid_1's rmse: 19835.1\n",
      "[8500]\ttraining's rmse: 16797.2\tvalid_1's rmse: 19831.1\n",
      "[9000]\ttraining's rmse: 16645.4\tvalid_1's rmse: 19826.2\n",
      "[9500]\ttraining's rmse: 16498.5\tvalid_1's rmse: 19821\n",
      "[10000]\ttraining's rmse: 16342\tvalid_1's rmse: 19809.4\n",
      "[10500]\ttraining's rmse: 16199.4\tvalid_1's rmse: 19803.6\n",
      "[11000]\ttraining's rmse: 16059.3\tvalid_1's rmse: 19798\n",
      "[11500]\ttraining's rmse: 15916\tvalid_1's rmse: 19790.2\n",
      "[12000]\ttraining's rmse: 15786.1\tvalid_1's rmse: 19787.9\n",
      "[12500]\ttraining's rmse: 15655.5\tvalid_1's rmse: 19785\n",
      "[13000]\ttraining's rmse: 15516.6\tvalid_1's rmse: 19777.8\n",
      "[13500]\ttraining's rmse: 15381.8\tvalid_1's rmse: 19771.6\n",
      "[14000]\ttraining's rmse: 15248.3\tvalid_1's rmse: 19774.8\n",
      "Early stopping, best iteration is:\n",
      "[13651]\ttraining's rmse: 15340.3\tvalid_1's rmse: 19770.8\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22781\tvalid_1's rmse: 22781.9\n",
      "[1000]\ttraining's rmse: 20903.4\tvalid_1's rmse: 21265.5\n",
      "[1500]\ttraining's rmse: 20129.7\tvalid_1's rmse: 20812.3\n",
      "[2000]\ttraining's rmse: 19646.2\tvalid_1's rmse: 20586.1\n",
      "[2500]\ttraining's rmse: 19283.1\tvalid_1's rmse: 20455.3\n",
      "[3000]\ttraining's rmse: 18980.9\tvalid_1's rmse: 20368.9\n",
      "[3500]\ttraining's rmse: 18710.9\tvalid_1's rmse: 20298\n",
      "[4000]\ttraining's rmse: 18470\tvalid_1's rmse: 20247.2\n",
      "[4500]\ttraining's rmse: 18244.1\tvalid_1's rmse: 20195.3\n",
      "[5000]\ttraining's rmse: 18024.3\tvalid_1's rmse: 20155.4\n",
      "[5500]\ttraining's rmse: 17818.7\tvalid_1's rmse: 20121.4\n",
      "[6000]\ttraining's rmse: 17621.2\tvalid_1's rmse: 20088\n",
      "[6500]\ttraining's rmse: 17437.3\tvalid_1's rmse: 20066.1\n",
      "[7000]\ttraining's rmse: 17259.1\tvalid_1's rmse: 20043.3\n",
      "[7500]\ttraining's rmse: 17080.5\tvalid_1's rmse: 20025.1\n",
      "[8000]\ttraining's rmse: 16906.4\tvalid_1's rmse: 20003.2\n",
      "[8500]\ttraining's rmse: 16746.7\tvalid_1's rmse: 19984.6\n",
      "[9000]\ttraining's rmse: 16586.2\tvalid_1's rmse: 19973.9\n",
      "[9500]\ttraining's rmse: 16436.9\tvalid_1's rmse: 19963.5\n",
      "[10000]\ttraining's rmse: 16286.9\tvalid_1's rmse: 19951.8\n",
      "[10500]\ttraining's rmse: 16136.7\tvalid_1's rmse: 19937.5\n",
      "[11000]\ttraining's rmse: 15987.2\tvalid_1's rmse: 19930.1\n",
      "[11500]\ttraining's rmse: 15844.3\tvalid_1's rmse: 19922.3\n",
      "[12000]\ttraining's rmse: 15702.1\tvalid_1's rmse: 19916.7\n",
      "[12500]\ttraining's rmse: 15561.8\tvalid_1's rmse: 19913\n",
      "[13000]\ttraining's rmse: 15425.4\tvalid_1's rmse: 19910.5\n",
      "Early stopping, best iteration is:\n",
      "[12843]\ttraining's rmse: 15467.2\tvalid_1's rmse: 19908.9\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22622.7\tvalid_1's rmse: 23365.8\n",
      "[1000]\ttraining's rmse: 20769.4\tvalid_1's rmse: 21945.9\n",
      "[1500]\ttraining's rmse: 19999.5\tvalid_1's rmse: 21486.4\n",
      "[2000]\ttraining's rmse: 19517.8\tvalid_1's rmse: 21249.7\n",
      "[2500]\ttraining's rmse: 19148.7\tvalid_1's rmse: 21095.5\n",
      "[3000]\ttraining's rmse: 18856.9\tvalid_1's rmse: 20990.7\n",
      "[3500]\ttraining's rmse: 18590.3\tvalid_1's rmse: 20903.5\n",
      "[4000]\ttraining's rmse: 18350.6\tvalid_1's rmse: 20829.9\n",
      "[4500]\ttraining's rmse: 18135.3\tvalid_1's rmse: 20770.1\n",
      "[5000]\ttraining's rmse: 17931.2\tvalid_1's rmse: 20718.3\n",
      "[5500]\ttraining's rmse: 17743.3\tvalid_1's rmse: 20678.1\n",
      "[6000]\ttraining's rmse: 17561.7\tvalid_1's rmse: 20645\n",
      "[6500]\ttraining's rmse: 17392\tvalid_1's rmse: 20612.4\n",
      "[7000]\ttraining's rmse: 17219.5\tvalid_1's rmse: 20583.7\n",
      "[7500]\ttraining's rmse: 17056.6\tvalid_1's rmse: 20559.6\n",
      "[8000]\ttraining's rmse: 16892\tvalid_1's rmse: 20541.7\n",
      "[8500]\ttraining's rmse: 16733\tvalid_1's rmse: 20519\n",
      "[9000]\ttraining's rmse: 16580.7\tvalid_1's rmse: 20499.9\n",
      "[9500]\ttraining's rmse: 16436.4\tvalid_1's rmse: 20480.9\n",
      "[10000]\ttraining's rmse: 16291.2\tvalid_1's rmse: 20468.4\n",
      "[10500]\ttraining's rmse: 16153.9\tvalid_1's rmse: 20453.7\n",
      "[11000]\ttraining's rmse: 16012.3\tvalid_1's rmse: 20440.5\n",
      "[11500]\ttraining's rmse: 15869.4\tvalid_1's rmse: 20427.6\n",
      "[12000]\ttraining's rmse: 15727.5\tvalid_1's rmse: 20415.6\n",
      "[12500]\ttraining's rmse: 15587.9\tvalid_1's rmse: 20406.3\n",
      "[13000]\ttraining's rmse: 15456.4\tvalid_1's rmse: 20398.1\n",
      "[13500]\ttraining's rmse: 15316.8\tvalid_1's rmse: 20381.2\n",
      "[14000]\ttraining's rmse: 15187.8\tvalid_1's rmse: 20370\n",
      "[14500]\ttraining's rmse: 15062.4\tvalid_1's rmse: 20360.5\n",
      "[15000]\ttraining's rmse: 14935.9\tvalid_1's rmse: 20352.7\n",
      "[15500]\ttraining's rmse: 14809.1\tvalid_1's rmse: 20348.2\n",
      "[16000]\ttraining's rmse: 14688.1\tvalid_1's rmse: 20343.4\n",
      "[16500]\ttraining's rmse: 14566\tvalid_1's rmse: 20338.1\n",
      "[17000]\ttraining's rmse: 14451.3\tvalid_1's rmse: 20332.3\n",
      "[17500]\ttraining's rmse: 14328.4\tvalid_1's rmse: 20327.3\n",
      "[18000]\ttraining's rmse: 14212.1\tvalid_1's rmse: 20322.4\n",
      "[18500]\ttraining's rmse: 14090.4\tvalid_1's rmse: 20321.2\n",
      "[19000]\ttraining's rmse: 13974.1\tvalid_1's rmse: 20316.8\n",
      "[19500]\ttraining's rmse: 13861.1\tvalid_1's rmse: 20310.4\n",
      "[20000]\ttraining's rmse: 13744.2\tvalid_1's rmse: 20305.5\n",
      "[20500]\ttraining's rmse: 13637.3\tvalid_1's rmse: 20300.1\n",
      "[21000]\ttraining's rmse: 13528.5\tvalid_1's rmse: 20299.8\n",
      "[21500]\ttraining's rmse: 13417.4\tvalid_1's rmse: 20299.2\n",
      "[22000]\ttraining's rmse: 13311\tvalid_1's rmse: 20300\n",
      "Early stopping, best iteration is:\n",
      "[21721]\ttraining's rmse: 13368.9\tvalid_1's rmse: 20297.6\n",
      "OOF Score: 20127.644733425317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_Country__YearsCodingProf</td>\n",
       "      <td>2.198125e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_Country__Age</td>\n",
       "      <td>1.750498e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_Country__ohe_DevType_Student</td>\n",
       "      <td>1.447822e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_Country__Employment</td>\n",
       "      <td>1.298058e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_YearsCodingProf__CurrencySymbol</td>\n",
       "      <td>1.187409e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te_Country__YearsCoding</td>\n",
       "      <td>1.185048e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>te_Country__SalaryType</td>\n",
       "      <td>1.133891e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>te_SalaryType__CurrencySymbol</td>\n",
       "      <td>8.791502e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te_Country__Dependents</td>\n",
       "      <td>8.538550e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>te_YearsCodingProf__Currency</td>\n",
       "      <td>8.395860e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>te_Country__FormalEducation</td>\n",
       "      <td>8.285837e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>te_Country__ohe_Methodology_Agile</td>\n",
       "      <td>6.225957e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>te_YearsCoding__CurrencySymbol</td>\n",
       "      <td>5.764028e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>te_Country__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>5.724352e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>te_Country__CareerSatisfaction</td>\n",
       "      <td>5.593408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>te_Country__CompanySize</td>\n",
       "      <td>5.365287e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>te_Country__ohe_CommunicationTools_Confluence</td>\n",
       "      <td>5.334318e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>te_Employment__CurrencySymbol</td>\n",
       "      <td>5.285584e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>te_CurrencySymbol__Age</td>\n",
       "      <td>5.146902e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te_Country__ohe_EducationTypes_Contributed_to_...</td>\n",
       "      <td>4.703792e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>te_CurrencySymbol__ohe_DevType_Student</td>\n",
       "      <td>3.640432e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>te_Country__CurrencySymbol</td>\n",
       "      <td>3.559595e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>te_Country__OperatingSystem</td>\n",
       "      <td>3.391093e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>te_Country__ohe_DevType_Engineering_manager</td>\n",
       "      <td>3.171251e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>te_CompanySize__YearsCodingProf</td>\n",
       "      <td>2.804819e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>te_YearsCodingProf__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>2.710426e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>te_YearsCodingProf__OperatingSystem</td>\n",
       "      <td>2.517497e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>te_YearsCodingProf__CareerSatisfaction</td>\n",
       "      <td>2.360659e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>te_Currency__SalaryType</td>\n",
       "      <td>2.343689e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>te_YearsCoding__Currency</td>\n",
       "      <td>2.240129e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>te_Currency__Age</td>\n",
       "      <td>2.236505e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>te_YearsCodingProf__ohe_CommunicationTools_Con...</td>\n",
       "      <td>2.114962e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>te_YearsCodingProf__SalaryType</td>\n",
       "      <td>2.074114e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>te_YearsCodingProf__MilitaryUS</td>\n",
       "      <td>2.011055e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>te_Country__Currency</td>\n",
       "      <td>1.952840e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>te_Country__MilitaryUS</td>\n",
       "      <td>1.937519e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>te_FormalEducation__YearsCodingProf</td>\n",
       "      <td>1.696749e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>te_Employment__YearsCodingProf</td>\n",
       "      <td>1.638617e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>te_Country__ohe_RaceEthnicity_White_or_of_Euro...</td>\n",
       "      <td>1.526830e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te_YearsCodingProf__ohe_RaceEthnicity_White_or...</td>\n",
       "      <td>1.497658e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>te_YearsCodingProf__Age</td>\n",
       "      <td>1.456202e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>te_YearsCodingProf__ohe_DevType_Student</td>\n",
       "      <td>1.381979e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>te_YearsCodingProf__ohe_Methodology_Agile</td>\n",
       "      <td>1.314549e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>te_SalaryType__Age</td>\n",
       "      <td>1.307886e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>te_Employment__Currency</td>\n",
       "      <td>1.291891e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>te_Age__MilitaryUS</td>\n",
       "      <td>1.175661e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>te_Country</td>\n",
       "      <td>1.171091e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>te_Employment__ohe_DevType_Student</td>\n",
       "      <td>1.147439e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>te_Employment__SalaryType</td>\n",
       "      <td>1.098570e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>te_Employment__Age</td>\n",
       "      <td>1.054308e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature          gain\n",
       "0                         te_Country__YearsCodingProf  2.198125e+09\n",
       "1                                     te_Country__Age  1.750498e+09\n",
       "2                     te_Country__ohe_DevType_Student  1.447822e+09\n",
       "3                              te_Country__Employment  1.298058e+09\n",
       "4                  te_YearsCodingProf__CurrencySymbol  1.187409e+09\n",
       "5                             te_Country__YearsCoding  1.185048e+09\n",
       "6                              te_Country__SalaryType  1.133891e+09\n",
       "7                       te_SalaryType__CurrencySymbol  8.791502e+08\n",
       "8                              te_Country__Dependents  8.538550e+08\n",
       "9                        te_YearsCodingProf__Currency  8.395860e+08\n",
       "10                        te_Country__FormalEducation  8.285837e+08\n",
       "11                  te_Country__ohe_Methodology_Agile  6.225957e+08\n",
       "12                     te_YearsCoding__CurrencySymbol  5.764028e+08\n",
       "13             te_Country__ohe_LanguageWorkedWith_PHP  5.724352e+08\n",
       "14                     te_Country__CareerSatisfaction  5.593408e+08\n",
       "15                            te_Country__CompanySize  5.365287e+08\n",
       "16      te_Country__ohe_CommunicationTools_Confluence  5.334318e+08\n",
       "17                      te_Employment__CurrencySymbol  5.285584e+08\n",
       "18                             te_CurrencySymbol__Age  5.146902e+08\n",
       "19  te_Country__ohe_EducationTypes_Contributed_to_...  4.703792e+08\n",
       "20             te_CurrencySymbol__ohe_DevType_Student  3.640432e+08\n",
       "21                         te_Country__CurrencySymbol  3.559595e+08\n",
       "22                        te_Country__OperatingSystem  3.391093e+08\n",
       "23        te_Country__ohe_DevType_Engineering_manager  3.171251e+08\n",
       "24                    te_CompanySize__YearsCodingProf  2.804819e+08\n",
       "25     te_YearsCodingProf__ohe_LanguageWorkedWith_PHP  2.710426e+08\n",
       "26                te_YearsCodingProf__OperatingSystem  2.517497e+08\n",
       "27             te_YearsCodingProf__CareerSatisfaction  2.360659e+08\n",
       "28                            te_Currency__SalaryType  2.343689e+08\n",
       "29                           te_YearsCoding__Currency  2.240129e+08\n",
       "30                                   te_Currency__Age  2.236505e+08\n",
       "31  te_YearsCodingProf__ohe_CommunicationTools_Con...  2.114962e+08\n",
       "32                     te_YearsCodingProf__SalaryType  2.074114e+08\n",
       "33                     te_YearsCodingProf__MilitaryUS  2.011055e+08\n",
       "34                               te_Country__Currency  1.952840e+08\n",
       "35                             te_Country__MilitaryUS  1.937519e+08\n",
       "36                te_FormalEducation__YearsCodingProf  1.696749e+08\n",
       "37                     te_Employment__YearsCodingProf  1.638617e+08\n",
       "38  te_Country__ohe_RaceEthnicity_White_or_of_Euro...  1.526830e+08\n",
       "39  te_YearsCodingProf__ohe_RaceEthnicity_White_or...  1.497658e+08\n",
       "40                            te_YearsCodingProf__Age  1.456202e+08\n",
       "41            te_YearsCodingProf__ohe_DevType_Student  1.381979e+08\n",
       "42          te_YearsCodingProf__ohe_Methodology_Agile  1.314549e+08\n",
       "43                                 te_SalaryType__Age  1.307886e+08\n",
       "44                            te_Employment__Currency  1.291891e+08\n",
       "45                                 te_Age__MilitaryUS  1.175661e+08\n",
       "46                                         te_Country  1.171091e+08\n",
       "47                 te_Employment__ohe_DevType_Student  1.147439e+08\n",
       "48                          te_Employment__SalaryType  1.098570e+08\n",
       "49                                 te_Employment__Age  1.054308e+08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, models, oof_score = train(train_df, test_df, use_cols, fold_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_df, models, use_cols, oof_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
