{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df):\n",
    "    \n",
    "    ###########################\n",
    "    # Functions of preprocess\n",
    "    ###########################\n",
    "    def get_multi_cat_cols(train_df):\n",
    "        tmp = train_df.iloc[:1000]\n",
    "        multi_cols = []\n",
    "        for c in train_df.columns:\n",
    "            sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "            if sep_num > 10:\n",
    "                multi_cols.append(c)\n",
    "        return multi_cols\n",
    "\n",
    "    def add_rank_feature(df):\n",
    "        rank_prefix_list = [\n",
    "            \"AssessBenefits\",\n",
    "            \"AssessJob\",\n",
    "            \"JobContactPriorities\",\n",
    "            \"JobEmailPriorities\",\n",
    "            \"AdsPriorities\",\n",
    "        ]\n",
    "        for prefix in tqdm(rank_prefix_list):\n",
    "            rank_cols = [c for c in df.columns if prefix in c]\n",
    "            col_pairs = itertools.combinations(rank_cols, 2)\n",
    "            for col_a, col_b in col_pairs:\n",
    "                df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "        return df\n",
    "\n",
    "    def get_basic_importance_cols(use_num=50):\n",
    "        # basicなモデルのimportanceを読み込み\n",
    "        importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "        imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "        return imp_feats\n",
    "\n",
    "    def make_agg_feature(train_df, test_df):\n",
    "        imp_feats = get_basic_importance_cols(use_num=50)\n",
    "        imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "        imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "        print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "        #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "        all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "        for cat_col in tqdm(imp_cat_cols):\n",
    "            for nume_col in imp_nume_cols:\n",
    "                # one-hotは同じカテゴリの場合がある\n",
    "                if cat_col == nume_col:\n",
    "                    continue\n",
    "                all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "                all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "                all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "                all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "                all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "                all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "        train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "        test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        del all_df\n",
    "        gc.collect()\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=False)\n",
    "    def target_encoding(train_df, test_df):\n",
    "        te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "        for c in tqdm(te_cols):\n",
    "            new_col = \"te_\" + c\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=False)\n",
    "    def multiple_target_encoding(train_df, test_df):\n",
    "         # multiple target encoding\n",
    "        multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "        imp_feats = get_basic_importance_cols(use_num=30)\n",
    "        multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "        combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "        for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "            new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "            test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "            del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "            gc.collect()\n",
    "        return train_df, test_df   \n",
    "    \n",
    "    ################################\n",
    "    # Columns infomation\n",
    "    ################################\n",
    "    original_cols = train_df.columns.tolist()\n",
    "    multi_cat_cols = get_multi_cat_cols(train_df)\n",
    "\n",
    "    nume_cols = [\n",
    "        c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "        if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "    ]\n",
    "\n",
    "    cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]\n",
    "\n",
    "    non_basic_nume_cols = []\n",
    "    non_basic_cat_cols = []\n",
    "\n",
    "    ################################\n",
    "    #  Make feature\n",
    "    ################################    \n",
    "    \n",
    "    # rank feature\n",
    "    train_df = add_rank_feature(train_df)\n",
    "    test_df = add_rank_feature(test_df)\n",
    "\n",
    "    # multi -category encoding \n",
    "    for c in tqdm(multi_cat_cols):\n",
    "        binarizer = MultiLabelBinarizer()\n",
    "        train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "        test_arr = binarizer.transform(test_multi_srs)\n",
    "        feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "        train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "        test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "        all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "        train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "        test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "        # ohe_featureはcategoryとnumerical両方として扱う\n",
    "        nume_cols += feat_cols\n",
    "        cat_cols += feat_cols\n",
    "        # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "        # SVD\n",
    "        svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "        all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "        train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "        test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # simple category encoding\n",
    "    for c in cat_cols:\n",
    "        train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "        test_df[c] = uniques.get_indexer(test_df[c])\n",
    "    \n",
    "    # reduce memory\n",
    "    # numerical cols\n",
    "    for c in nume_cols:\n",
    "        if train_df[c].nunique() > 1000:\n",
    "            train_df[c] = train_df[c].astype(np.float32)\n",
    "            test_df[c] = test_df[c].astype(np.float32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.float16)\n",
    "            test_df[c] = test_df[c].astype(np.float16)\n",
    "    # category cols\n",
    "    for c in cat_cols:\n",
    "        if train_df[c].max() > 32767:\n",
    "            train_df[c] = train_df[c].astype(np.int32)\n",
    "            test_df[c] = test_df[c].astype(np.int32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.int16)\n",
    "            test_df[c] = test_df[c].astype(np.int16)\n",
    "    \n",
    "    # change columns name\n",
    "    train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "    test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "   \n",
    "    # aggregate feature\n",
    "    train_df, test_df = make_agg_feature(train_df, test_df)\n",
    "\n",
    "    # make train/validation index list for target encoding\n",
    "    folds = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"Salary\"])]\n",
    "    \n",
    "    # target encoding\n",
    "    train_df, test_df = target_encoding(train_df, test_df)\n",
    "\n",
    "    # multiple category target encoding \n",
    "    train_df, test_df = multiple_target_encoding(train_df, test_df)\n",
    "    \n",
    "    # make use columns list\n",
    "    use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\"]]\n",
    "    print(len(use_cols))\n",
    "    \n",
    "    return train_df, test_df, use_cols, fold_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, use_cols, fold_idx_list):\n",
    "\n",
    "    lgb_params = {\n",
    "                'objective': 'poisson',\n",
    "                \"metric\": \"rmse\",\n",
    "                \"verbosity\": -1,\n",
    "                \"boosting\": \"gbdt\",\n",
    "                'learning_rate': 0.05,\n",
    "                'num_leaves': 64,\n",
    "                'min_data_in_leaf': 80, \n",
    "                'max_depth': 4,\n",
    "                \"bagging_freq\": 5,\n",
    "                \"bagging_fraction\": 0.8,\n",
    "                \"lambda_l1\": 0.5,\n",
    "                \"lambda_l2\": 0.5,\n",
    "                \"feature_fraction\": 0.1,\n",
    "                \"seed\": 2020,\n",
    "                \"num_threads\": -1,\n",
    "                \"max_bins\": 30\n",
    "    }\n",
    "    def feature_selection(train_df, use_cols, n_features=1000):\n",
    "        df = train_df.sample(30000, random_state=2020)\n",
    "        train_dataset = lgb.Dataset(\n",
    "            df.loc[:, use_cols],\n",
    "            label = df.loc[:, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    2000,\n",
    "                    valid_sets = [train_dataset],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds = None,\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "        return select_features\n",
    "    \n",
    "    def lgb_train(train_df, fold_idx_list, use_cols, feature_select=None, seed=None, *args, **kwargs):\n",
    "        importances = pd.DataFrame()\n",
    "        oof_preds = np.zeros(len(train_df))\n",
    "        models = []\n",
    "        if feature_select is not None and isinstance(feature_select, int):\n",
    "            _use_cols = feature_selection(train_df, use_cols, n_features=feature_select)\n",
    "        else:\n",
    "            _use_cols = use_cols.copy()\n",
    "        _lgb_params = lgb_params.copy()\n",
    "        if seed is not None:\n",
    "            _lgb_params[\"seed\"] = seed\n",
    "\n",
    "        for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "            print(f\"Fold {fold_i+1}\")\n",
    "            train_dataset = lgb.Dataset(\n",
    "                train_df.loc[trn_idx, _use_cols],\n",
    "                label = train_df.loc[trn_idx, \"Salary\"]\n",
    "            )\n",
    "            valid_dataset = lgb.Dataset(\n",
    "                train_df.loc[val_idx, _use_cols],\n",
    "                label = train_df.loc[val_idx, \"Salary\"]\n",
    "            )\n",
    "            model = lgb.train(\n",
    "                        _lgb_params,\n",
    "                        train_dataset,\n",
    "                        30000,\n",
    "                        valid_sets = [train_dataset, valid_dataset],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 500,\n",
    "                        #feval = eval_f1,\n",
    "                        #callbacks = [log_callback],\n",
    "            )\n",
    "            imp_df = pd.DataFrame()\n",
    "            imp_df['feature'] = _use_cols\n",
    "            imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "            importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "            # oof predict\n",
    "            oof_preds[val_idx] = model.predict(train_df.loc[val_idx, _use_cols])\n",
    "            models.append(model)\n",
    "\n",
    "        oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "        print(f\"OOF Score: {oof_score}\")\n",
    "        return models, oof_preds, importances, oof_score, _use_cols\n",
    "    \n",
    "    training_list = [\n",
    "        {\n",
    "            \"n_features\": None,\n",
    "            \"seed\": 2020,\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"n_features\": 2000,\n",
    "            \"seed\": 2021,\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"n_features\": 1500,\n",
    "            \"seed\": 2022,\n",
    "            \"weight\": 0.25\n",
    "        },\n",
    "        {\n",
    "            \"n_features\": 1000,\n",
    "            \"seed\": 2023,\n",
    "            \"weight\": 0.25\n",
    "        }\n",
    "    \n",
    "    ]\n",
    "    output_list = []\n",
    "    for train_config in training_list: \n",
    "        _models, _oof_preds, _importances, _oof_score, _use_cols = \\\n",
    "            lgb_train(train_df, fold_idx_list, use_cols, **train_config)\n",
    "        output_list.append(\n",
    "            {\n",
    "                \"models\": _models,\n",
    "                \"oof_preds\": _oof_preds,\n",
    "                \"importances\": _importances,\n",
    "                \"oof_score\": _oof_score,\n",
    "                \"use_cols\": _use_cols,\n",
    "                \"weight\": train_config[\"weight\"]\n",
    "            }\n",
    "        )\n",
    "    # calc total oof score\n",
    "    oof_preds = np.zeros(len(train_df))\n",
    "    importance_list = []\n",
    "    for output in output_list:\n",
    "        oof_preds += output[\"oof_preds\"] * output[\"weight\"]\n",
    "        importance_list.append(output[\"importances\"])\n",
    "    \n",
    "    oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "    print(f\"Total OOF Score: {oof_score}\")    \n",
    "    \n",
    "    display(\n",
    "        pd.concat(importance_list, axis=0).groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:50]\n",
    "    )\n",
    "\n",
    "    return train_df, test_df, output_list, oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, output_list, oof_score):\n",
    "    test_pred = np.zeros(len(test_df))\n",
    "    for output in tqdm(output_list):\n",
    "        models = output[\"models\"]\n",
    "        use_cols = output[\"use_cols\"]\n",
    "        weight = output[\"weight\"]\n",
    "        for model in models:\n",
    "            test_pred += (model.predict(test_df[use_cols]) / len(models)) * weight\n",
    "    \n",
    "    # make submit file\n",
    "    sub_df = pd.read_csv(\"../input/submit.csv\")\n",
    "    sub_df[\"Salary\"] = test_pred\n",
    "    sub_df.to_csv(f\"../predict/{model_title}_{oof_score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = \"039_seed_averaging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b0840b56f643baaeae68b57d678a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae1fe25a57445cae52ede5b7ebe897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8598eb83b8c149b4a72273ce49725cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d960f1ca034c65a2ce45f2022ab03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2495\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, use_cols, fold_idx_list = preprocess(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19249.2\tvalid_1's rmse: 20820.9\n",
      "[1000]\ttraining's rmse: 18010.4\tvalid_1's rmse: 20497\n",
      "[1500]\ttraining's rmse: 17070.6\tvalid_1's rmse: 20349.8\n",
      "[2000]\ttraining's rmse: 16288.7\tvalid_1's rmse: 20294.1\n",
      "[2500]\ttraining's rmse: 15569.3\tvalid_1's rmse: 20242.6\n",
      "[3000]\ttraining's rmse: 14908.8\tvalid_1's rmse: 20219.9\n",
      "[3500]\ttraining's rmse: 14277.9\tvalid_1's rmse: 20215\n",
      "Early stopping, best iteration is:\n",
      "[3386]\ttraining's rmse: 14415.1\tvalid_1's rmse: 20206.8\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19287.2\tvalid_1's rmse: 20823.7\n",
      "[1000]\ttraining's rmse: 18069\tvalid_1's rmse: 20486.1\n",
      "[1500]\ttraining's rmse: 17189.8\tvalid_1's rmse: 20344\n",
      "[2000]\ttraining's rmse: 16394\tvalid_1's rmse: 20243.8\n",
      "[2500]\ttraining's rmse: 15681.9\tvalid_1's rmse: 20207.5\n",
      "[3000]\ttraining's rmse: 15009.5\tvalid_1's rmse: 20194.3\n",
      "[3500]\ttraining's rmse: 14364.3\tvalid_1's rmse: 20177.7\n",
      "[4000]\ttraining's rmse: 13767.2\tvalid_1's rmse: 20157.8\n",
      "[4500]\ttraining's rmse: 13209.9\tvalid_1's rmse: 20142.5\n",
      "Early stopping, best iteration is:\n",
      "[4276]\ttraining's rmse: 13467.3\tvalid_1's rmse: 20139.8\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19251.2\tvalid_1's rmse: 20841.6\n",
      "[1000]\ttraining's rmse: 18050.4\tvalid_1's rmse: 20617.2\n",
      "[1500]\ttraining's rmse: 17159.9\tvalid_1's rmse: 20512.9\n",
      "[2000]\ttraining's rmse: 16400.7\tvalid_1's rmse: 20463.9\n",
      "[2500]\ttraining's rmse: 15689.6\tvalid_1's rmse: 20460.5\n",
      "[3000]\ttraining's rmse: 15021.8\tvalid_1's rmse: 20449.2\n",
      "[3500]\ttraining's rmse: 14396.3\tvalid_1's rmse: 20445.3\n",
      "Early stopping, best iteration is:\n",
      "[3467]\ttraining's rmse: 14435.8\tvalid_1's rmse: 20441.1\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19324.6\tvalid_1's rmse: 20862.4\n",
      "[1000]\ttraining's rmse: 18094.4\tvalid_1's rmse: 20490.2\n",
      "[1500]\ttraining's rmse: 17194.3\tvalid_1's rmse: 20339.4\n",
      "[2000]\ttraining's rmse: 16409.8\tvalid_1's rmse: 20255.6\n",
      "[2500]\ttraining's rmse: 15719.2\tvalid_1's rmse: 20208.8\n",
      "[3000]\ttraining's rmse: 15070.7\tvalid_1's rmse: 20189.4\n",
      "[3500]\ttraining's rmse: 14442\tvalid_1's rmse: 20173.6\n",
      "[4000]\ttraining's rmse: 13835.2\tvalid_1's rmse: 20176.8\n",
      "Early stopping, best iteration is:\n",
      "[3753]\ttraining's rmse: 14141\tvalid_1's rmse: 20159.7\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19359.2\tvalid_1's rmse: 20559.4\n",
      "[1000]\ttraining's rmse: 18143.9\tvalid_1's rmse: 20237.6\n",
      "[1500]\ttraining's rmse: 17281.8\tvalid_1's rmse: 20110.9\n",
      "[2000]\ttraining's rmse: 16481.1\tvalid_1's rmse: 20046.4\n",
      "[2500]\ttraining's rmse: 15782.8\tvalid_1's rmse: 20000.1\n",
      "[3000]\ttraining's rmse: 15141\tvalid_1's rmse: 19984.9\n",
      "[3500]\ttraining's rmse: 14506.9\tvalid_1's rmse: 19989.6\n",
      "Early stopping, best iteration is:\n",
      "[3072]\ttraining's rmse: 15048\tvalid_1's rmse: 19981.7\n",
      "OOF Score: 20186.360716338484\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19269.4\tvalid_1's rmse: 20844.6\n",
      "[1000]\ttraining's rmse: 18000.4\tvalid_1's rmse: 20504.3\n",
      "[1500]\ttraining's rmse: 17079.8\tvalid_1's rmse: 20365.4\n",
      "[2000]\ttraining's rmse: 16289\tvalid_1's rmse: 20300.1\n",
      "[2500]\ttraining's rmse: 15597.8\tvalid_1's rmse: 20280.3\n",
      "[3000]\ttraining's rmse: 14950.9\tvalid_1's rmse: 20247.6\n",
      "[3500]\ttraining's rmse: 14320.4\tvalid_1's rmse: 20218.1\n",
      "[4000]\ttraining's rmse: 13709.2\tvalid_1's rmse: 20219.1\n",
      "Early stopping, best iteration is:\n",
      "[3933]\ttraining's rmse: 13796.8\tvalid_1's rmse: 20215.2\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19292\tvalid_1's rmse: 20863.7\n",
      "[1000]\ttraining's rmse: 18089.2\tvalid_1's rmse: 20494.6\n",
      "[1500]\ttraining's rmse: 17183.2\tvalid_1's rmse: 20316.8\n",
      "[2000]\ttraining's rmse: 16405.9\tvalid_1's rmse: 20232.6\n",
      "[2500]\ttraining's rmse: 15686.7\tvalid_1's rmse: 20167.3\n",
      "[3000]\ttraining's rmse: 15039.4\tvalid_1's rmse: 20145.5\n",
      "[3500]\ttraining's rmse: 14396.4\tvalid_1's rmse: 20122.7\n",
      "[4000]\ttraining's rmse: 13799.5\tvalid_1's rmse: 20130.3\n",
      "Early stopping, best iteration is:\n",
      "[3559]\ttraining's rmse: 14325.4\tvalid_1's rmse: 20117.5\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19244.4\tvalid_1's rmse: 20867.1\n",
      "[1000]\ttraining's rmse: 18044.5\tvalid_1's rmse: 20616.3\n",
      "[1500]\ttraining's rmse: 17138\tvalid_1's rmse: 20522.9\n",
      "[2000]\ttraining's rmse: 16359.7\tvalid_1's rmse: 20485.2\n",
      "[2500]\ttraining's rmse: 15635\tvalid_1's rmse: 20464.7\n",
      "[3000]\ttraining's rmse: 14992.2\tvalid_1's rmse: 20464.3\n",
      "Early stopping, best iteration is:\n",
      "[2947]\ttraining's rmse: 15052.1\tvalid_1's rmse: 20458.8\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19295.2\tvalid_1's rmse: 20836.7\n",
      "[1000]\ttraining's rmse: 18071\tvalid_1's rmse: 20499.3\n",
      "[1500]\ttraining's rmse: 17170.2\tvalid_1's rmse: 20321.1\n",
      "[2000]\ttraining's rmse: 16402.8\tvalid_1's rmse: 20227.3\n",
      "[2500]\ttraining's rmse: 15699\tvalid_1's rmse: 20198.6\n",
      "[3000]\ttraining's rmse: 15027.5\tvalid_1's rmse: 20170.5\n",
      "[3500]\ttraining's rmse: 14403\tvalid_1's rmse: 20158.7\n",
      "Early stopping, best iteration is:\n",
      "[3374]\ttraining's rmse: 14557\tvalid_1's rmse: 20154.2\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19389\tvalid_1's rmse: 20456.3\n",
      "[1000]\ttraining's rmse: 18159.2\tvalid_1's rmse: 20126.2\n",
      "[1500]\ttraining's rmse: 17257.5\tvalid_1's rmse: 20013.9\n",
      "[2000]\ttraining's rmse: 16496.9\tvalid_1's rmse: 19962.4\n",
      "[2500]\ttraining's rmse: 15774.8\tvalid_1's rmse: 19938.3\n",
      "[3000]\ttraining's rmse: 15112.7\tvalid_1's rmse: 19910.4\n",
      "[3500]\ttraining's rmse: 14492.5\tvalid_1's rmse: 19909\n",
      "Early stopping, best iteration is:\n",
      "[3066]\ttraining's rmse: 15024.9\tvalid_1's rmse: 19903.6\n",
      "OOF Score: 20170.65587730133\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19259.4\tvalid_1's rmse: 20813.8\n",
      "[1000]\ttraining's rmse: 17990.6\tvalid_1's rmse: 20510.9\n",
      "[1500]\ttraining's rmse: 17073.8\tvalid_1's rmse: 20392.5\n",
      "[2000]\ttraining's rmse: 16324.6\tvalid_1's rmse: 20320.8\n",
      "[2500]\ttraining's rmse: 15589.3\tvalid_1's rmse: 20281.6\n",
      "[3000]\ttraining's rmse: 14921.1\tvalid_1's rmse: 20286.4\n",
      "Early stopping, best iteration is:\n",
      "[2636]\ttraining's rmse: 15410.4\tvalid_1's rmse: 20268.4\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19316.7\tvalid_1's rmse: 20778.6\n",
      "[1000]\ttraining's rmse: 18114.8\tvalid_1's rmse: 20431.4\n",
      "[1500]\ttraining's rmse: 17239.6\tvalid_1's rmse: 20275.2\n",
      "[2000]\ttraining's rmse: 16455.9\tvalid_1's rmse: 20192.5\n",
      "[2500]\ttraining's rmse: 15748.5\tvalid_1's rmse: 20136\n",
      "[3000]\ttraining's rmse: 15085\tvalid_1's rmse: 20127.3\n",
      "[3500]\ttraining's rmse: 14446.5\tvalid_1's rmse: 20116.8\n",
      "Early stopping, best iteration is:\n",
      "[3302]\ttraining's rmse: 14691.4\tvalid_1's rmse: 20113\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19250.2\tvalid_1's rmse: 20880.1\n",
      "[1000]\ttraining's rmse: 18066.1\tvalid_1's rmse: 20654.3\n",
      "[1500]\ttraining's rmse: 17160\tvalid_1's rmse: 20546\n",
      "[2000]\ttraining's rmse: 16369.9\tvalid_1's rmse: 20503.9\n",
      "[2500]\ttraining's rmse: 15650.3\tvalid_1's rmse: 20478.3\n",
      "[3000]\ttraining's rmse: 15009.4\tvalid_1's rmse: 20455.2\n",
      "[3500]\ttraining's rmse: 14379.6\tvalid_1's rmse: 20453.1\n",
      "Early stopping, best iteration is:\n",
      "[3385]\ttraining's rmse: 14526.2\tvalid_1's rmse: 20447.7\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19299.3\tvalid_1's rmse: 20930.8\n",
      "[1000]\ttraining's rmse: 18112.4\tvalid_1's rmse: 20566.6\n",
      "[1500]\ttraining's rmse: 17205.8\tvalid_1's rmse: 20410.7\n",
      "[2000]\ttraining's rmse: 16446.7\tvalid_1's rmse: 20333.2\n",
      "[2500]\ttraining's rmse: 15723.5\tvalid_1's rmse: 20282.1\n",
      "[3000]\ttraining's rmse: 15047.2\tvalid_1's rmse: 20235.7\n",
      "[3500]\ttraining's rmse: 14422.5\tvalid_1's rmse: 20209.6\n",
      "[4000]\ttraining's rmse: 13837.4\tvalid_1's rmse: 20212.9\n",
      "Early stopping, best iteration is:\n",
      "[3594]\ttraining's rmse: 14313.9\tvalid_1's rmse: 20202.3\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19355.5\tvalid_1's rmse: 20489.4\n",
      "[1000]\ttraining's rmse: 18140.8\tvalid_1's rmse: 20178\n",
      "[1500]\ttraining's rmse: 17219.4\tvalid_1's rmse: 20079.2\n",
      "[2000]\ttraining's rmse: 16464.8\tvalid_1's rmse: 20030.5\n",
      "[2500]\ttraining's rmse: 15738.7\tvalid_1's rmse: 19981.2\n",
      "[3000]\ttraining's rmse: 15121.6\tvalid_1's rmse: 19986.5\n",
      "Early stopping, best iteration is:\n",
      "[2549]\ttraining's rmse: 15670.9\tvalid_1's rmse: 19976.9\n",
      "OOF Score: 20202.259400340245\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19258.8\tvalid_1's rmse: 20846.8\n",
      "[1000]\ttraining's rmse: 17996.2\tvalid_1's rmse: 20533\n",
      "[1500]\ttraining's rmse: 17086.7\tvalid_1's rmse: 20387.1\n",
      "[2000]\ttraining's rmse: 16311.7\tvalid_1's rmse: 20344.3\n",
      "[2500]\ttraining's rmse: 15588.4\tvalid_1's rmse: 20273.4\n",
      "[3000]\ttraining's rmse: 14930.9\tvalid_1's rmse: 20247.5\n",
      "[3500]\ttraining's rmse: 14289.7\tvalid_1's rmse: 20234\n",
      "[4000]\ttraining's rmse: 13706.8\tvalid_1's rmse: 20235.5\n",
      "Early stopping, best iteration is:\n",
      "[3836]\ttraining's rmse: 13900\tvalid_1's rmse: 20226.6\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19314\tvalid_1's rmse: 20805.8\n",
      "[1000]\ttraining's rmse: 18123.2\tvalid_1's rmse: 20485.2\n",
      "[1500]\ttraining's rmse: 17220.8\tvalid_1's rmse: 20336.3\n",
      "[2000]\ttraining's rmse: 16454\tvalid_1's rmse: 20234.7\n",
      "[2500]\ttraining's rmse: 15724\tvalid_1's rmse: 20183.1\n",
      "[3000]\ttraining's rmse: 15058.3\tvalid_1's rmse: 20160.6\n",
      "[3500]\ttraining's rmse: 14414\tvalid_1's rmse: 20117\n",
      "[4000]\ttraining's rmse: 13816.1\tvalid_1's rmse: 20107.3\n",
      "[4500]\ttraining's rmse: 13258.6\tvalid_1's rmse: 20104.2\n",
      "Early stopping, best iteration is:\n",
      "[4250]\ttraining's rmse: 13537.2\tvalid_1's rmse: 20091.4\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19230.9\tvalid_1's rmse: 20823.9\n",
      "[1000]\ttraining's rmse: 18057.6\tvalid_1's rmse: 20604.4\n",
      "[1500]\ttraining's rmse: 17158.2\tvalid_1's rmse: 20513.8\n",
      "[2000]\ttraining's rmse: 16381\tvalid_1's rmse: 20469.6\n",
      "[2500]\ttraining's rmse: 15651.2\tvalid_1's rmse: 20425.7\n",
      "[3000]\ttraining's rmse: 14984.3\tvalid_1's rmse: 20429.3\n",
      "Early stopping, best iteration is:\n",
      "[2704]\ttraining's rmse: 15374.4\tvalid_1's rmse: 20415.1\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19295.2\tvalid_1's rmse: 20909.8\n",
      "[1000]\ttraining's rmse: 18076.5\tvalid_1's rmse: 20548.2\n",
      "[1500]\ttraining's rmse: 17180.4\tvalid_1's rmse: 20401.4\n",
      "[2000]\ttraining's rmse: 16381.2\tvalid_1's rmse: 20303.7\n",
      "[2500]\ttraining's rmse: 15684.8\tvalid_1's rmse: 20262.8\n",
      "[3000]\ttraining's rmse: 15032.5\tvalid_1's rmse: 20236.3\n",
      "[3500]\ttraining's rmse: 14416.8\tvalid_1's rmse: 20226.5\n",
      "Early stopping, best iteration is:\n",
      "[3428]\ttraining's rmse: 14508.3\tvalid_1's rmse: 20223.4\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 19370\tvalid_1's rmse: 20498.3\n",
      "[1000]\ttraining's rmse: 18145.1\tvalid_1's rmse: 20198.5\n",
      "[1500]\ttraining's rmse: 17261\tvalid_1's rmse: 20069.7\n",
      "[2000]\ttraining's rmse: 16478.7\tvalid_1's rmse: 20009\n",
      "[2500]\ttraining's rmse: 15777.5\tvalid_1's rmse: 19980.9\n",
      "[3000]\ttraining's rmse: 15123\tvalid_1's rmse: 19976.5\n",
      "[3500]\ttraining's rmse: 14512.5\tvalid_1's rmse: 19973.5\n",
      "Early stopping, best iteration is:\n",
      "[3343]\ttraining's rmse: 14696\tvalid_1's rmse: 19964\n",
      "OOF Score: 20184.68056772443\n",
      "Total OOF Score: 20111.36501516836\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_Country__Age</td>\n",
       "      <td>4.585006e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_Country__YearsCodingProf</td>\n",
       "      <td>4.520142e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_Country__Employment</td>\n",
       "      <td>3.446690e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_Country__YearsCoding</td>\n",
       "      <td>3.442708e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_Country__SalaryType</td>\n",
       "      <td>2.588627e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te_Country__ohe_DevType_Student</td>\n",
       "      <td>2.425946e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>te_YearsCodingProf__CurrencySymbol</td>\n",
       "      <td>2.214364e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>te_Country__FormalEducation</td>\n",
       "      <td>2.002769e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te_Country__CareerSatisfaction</td>\n",
       "      <td>1.811164e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>te_SalaryType__CurrencySymbol</td>\n",
       "      <td>1.743912e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>te_Country__ohe_Methodology_Agile</td>\n",
       "      <td>1.291969e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>te_Country__ohe_CommunicationTools_Confluence</td>\n",
       "      <td>1.124316e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>te_YearsCodingProf__Currency</td>\n",
       "      <td>1.111153e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>te_Country__ohe_EducationTypes_Contributed_to_...</td>\n",
       "      <td>9.922229e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>te_Country__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>9.389084e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>te_YearsCoding__CurrencySymbol</td>\n",
       "      <td>9.076118e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>te_Country__Dependents</td>\n",
       "      <td>8.793135e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>te_YearsCodingProf__MilitaryUS</td>\n",
       "      <td>7.714623e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>te_CurrencySymbol__Age</td>\n",
       "      <td>7.227793e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te_Employment__CurrencySymbol</td>\n",
       "      <td>6.590446e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>te_CurrencySymbol__ohe_DevType_Student</td>\n",
       "      <td>6.335345e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>te_YearsCodingProf__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>6.325577e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>te_Country__MilitaryUS</td>\n",
       "      <td>6.039450e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>te_CompanySize__YearsCodingProf</td>\n",
       "      <td>5.944308e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>te_Country__ohe_DevType_Engineering_manager</td>\n",
       "      <td>5.583212e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>te_Country__CurrencySymbol</td>\n",
       "      <td>5.379304e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>te_Currency__Age</td>\n",
       "      <td>5.219625e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>te_YearsCodingProf__SalaryType</td>\n",
       "      <td>5.016352e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>te_Currency__SalaryType</td>\n",
       "      <td>4.910931e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>te_YearsCodingProf__OperatingSystem</td>\n",
       "      <td>4.816866e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>te_SalaryType__Age</td>\n",
       "      <td>4.429842e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>te_YearsCoding__Currency</td>\n",
       "      <td>4.263751e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>te_Country__OperatingSystem</td>\n",
       "      <td>4.164611e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>te_Country__CompanySize</td>\n",
       "      <td>3.930416e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>te_Employment__YearsCodingProf</td>\n",
       "      <td>3.919299e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>te_Country</td>\n",
       "      <td>3.908703e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>te_Employment__Currency</td>\n",
       "      <td>3.742153e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>te_YearsCodingProf__ohe_RaceEthnicity_White_or...</td>\n",
       "      <td>3.440734e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>te_YearsCodingProf__ohe_DevType_Student</td>\n",
       "      <td>3.387761e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te_Country__Currency</td>\n",
       "      <td>3.299944e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>te_YearsCodingProf__ohe_CommunicationTools_Con...</td>\n",
       "      <td>3.126329e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>te_YearsCodingProf__ohe_EducationTypes_Contrib...</td>\n",
       "      <td>2.572849e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>te_YearsCodingProf__CareerSatisfaction</td>\n",
       "      <td>2.471949e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>te_FormalEducation__YearsCodingProf</td>\n",
       "      <td>2.366002e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>te_CompanySize__OperatingSystem</td>\n",
       "      <td>2.268757e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>te_YearsCodingProf__ohe_Methodology_Agile</td>\n",
       "      <td>2.267516e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>te_YearsCodingProf__Dependents</td>\n",
       "      <td>2.024592e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>te_YearsCoding__YearsCodingProf</td>\n",
       "      <td>1.979352e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>te_Currency__ohe_DevType_Student</td>\n",
       "      <td>1.840801e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>te_Employment__SalaryType</td>\n",
       "      <td>1.838042e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature          gain\n",
       "0                                     te_Country__Age  4.585006e+08\n",
       "1                         te_Country__YearsCodingProf  4.520142e+08\n",
       "2                              te_Country__Employment  3.446690e+08\n",
       "3                             te_Country__YearsCoding  3.442708e+08\n",
       "4                              te_Country__SalaryType  2.588627e+08\n",
       "5                     te_Country__ohe_DevType_Student  2.425946e+08\n",
       "6                  te_YearsCodingProf__CurrencySymbol  2.214364e+08\n",
       "7                         te_Country__FormalEducation  2.002769e+08\n",
       "8                      te_Country__CareerSatisfaction  1.811164e+08\n",
       "9                       te_SalaryType__CurrencySymbol  1.743912e+08\n",
       "10                  te_Country__ohe_Methodology_Agile  1.291969e+08\n",
       "11      te_Country__ohe_CommunicationTools_Confluence  1.124316e+08\n",
       "12                       te_YearsCodingProf__Currency  1.111153e+08\n",
       "13  te_Country__ohe_EducationTypes_Contributed_to_...  9.922229e+07\n",
       "14             te_Country__ohe_LanguageWorkedWith_PHP  9.389084e+07\n",
       "15                     te_YearsCoding__CurrencySymbol  9.076118e+07\n",
       "16                             te_Country__Dependents  8.793135e+07\n",
       "17                     te_YearsCodingProf__MilitaryUS  7.714623e+07\n",
       "18                             te_CurrencySymbol__Age  7.227793e+07\n",
       "19                      te_Employment__CurrencySymbol  6.590446e+07\n",
       "20             te_CurrencySymbol__ohe_DevType_Student  6.335345e+07\n",
       "21     te_YearsCodingProf__ohe_LanguageWorkedWith_PHP  6.325577e+07\n",
       "22                             te_Country__MilitaryUS  6.039450e+07\n",
       "23                    te_CompanySize__YearsCodingProf  5.944308e+07\n",
       "24        te_Country__ohe_DevType_Engineering_manager  5.583212e+07\n",
       "25                         te_Country__CurrencySymbol  5.379304e+07\n",
       "26                                   te_Currency__Age  5.219625e+07\n",
       "27                     te_YearsCodingProf__SalaryType  5.016352e+07\n",
       "28                            te_Currency__SalaryType  4.910931e+07\n",
       "29                te_YearsCodingProf__OperatingSystem  4.816866e+07\n",
       "30                                 te_SalaryType__Age  4.429842e+07\n",
       "31                           te_YearsCoding__Currency  4.263751e+07\n",
       "32                        te_Country__OperatingSystem  4.164611e+07\n",
       "33                            te_Country__CompanySize  3.930416e+07\n",
       "34                     te_Employment__YearsCodingProf  3.919299e+07\n",
       "35                                         te_Country  3.908703e+07\n",
       "36                            te_Employment__Currency  3.742153e+07\n",
       "37  te_YearsCodingProf__ohe_RaceEthnicity_White_or...  3.440734e+07\n",
       "38            te_YearsCodingProf__ohe_DevType_Student  3.387761e+07\n",
       "39                               te_Country__Currency  3.299944e+07\n",
       "40  te_YearsCodingProf__ohe_CommunicationTools_Con...  3.126329e+07\n",
       "41  te_YearsCodingProf__ohe_EducationTypes_Contrib...  2.572849e+07\n",
       "42             te_YearsCodingProf__CareerSatisfaction  2.471949e+07\n",
       "43                te_FormalEducation__YearsCodingProf  2.366002e+07\n",
       "44                    te_CompanySize__OperatingSystem  2.268757e+07\n",
       "45          te_YearsCodingProf__ohe_Methodology_Agile  2.267516e+07\n",
       "46                     te_YearsCodingProf__Dependents  2.024592e+07\n",
       "47                    te_YearsCoding__YearsCodingProf  1.979352e+07\n",
       "48                   te_Currency__ohe_DevType_Student  1.840801e+07\n",
       "49                          te_Employment__SalaryType  1.838042e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, output_list, oof_score = train(train_df, test_df, use_cols, fold_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232a21ae53524216bea3718c19acdb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict(test_df, output_list, oof_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
