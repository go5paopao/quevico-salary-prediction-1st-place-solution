{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df):\n",
    "    \n",
    "    ###########################\n",
    "    # Functions of preprocess\n",
    "    ###########################\n",
    "    def get_multi_cat_cols(train_df):\n",
    "        tmp = train_df.iloc[:1000]\n",
    "        multi_cols = []\n",
    "        for c in train_df.columns:\n",
    "            sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "            if sep_num > 10:\n",
    "                multi_cols.append(c)\n",
    "        return multi_cols\n",
    "\n",
    "    def add_rank_feature(df):\n",
    "        rank_prefix_list = [\n",
    "            \"AssessBenefits\",\n",
    "            \"AssessJob\",\n",
    "            \"JobContactPriorities\",\n",
    "            \"JobEmailPriorities\",\n",
    "            \"AdsPriorities\",\n",
    "        ]\n",
    "        for prefix in tqdm(rank_prefix_list):\n",
    "            rank_cols = [c for c in df.columns if prefix in c]\n",
    "            col_pairs = itertools.combinations(rank_cols, 2)\n",
    "            for col_a, col_b in col_pairs:\n",
    "                df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "        return df\n",
    "\n",
    "    def get_basic_importance_cols(use_num=50):\n",
    "        # basicなモデルのimportanceを読み込み\n",
    "        importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "        imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "        return imp_feats\n",
    "\n",
    "    def make_agg_feature(train_df, test_df):\n",
    "        imp_feats = get_basic_importance_cols(use_num=50)\n",
    "        imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "        imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "        print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "        #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "        all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "        for cat_col in tqdm(imp_cat_cols):\n",
    "            for nume_col in imp_nume_cols:\n",
    "                # one-hotは同じカテゴリの場合がある\n",
    "                if cat_col == nume_col:\n",
    "                    continue\n",
    "                all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "                all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "                all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "                all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "                all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "                all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "        train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "        test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        del all_df\n",
    "        gc.collect()\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=False)\n",
    "    def target_encoding(train_df, test_df):\n",
    "        te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "        for c in tqdm(te_cols):\n",
    "            new_col = \"te_\" + c\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=False)\n",
    "    def multiple_target_encoding(train_df, test_df):\n",
    "         # multiple target encoding\n",
    "        multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "        imp_feats = get_basic_importance_cols(use_num=30)\n",
    "        multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "        combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "        for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "            new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "            test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].mean().astype(np.float32)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val)\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "            del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "            gc.collect()\n",
    "        return train_df, test_df   \n",
    "    \n",
    "    ################################\n",
    "    # Columns infomation\n",
    "    ################################\n",
    "    original_cols = train_df.columns.tolist()\n",
    "    multi_cat_cols = get_multi_cat_cols(train_df)\n",
    "\n",
    "    nume_cols = [\n",
    "        c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "        if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "    ]\n",
    "\n",
    "    cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]\n",
    "\n",
    "    non_basic_nume_cols = []\n",
    "    non_basic_cat_cols = []\n",
    "\n",
    "    ################################\n",
    "    #  Make feature\n",
    "    ################################    \n",
    "    \n",
    "    # rank feature\n",
    "    train_df = add_rank_feature(train_df)\n",
    "    test_df = add_rank_feature(test_df)\n",
    "\n",
    "    # multi -category encoding \n",
    "    for c in tqdm(multi_cat_cols):\n",
    "        binarizer = MultiLabelBinarizer()\n",
    "        train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "        test_arr = binarizer.transform(test_multi_srs)\n",
    "        feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "        train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "        test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "        all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "        train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "        test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "        # ohe_featureはcategoryとnumerical両方として扱う\n",
    "        nume_cols += feat_cols\n",
    "        cat_cols += feat_cols\n",
    "        # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "        # SVD\n",
    "        svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "        all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "        train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "        test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # simple category encoding\n",
    "    for c in cat_cols:\n",
    "        train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "        test_df[c] = uniques.get_indexer(test_df[c])\n",
    "    \n",
    "    # reduce memory\n",
    "    # numerical cols\n",
    "    for c in nume_cols:\n",
    "        if train_df[c].nunique() > 1000:\n",
    "            train_df[c] = train_df[c].astype(np.float32)\n",
    "            test_df[c] = test_df[c].astype(np.float32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.float16)\n",
    "            test_df[c] = test_df[c].astype(np.float16)\n",
    "    # category cols\n",
    "    for c in cat_cols:\n",
    "        if train_df[c].max() > 32767:\n",
    "            train_df[c] = train_df[c].astype(np.int32)\n",
    "            test_df[c] = test_df[c].astype(np.int32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.int16)\n",
    "            test_df[c] = test_df[c].astype(np.int16)\n",
    "    \n",
    "    # change columns name\n",
    "    train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "    test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "   \n",
    "    # aggregate feature\n",
    "    train_df, test_df = make_agg_feature(train_df, test_df)\n",
    "\n",
    "    # make train/validation index list for target encoding\n",
    "    folds = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"Salary\"])]\n",
    "    \n",
    "    # target encoding\n",
    "    train_df, test_df = target_encoding(train_df, test_df)\n",
    "\n",
    "    # multiple category target encoding \n",
    "    train_df, test_df = multiple_target_encoding(train_df, test_df)\n",
    "    \n",
    "    # make use columns list\n",
    "    use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\"]]\n",
    "    print(len(use_cols))\n",
    "    \n",
    "    return train_df, test_df, use_cols, fold_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, use_cols, fold_idx_list):\n",
    "\n",
    "    lgb_params = {\n",
    "                'objective': 'poisson',\n",
    "                \"metric\": \"rmse\",\n",
    "                \"verbosity\": -1,\n",
    "                \"boosting\": \"gbdt\",\n",
    "                'learning_rate': 0.01,\n",
    "                'num_leaves': 64,\n",
    "                'min_data_in_leaf': 80, \n",
    "                'max_depth': 4,\n",
    "                \"bagging_freq\": 5,\n",
    "                \"bagging_fraction\": 0.8,\n",
    "                \"lambda_l1\": 0.5,\n",
    "                \"lambda_l2\": 0.5,\n",
    "                \"feature_fraction\": 0.1,\n",
    "                \"seed\": 2020,\n",
    "                \"num_threads\": -1,\n",
    "                \"max_bins\": 30\n",
    "    }\n",
    "    def feature_selection(train_df, use_cols, n_features=1000):\n",
    "        df = train_df.sample(30000, random_state=2020)\n",
    "        train_dataset = lgb.Dataset(\n",
    "            df.loc[:, use_cols],\n",
    "            label = df.loc[:, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    2000,\n",
    "                    valid_sets = [train_dataset],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds = None,\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "        return select_features\n",
    "    \n",
    "    importances = pd.DataFrame()\n",
    "    oof_preds = np.zeros(len(train_df))\n",
    "    models = []\n",
    "\n",
    "    # use_cols = feature_selection(train_df, use_cols, n_features=1000)\n",
    "\n",
    "    for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "        print(f\"Fold {fold_i+1}\")\n",
    "        train_dataset = lgb.Dataset(\n",
    "            train_df.loc[trn_idx, use_cols],\n",
    "            label = train_df.loc[trn_idx, \"Salary\"]\n",
    "        )\n",
    "        valid_dataset = lgb.Dataset(\n",
    "            train_df.loc[val_idx, use_cols],\n",
    "            label = train_df.loc[val_idx, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    30000,\n",
    "                    valid_sets = [train_dataset, valid_dataset],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 500,\n",
    "                    #feval = eval_f1,\n",
    "                    #callbacks = [log_callback],\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])\n",
    "        models.append(model)\n",
    "\n",
    "    oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "    print(f\"OOF Score: {oof_score}\")\n",
    "    \n",
    "    display(\n",
    "        importances.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:50]\n",
    "    )\n",
    "\n",
    "    return train_df, test_df, models, oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, models, use_cols, oof_score):\n",
    "    test_pred = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        test_pred += model.predict(test_df[use_cols]) / len(models)\n",
    "    sub_df = pd.read_csv(\"../input/submit.csv\")\n",
    "    sub_df[\"Salary\"] = test_pred\n",
    "    sub_df.to_csv(f\"../predict/{model_title}_{oof_score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = \"038_lr001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dc68e279bd4cdeacbb0253c0335dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8008ed48ea41e5b2770a2f24502695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a4c27c0e6746b4ba1cba35a5149608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3398870304ab479db5668c1ac6231d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2495\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, use_cols, fold_idx_list = preprocess(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22706.1\tvalid_1's rmse: 23002.4\n",
      "[1000]\ttraining's rmse: 20850.6\tvalid_1's rmse: 21581.6\n",
      "[1500]\ttraining's rmse: 20076.2\tvalid_1's rmse: 21142.8\n",
      "[2000]\ttraining's rmse: 19592.4\tvalid_1's rmse: 20929.1\n",
      "[2500]\ttraining's rmse: 19222.7\tvalid_1's rmse: 20788.7\n",
      "[3000]\ttraining's rmse: 18912.2\tvalid_1's rmse: 20688.6\n",
      "[3500]\ttraining's rmse: 18650.1\tvalid_1's rmse: 20616.3\n",
      "[4000]\ttraining's rmse: 18403.6\tvalid_1's rmse: 20561\n",
      "[4500]\ttraining's rmse: 18173.1\tvalid_1's rmse: 20509\n",
      "[5000]\ttraining's rmse: 17956.7\tvalid_1's rmse: 20464.6\n",
      "[5500]\ttraining's rmse: 17753.7\tvalid_1's rmse: 20434.8\n",
      "[6000]\ttraining's rmse: 17567.4\tvalid_1's rmse: 20413.2\n",
      "[6500]\ttraining's rmse: 17393\tvalid_1's rmse: 20388.7\n",
      "[7000]\ttraining's rmse: 17214.5\tvalid_1's rmse: 20364.4\n",
      "[7500]\ttraining's rmse: 17052.9\tvalid_1's rmse: 20349.5\n",
      "[8000]\ttraining's rmse: 16884.8\tvalid_1's rmse: 20333.2\n",
      "[8500]\ttraining's rmse: 16721.9\tvalid_1's rmse: 20316.3\n",
      "[9000]\ttraining's rmse: 16563.6\tvalid_1's rmse: 20300.9\n",
      "[9500]\ttraining's rmse: 16409.5\tvalid_1's rmse: 20289\n",
      "[10000]\ttraining's rmse: 16263.4\tvalid_1's rmse: 20279.3\n",
      "[10500]\ttraining's rmse: 16112.3\tvalid_1's rmse: 20270.7\n",
      "[11000]\ttraining's rmse: 15967.2\tvalid_1's rmse: 20258.3\n",
      "[11500]\ttraining's rmse: 15828.2\tvalid_1's rmse: 20250.6\n",
      "[12000]\ttraining's rmse: 15682.6\tvalid_1's rmse: 20242.9\n",
      "[12500]\ttraining's rmse: 15541.7\tvalid_1's rmse: 20238.9\n",
      "[13000]\ttraining's rmse: 15410.3\tvalid_1's rmse: 20234.9\n",
      "[13500]\ttraining's rmse: 15273.5\tvalid_1's rmse: 20233.8\n",
      "[14000]\ttraining's rmse: 15139.7\tvalid_1's rmse: 20226\n",
      "[14500]\ttraining's rmse: 15004.5\tvalid_1's rmse: 20219.2\n",
      "[15000]\ttraining's rmse: 14879.4\tvalid_1's rmse: 20216.3\n",
      "[15500]\ttraining's rmse: 14749.2\tvalid_1's rmse: 20210.9\n",
      "[16000]\ttraining's rmse: 14618.2\tvalid_1's rmse: 20206.3\n",
      "[16500]\ttraining's rmse: 14499\tvalid_1's rmse: 20203.5\n",
      "[17000]\ttraining's rmse: 14372.3\tvalid_1's rmse: 20202.6\n",
      "Early stopping, best iteration is:\n",
      "[16703]\ttraining's rmse: 14448.3\tvalid_1's rmse: 20200.6\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22657.8\tvalid_1's rmse: 23252.9\n",
      "[1000]\ttraining's rmse: 20853.9\tvalid_1's rmse: 21708.7\n",
      "[1500]\ttraining's rmse: 20099.6\tvalid_1's rmse: 21183.3\n",
      "[2000]\ttraining's rmse: 19619.6\tvalid_1's rmse: 20928.2\n",
      "[2500]\ttraining's rmse: 19249.6\tvalid_1's rmse: 20772.7\n",
      "[3000]\ttraining's rmse: 18952.3\tvalid_1's rmse: 20668.4\n",
      "[3500]\ttraining's rmse: 18697.6\tvalid_1's rmse: 20589.2\n",
      "[4000]\ttraining's rmse: 18461.4\tvalid_1's rmse: 20516.8\n",
      "[4500]\ttraining's rmse: 18245.5\tvalid_1's rmse: 20460.4\n",
      "[5000]\ttraining's rmse: 18041.7\tvalid_1's rmse: 20416.7\n",
      "[5500]\ttraining's rmse: 17853.9\tvalid_1's rmse: 20377.8\n",
      "[6000]\ttraining's rmse: 17669.8\tvalid_1's rmse: 20341.9\n",
      "[6500]\ttraining's rmse: 17496.1\tvalid_1's rmse: 20315.8\n",
      "[7000]\ttraining's rmse: 17319\tvalid_1's rmse: 20289.6\n",
      "[7500]\ttraining's rmse: 17149.8\tvalid_1's rmse: 20267\n",
      "[8000]\ttraining's rmse: 16990.2\tvalid_1's rmse: 20242.4\n",
      "[8500]\ttraining's rmse: 16824.9\tvalid_1's rmse: 20222\n",
      "[9000]\ttraining's rmse: 16667.7\tvalid_1's rmse: 20201.8\n",
      "[9500]\ttraining's rmse: 16520.5\tvalid_1's rmse: 20186.8\n",
      "[10000]\ttraining's rmse: 16368.8\tvalid_1's rmse: 20172.4\n",
      "[10500]\ttraining's rmse: 16218.6\tvalid_1's rmse: 20158.7\n",
      "[11000]\ttraining's rmse: 16069.2\tvalid_1's rmse: 20146.8\n",
      "[11500]\ttraining's rmse: 15925.4\tvalid_1's rmse: 20136.3\n",
      "[12000]\ttraining's rmse: 15785.9\tvalid_1's rmse: 20124.8\n",
      "[12500]\ttraining's rmse: 15643.9\tvalid_1's rmse: 20117.1\n",
      "[13000]\ttraining's rmse: 15507.9\tvalid_1's rmse: 20110.8\n",
      "[13500]\ttraining's rmse: 15371.3\tvalid_1's rmse: 20104.8\n",
      "[14000]\ttraining's rmse: 15237.4\tvalid_1's rmse: 20097.9\n",
      "[14500]\ttraining's rmse: 15104.4\tvalid_1's rmse: 20092.2\n",
      "[15000]\ttraining's rmse: 14973.6\tvalid_1's rmse: 20085.7\n",
      "[15500]\ttraining's rmse: 14845.5\tvalid_1's rmse: 20082.6\n",
      "[16000]\ttraining's rmse: 14717.2\tvalid_1's rmse: 20080.9\n",
      "[16500]\ttraining's rmse: 14596.8\tvalid_1's rmse: 20077\n",
      "[17000]\ttraining's rmse: 14471.3\tvalid_1's rmse: 20071.3\n",
      "[17500]\ttraining's rmse: 14349.3\tvalid_1's rmse: 20065.4\n",
      "[18000]\ttraining's rmse: 14227\tvalid_1's rmse: 20062.1\n",
      "[18500]\ttraining's rmse: 14107.8\tvalid_1's rmse: 20057.9\n",
      "[19000]\ttraining's rmse: 13992\tvalid_1's rmse: 20058.8\n",
      "Early stopping, best iteration is:\n",
      "[18752]\ttraining's rmse: 14047.2\tvalid_1's rmse: 20056.2\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22710.2\tvalid_1's rmse: 23069.4\n",
      "[1000]\ttraining's rmse: 20838.7\tvalid_1's rmse: 21552.9\n",
      "[1500]\ttraining's rmse: 20064.5\tvalid_1's rmse: 21122.8\n",
      "[2000]\ttraining's rmse: 19581.4\tvalid_1's rmse: 20921.3\n",
      "[2500]\ttraining's rmse: 19213.1\tvalid_1's rmse: 20802.1\n",
      "[3000]\ttraining's rmse: 18913.8\tvalid_1's rmse: 20716.3\n",
      "[3500]\ttraining's rmse: 18652.7\tvalid_1's rmse: 20654.1\n",
      "[4000]\ttraining's rmse: 18422\tvalid_1's rmse: 20607\n",
      "[4500]\ttraining's rmse: 18210.9\tvalid_1's rmse: 20572.6\n",
      "[5000]\ttraining's rmse: 18006.8\tvalid_1's rmse: 20537.4\n",
      "[5500]\ttraining's rmse: 17813.6\tvalid_1's rmse: 20511.8\n",
      "[6000]\ttraining's rmse: 17629.4\tvalid_1's rmse: 20487\n",
      "[6500]\ttraining's rmse: 17447.9\tvalid_1's rmse: 20461.6\n",
      "[7000]\ttraining's rmse: 17274.5\tvalid_1's rmse: 20447.8\n",
      "[7500]\ttraining's rmse: 17104.2\tvalid_1's rmse: 20426.2\n",
      "[8000]\ttraining's rmse: 16939.2\tvalid_1's rmse: 20410.1\n",
      "[8500]\ttraining's rmse: 16781.3\tvalid_1's rmse: 20398.6\n",
      "[9000]\ttraining's rmse: 16620.6\tvalid_1's rmse: 20386.9\n",
      "[9500]\ttraining's rmse: 16466\tvalid_1's rmse: 20378.1\n",
      "[10000]\ttraining's rmse: 16316\tvalid_1's rmse: 20374\n",
      "[10500]\ttraining's rmse: 16173.4\tvalid_1's rmse: 20369.8\n",
      "[11000]\ttraining's rmse: 16027.2\tvalid_1's rmse: 20365.8\n",
      "[11500]\ttraining's rmse: 15887.3\tvalid_1's rmse: 20363.5\n",
      "[12000]\ttraining's rmse: 15746.2\tvalid_1's rmse: 20360.1\n",
      "[12500]\ttraining's rmse: 15615\tvalid_1's rmse: 20358.8\n",
      "[13000]\ttraining's rmse: 15477.1\tvalid_1's rmse: 20358\n",
      "Early stopping, best iteration is:\n",
      "[12661]\ttraining's rmse: 15570\tvalid_1's rmse: 20355.5\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22677.1\tvalid_1's rmse: 23071.1\n",
      "[1000]\ttraining's rmse: 20846.2\tvalid_1's rmse: 21621.7\n",
      "[1500]\ttraining's rmse: 20076\tvalid_1's rmse: 21177.4\n",
      "[2000]\ttraining's rmse: 19598.1\tvalid_1's rmse: 20955.2\n",
      "[2500]\ttraining's rmse: 19236.6\tvalid_1's rmse: 20814.9\n",
      "[3000]\ttraining's rmse: 18943.4\tvalid_1's rmse: 20714.1\n",
      "[3500]\ttraining's rmse: 18686.3\tvalid_1's rmse: 20633.7\n",
      "[4000]\ttraining's rmse: 18447.5\tvalid_1's rmse: 20564.1\n",
      "[4500]\ttraining's rmse: 18232.6\tvalid_1's rmse: 20507.8\n",
      "[5000]\ttraining's rmse: 18034.9\tvalid_1's rmse: 20464.9\n",
      "[5500]\ttraining's rmse: 17840\tvalid_1's rmse: 20420.9\n",
      "[6000]\ttraining's rmse: 17657.9\tvalid_1's rmse: 20388\n",
      "[6500]\ttraining's rmse: 17480.5\tvalid_1's rmse: 20356.8\n",
      "[7000]\ttraining's rmse: 17310.2\tvalid_1's rmse: 20326.6\n",
      "[7500]\ttraining's rmse: 17142.8\tvalid_1's rmse: 20302.3\n",
      "[8000]\ttraining's rmse: 16979.9\tvalid_1's rmse: 20282.1\n",
      "[8500]\ttraining's rmse: 16820.9\tvalid_1's rmse: 20267\n",
      "[9000]\ttraining's rmse: 16669.3\tvalid_1's rmse: 20243.8\n",
      "[9500]\ttraining's rmse: 16516.3\tvalid_1's rmse: 20227\n",
      "[10000]\ttraining's rmse: 16360.2\tvalid_1's rmse: 20215\n",
      "[10500]\ttraining's rmse: 16218\tvalid_1's rmse: 20203.4\n",
      "[11000]\ttraining's rmse: 16070.7\tvalid_1's rmse: 20191.6\n",
      "[11500]\ttraining's rmse: 15937.1\tvalid_1's rmse: 20182.8\n",
      "[12000]\ttraining's rmse: 15796.4\tvalid_1's rmse: 20175.2\n",
      "[12500]\ttraining's rmse: 15654.2\tvalid_1's rmse: 20164.6\n",
      "[13000]\ttraining's rmse: 15512\tvalid_1's rmse: 20157.3\n",
      "[13500]\ttraining's rmse: 15377\tvalid_1's rmse: 20144.6\n",
      "[14000]\ttraining's rmse: 15243.6\tvalid_1's rmse: 20138.7\n",
      "[14500]\ttraining's rmse: 15112.6\tvalid_1's rmse: 20135.2\n",
      "[15000]\ttraining's rmse: 14983.1\tvalid_1's rmse: 20132.8\n",
      "[15500]\ttraining's rmse: 14856.7\tvalid_1's rmse: 20127.3\n",
      "[16000]\ttraining's rmse: 14730.5\tvalid_1's rmse: 20120.6\n",
      "[16500]\ttraining's rmse: 14602.5\tvalid_1's rmse: 20118.4\n",
      "[17000]\ttraining's rmse: 14478.5\tvalid_1's rmse: 20113\n",
      "[17500]\ttraining's rmse: 14353.9\tvalid_1's rmse: 20106.4\n",
      "[18000]\ttraining's rmse: 14235.5\tvalid_1's rmse: 20104.3\n",
      "[18500]\ttraining's rmse: 14116.7\tvalid_1's rmse: 20101.5\n",
      "Early stopping, best iteration is:\n",
      "[18457]\ttraining's rmse: 14127\tvalid_1's rmse: 20100.7\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22731.2\tvalid_1's rmse: 23037.3\n",
      "[1000]\ttraining's rmse: 20930.4\tvalid_1's rmse: 21398.7\n",
      "[1500]\ttraining's rmse: 20164.4\tvalid_1's rmse: 20871.2\n",
      "[2000]\ttraining's rmse: 19676.7\tvalid_1's rmse: 20611.9\n",
      "[2500]\ttraining's rmse: 19311.8\tvalid_1's rmse: 20457.6\n",
      "[3000]\ttraining's rmse: 19003.9\tvalid_1's rmse: 20349.2\n",
      "[3500]\ttraining's rmse: 18737.7\tvalid_1's rmse: 20273.3\n",
      "[4000]\ttraining's rmse: 18499.3\tvalid_1's rmse: 20206\n",
      "[4500]\ttraining's rmse: 18285.4\tvalid_1's rmse: 20158.4\n",
      "[5000]\ttraining's rmse: 18081\tvalid_1's rmse: 20122.7\n",
      "[5500]\ttraining's rmse: 17897.8\tvalid_1's rmse: 20093\n",
      "[6000]\ttraining's rmse: 17721.7\tvalid_1's rmse: 20067.6\n",
      "[6500]\ttraining's rmse: 17547\tvalid_1's rmse: 20039.1\n",
      "[7000]\ttraining's rmse: 17380.1\tvalid_1's rmse: 20018.8\n",
      "[7500]\ttraining's rmse: 17210.4\tvalid_1's rmse: 20002.3\n",
      "[8000]\ttraining's rmse: 17047.3\tvalid_1's rmse: 19984.7\n",
      "[8500]\ttraining's rmse: 16890.9\tvalid_1's rmse: 19972.8\n",
      "[9000]\ttraining's rmse: 16738.6\tvalid_1's rmse: 19960.8\n",
      "[9500]\ttraining's rmse: 16593\tvalid_1's rmse: 19949.6\n",
      "[10000]\ttraining's rmse: 16440.5\tvalid_1's rmse: 19940.6\n",
      "[10500]\ttraining's rmse: 16294.4\tvalid_1's rmse: 19932.3\n",
      "[11000]\ttraining's rmse: 16151.6\tvalid_1's rmse: 19922.9\n",
      "[11500]\ttraining's rmse: 16008.5\tvalid_1's rmse: 19914.8\n",
      "[12000]\ttraining's rmse: 15869.1\tvalid_1's rmse: 19906\n",
      "[12500]\ttraining's rmse: 15734\tvalid_1's rmse: 19899.7\n",
      "[13000]\ttraining's rmse: 15600.2\tvalid_1's rmse: 19895.7\n",
      "[13500]\ttraining's rmse: 15463.9\tvalid_1's rmse: 19892.9\n",
      "[14000]\ttraining's rmse: 15329.7\tvalid_1's rmse: 19887.7\n",
      "[14500]\ttraining's rmse: 15201.1\tvalid_1's rmse: 19883.5\n",
      "[15000]\ttraining's rmse: 15070.4\tvalid_1's rmse: 19879.2\n",
      "[15500]\ttraining's rmse: 14938.9\tvalid_1's rmse: 19878.3\n",
      "Early stopping, best iteration is:\n",
      "[15425]\ttraining's rmse: 14957.9\tvalid_1's rmse: 19877.5\n",
      "OOF Score: 20118.729705391474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_Country__YearsCodingProf</td>\n",
       "      <td>2.499778e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_Country__Employment</td>\n",
       "      <td>1.968762e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_Country__Age</td>\n",
       "      <td>1.664930e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_Country__SalaryType</td>\n",
       "      <td>1.664380e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_Country__YearsCoding</td>\n",
       "      <td>1.629975e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te_Country__ohe_DevType_Student</td>\n",
       "      <td>1.583906e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>te_YearsCodingProf__CurrencySymbol</td>\n",
       "      <td>1.098677e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>te_Country__FormalEducation</td>\n",
       "      <td>8.783559e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te_Country__ohe_Methodology_Agile</td>\n",
       "      <td>8.111965e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>te_SalaryType__CurrencySymbol</td>\n",
       "      <td>7.573665e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>te_Country__ohe_EducationTypes_Contributed_to_...</td>\n",
       "      <td>7.111347e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>te_YearsCodingProf__Currency</td>\n",
       "      <td>6.418571e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>te_Country__Dependents</td>\n",
       "      <td>5.125450e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>te_Country__CareerSatisfaction</td>\n",
       "      <td>4.919318e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>te_Country__CompanySize</td>\n",
       "      <td>4.692761e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>te_Employment__CurrencySymbol</td>\n",
       "      <td>4.360668e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>te_Country__ohe_DevType_Engineering_manager</td>\n",
       "      <td>3.900561e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>te_YearsCoding__CurrencySymbol</td>\n",
       "      <td>3.637284e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>te_Country__ohe_CommunicationTools_Confluence</td>\n",
       "      <td>3.572228e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te_Country__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>3.327914e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>te_YearsCodingProf__OperatingSystem</td>\n",
       "      <td>3.090897e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>te_CompanySize__YearsCodingProf</td>\n",
       "      <td>2.893326e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>te_CurrencySymbol__Age</td>\n",
       "      <td>2.573028e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>te_YearsCodingProf__SalaryType</td>\n",
       "      <td>2.337685e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>te_YearsCodingProf__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>2.248358e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>te_Currency__Age</td>\n",
       "      <td>2.086071e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>te_CurrencySymbol__ohe_DevType_Student</td>\n",
       "      <td>2.030472e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>te_Employment__YearsCodingProf</td>\n",
       "      <td>2.024140e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>te_YearsCodingProf__ohe_CommunicationTools_Con...</td>\n",
       "      <td>1.961397e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>te_YearsCodingProf__ohe_RaceEthnicity_White_or...</td>\n",
       "      <td>1.948706e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>te_Country__Currency</td>\n",
       "      <td>1.908138e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>te_YearsCodingProf__MilitaryUS</td>\n",
       "      <td>1.874029e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>te_Country__CurrencySymbol</td>\n",
       "      <td>1.845942e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>te_YearsCoding__Currency</td>\n",
       "      <td>1.835986e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>te_Country__ohe_RaceEthnicity_White_or_of_Euro...</td>\n",
       "      <td>1.827277e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>te_SalaryType__Age</td>\n",
       "      <td>1.800764e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>te_FormalEducation__YearsCodingProf</td>\n",
       "      <td>1.791099e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>te_YearsCodingProf__CareerSatisfaction</td>\n",
       "      <td>1.761777e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>te_Currency__SalaryType</td>\n",
       "      <td>1.728458e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te_YearsCodingProf__ohe_DevType_Student</td>\n",
       "      <td>1.572374e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>te_YearsCodingProf__ohe_EducationTypes_Contrib...</td>\n",
       "      <td>1.464544e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>te_Employment__Currency</td>\n",
       "      <td>1.400124e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>te_Country__MilitaryUS</td>\n",
       "      <td>1.364808e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>te_Country</td>\n",
       "      <td>1.350391e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>te_Country__OperatingSystem</td>\n",
       "      <td>1.285699e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>te_YearsCodingProf__ohe_Methodology_Agile</td>\n",
       "      <td>1.036007e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>te_Employment__SalaryType</td>\n",
       "      <td>1.035424e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>te_YearsCoding__SalaryType</td>\n",
       "      <td>1.031033e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>te_CompanySize__OperatingSystem</td>\n",
       "      <td>9.762294e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>te_Age__MilitaryUS</td>\n",
       "      <td>9.410072e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature          gain\n",
       "0                         te_Country__YearsCodingProf  2.499778e+09\n",
       "1                              te_Country__Employment  1.968762e+09\n",
       "2                                     te_Country__Age  1.664930e+09\n",
       "3                              te_Country__SalaryType  1.664380e+09\n",
       "4                             te_Country__YearsCoding  1.629975e+09\n",
       "5                     te_Country__ohe_DevType_Student  1.583906e+09\n",
       "6                  te_YearsCodingProf__CurrencySymbol  1.098677e+09\n",
       "7                         te_Country__FormalEducation  8.783559e+08\n",
       "8                   te_Country__ohe_Methodology_Agile  8.111965e+08\n",
       "9                       te_SalaryType__CurrencySymbol  7.573665e+08\n",
       "10  te_Country__ohe_EducationTypes_Contributed_to_...  7.111347e+08\n",
       "11                       te_YearsCodingProf__Currency  6.418571e+08\n",
       "12                             te_Country__Dependents  5.125450e+08\n",
       "13                     te_Country__CareerSatisfaction  4.919318e+08\n",
       "14                            te_Country__CompanySize  4.692761e+08\n",
       "15                      te_Employment__CurrencySymbol  4.360668e+08\n",
       "16        te_Country__ohe_DevType_Engineering_manager  3.900561e+08\n",
       "17                     te_YearsCoding__CurrencySymbol  3.637284e+08\n",
       "18      te_Country__ohe_CommunicationTools_Confluence  3.572228e+08\n",
       "19             te_Country__ohe_LanguageWorkedWith_PHP  3.327914e+08\n",
       "20                te_YearsCodingProf__OperatingSystem  3.090897e+08\n",
       "21                    te_CompanySize__YearsCodingProf  2.893326e+08\n",
       "22                             te_CurrencySymbol__Age  2.573028e+08\n",
       "23                     te_YearsCodingProf__SalaryType  2.337685e+08\n",
       "24     te_YearsCodingProf__ohe_LanguageWorkedWith_PHP  2.248358e+08\n",
       "25                                   te_Currency__Age  2.086071e+08\n",
       "26             te_CurrencySymbol__ohe_DevType_Student  2.030472e+08\n",
       "27                     te_Employment__YearsCodingProf  2.024140e+08\n",
       "28  te_YearsCodingProf__ohe_CommunicationTools_Con...  1.961397e+08\n",
       "29  te_YearsCodingProf__ohe_RaceEthnicity_White_or...  1.948706e+08\n",
       "30                               te_Country__Currency  1.908138e+08\n",
       "31                     te_YearsCodingProf__MilitaryUS  1.874029e+08\n",
       "32                         te_Country__CurrencySymbol  1.845942e+08\n",
       "33                           te_YearsCoding__Currency  1.835986e+08\n",
       "34  te_Country__ohe_RaceEthnicity_White_or_of_Euro...  1.827277e+08\n",
       "35                                 te_SalaryType__Age  1.800764e+08\n",
       "36                te_FormalEducation__YearsCodingProf  1.791099e+08\n",
       "37             te_YearsCodingProf__CareerSatisfaction  1.761777e+08\n",
       "38                            te_Currency__SalaryType  1.728458e+08\n",
       "39            te_YearsCodingProf__ohe_DevType_Student  1.572374e+08\n",
       "40  te_YearsCodingProf__ohe_EducationTypes_Contrib...  1.464544e+08\n",
       "41                            te_Employment__Currency  1.400124e+08\n",
       "42                             te_Country__MilitaryUS  1.364808e+08\n",
       "43                                         te_Country  1.350391e+08\n",
       "44                        te_Country__OperatingSystem  1.285699e+08\n",
       "45          te_YearsCodingProf__ohe_Methodology_Agile  1.036007e+08\n",
       "46                          te_Employment__SalaryType  1.035424e+08\n",
       "47                         te_YearsCoding__SalaryType  1.031033e+08\n",
       "48                    te_CompanySize__OperatingSystem  9.762294e+07\n",
       "49                                 te_Age__MilitaryUS  9.410072e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, models, oof_score = train(train_df, test_df, use_cols, fold_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_df, models, use_cols, oof_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
