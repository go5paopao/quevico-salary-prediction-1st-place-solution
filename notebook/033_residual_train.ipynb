{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_cat_cols(train_df):\n",
    "    tmp = train_df.iloc[:1000]\n",
    "    multi_cols = []\n",
    "    for c in train_df.columns:\n",
    "        sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "        if sep_num > 10:\n",
    "            multi_cols.append(c)\n",
    "    return multi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cols = train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cat_cols = get_multi_cat_cols(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nume_cols = [\n",
    "    c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "    if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_basic_nume_cols = []\n",
    "non_basic_cat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 65, 40, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_cols), len(cat_cols), len(nume_cols), len(multi_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_feature(df):\n",
    "    df[\"ohe_main_cluster\"] = 1\n",
    "    df.loc[(df.DevType.fillna(\"\").str.contains(\"Student\"))\n",
    "                | (df.SalaryType != \"Yearly\")\n",
    "                | (df[\"Age\"] == \"Under 18 years old\")\n",
    "                | (df[\"CurrencySymbol\"] == \"INR\"),\n",
    "           \"ohe_main_cluster\"\n",
    "    ] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = hand_feature(train_df)\n",
    "test_df = hand_feature(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rank_feature(df):\n",
    "    rank_prefix_list = [\n",
    "        \"AssessBenefits\",\n",
    "        \"AssessJob\",\n",
    "        \"JobContactPriorities\",\n",
    "        \"JobEmailPriorities\",\n",
    "        \"AdsPriorities\",\n",
    "    ]\n",
    "    for prefix in tqdm(rank_prefix_list):\n",
    "        rank_cols = [c for c in df.columns if prefix in c]\n",
    "        col_pairs = itertools.combinations(rank_cols, 2)\n",
    "        for col_a, col_b in col_pairs:\n",
    "            df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7336542d7bc74fd9a99fa63dbc17f804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84c0f585b1f4acb8ca8efcdef7f5336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = add_rank_feature(train_df)\n",
    "test_df = add_rank_feature(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-category encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e5e96bc8e140f9922f576b478ecc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(multi_cat_cols):\n",
    "    binarizer = MultiLabelBinarizer()\n",
    "    train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "    test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "    train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "    test_arr = binarizer.transform(test_multi_srs)\n",
    "    feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "    train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "    test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "    all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "    train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "    test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "    train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "    test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "    # ohe_featureはcategoryとnumerical両方として扱う\n",
    "    nume_cols += feat_cols\n",
    "    cat_cols += feat_cols\n",
    "    # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "    all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "    train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "    test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple-category encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "    test_df[c] = uniques.get_indexer(test_df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce data memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in nume_cols:\n",
    "    if train_df[c].nunique() > 1000:\n",
    "        train_df[c] = train_df[c].astype(np.float32)\n",
    "        test_df[c] = test_df[c].astype(np.float32)\n",
    "    else:\n",
    "        train_df[c] = train_df[c].astype(np.float16)\n",
    "        test_df[c] = test_df[c].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    if train_df[c].max() > 32767:\n",
    "        train_df[c] = train_df[c].astype(np.int32)\n",
    "        test_df[c] = test_df[c].astype(np.int32)\n",
    "    else:\n",
    "        train_df[c] = train_df[c].astype(np.int16)\n",
    "        test_df[c] = test_df[c].astype(np.int16)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33857, 660), (11259, 659))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Category Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_importance_cols(use_num=50):\n",
    "    # basicなモデルのimportanceを読み込み\n",
    "    importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "    imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "    return imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agg_feature(train_df, test_df):\n",
    "    imp_feats = get_basic_importance_cols(use_num=50)\n",
    "    imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "    imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "    print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "    #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "    all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    for cat_col in tqdm(imp_cat_cols):\n",
    "        for nume_col in imp_nume_cols:\n",
    "            # one-hotは同じカテゴリの場合がある\n",
    "            if cat_col == nume_col:\n",
    "                continue\n",
    "            all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "            all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "            all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "            all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "            all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "            all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "    train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "    test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "    del all_df\n",
    "    gc.collect()\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473c5126e81f4c15b137eb932c1ca8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = make_agg_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make fold index(for target encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"Salary\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@feature_cache(reset=False)\n",
    "def target_encoding(train_df, test_df):\n",
    "    te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "    for c in tqdm(te_cols):\n",
    "        new_col = \"te_\" + c\n",
    "        train_df[new_col] = 0\n",
    "        test_df[new_col] = 0\n",
    "        for trn_idx, val_idx in fold_idx_list:\n",
    "            mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].mean().astype(np.float32)\n",
    "            train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val)\n",
    "            test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val) / len(fold_idx_list)\n",
    "        train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "        test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = target_encoding(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@feature_cache(reset=False)\n",
    "def multiple_target_encoding(train_df, test_df):\n",
    "     # multiple target encoding\n",
    "    multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "    imp_feats = get_basic_importance_cols(use_num=30)\n",
    "    multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "    combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "    for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "        new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "        train_df[new_col] = 0\n",
    "        test_df[new_col] = 0\n",
    "        train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "        test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "        for trn_idx, val_idx in fold_idx_list:\n",
    "            mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].mean().astype(np.float32)\n",
    "            train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val)\n",
    "            test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val) / len(fold_idx_list)\n",
    "        train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "        test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "        gc.collect()\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = multiple_target_encoding(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2495\n"
     ]
    }
   ],
   "source": [
    "use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\", \"ohe_main_cluster\"]]\n",
    "print(len(use_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "            'objective': 'poisson',\n",
    "            \"metric\": \"rmse\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            'learning_rate': 0.05,\n",
    "            'num_leaves': 64,\n",
    "            'min_data_in_leaf': 80, \n",
    "            'max_depth': 4,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"bagging_fraction\": 0.8,\n",
    "            \"lambda_l1\": 0.5,\n",
    "            \"lambda_l2\": 0.5,\n",
    "            \"feature_fraction\": 0.1,\n",
    "            \"seed\": 2020,\n",
    "            \"num_threads\": -1,\n",
    "            \"max_bins\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train_df, use_cols, n_features=1000):\n",
    "    df = train_df.sample(30000, random_state=2020)\n",
    "    train_dataset = lgb.Dataset(\n",
    "        df.loc[:, use_cols],\n",
    "        label = df.loc[:, \"Salary\"]\n",
    "    )\n",
    "    model = lgb.train(\n",
    "                lgb_params,\n",
    "                train_dataset,\n",
    "                2000,\n",
    "                valid_sets = [train_dataset],\n",
    "                verbose_eval=200,\n",
    "                early_stopping_rounds = None,\n",
    "    )\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = use_cols\n",
    "    imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "    select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "    return select_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22677.8\tvalid_1's rmse: 23007.5\n",
      "[200]\ttraining's rmse: 20867.3\tvalid_1's rmse: 21623.9\n",
      "[300]\ttraining's rmse: 20103.6\tvalid_1's rmse: 21190.2\n",
      "[400]\ttraining's rmse: 19618.8\tvalid_1's rmse: 20961.4\n",
      "[500]\ttraining's rmse: 19249.2\tvalid_1's rmse: 20820.9\n",
      "[600]\ttraining's rmse: 18941.4\tvalid_1's rmse: 20714.1\n",
      "[700]\ttraining's rmse: 18677.8\tvalid_1's rmse: 20657.4\n",
      "[800]\ttraining's rmse: 18438.6\tvalid_1's rmse: 20595.4\n",
      "[900]\ttraining's rmse: 18223.4\tvalid_1's rmse: 20539.8\n",
      "[1000]\ttraining's rmse: 18010.4\tvalid_1's rmse: 20497\n",
      "[1100]\ttraining's rmse: 17821.3\tvalid_1's rmse: 20457.8\n",
      "[1200]\ttraining's rmse: 17633.1\tvalid_1's rmse: 20418.4\n",
      "[1300]\ttraining's rmse: 17416.3\tvalid_1's rmse: 20393.9\n",
      "[1400]\ttraining's rmse: 17250.4\tvalid_1's rmse: 20368.4\n",
      "[1500]\ttraining's rmse: 17070.6\tvalid_1's rmse: 20349.8\n",
      "[1600]\ttraining's rmse: 16914.7\tvalid_1's rmse: 20334.7\n",
      "[1700]\ttraining's rmse: 16746.5\tvalid_1's rmse: 20322.1\n",
      "[1800]\ttraining's rmse: 16592.1\tvalid_1's rmse: 20318.9\n",
      "[1900]\ttraining's rmse: 16438.5\tvalid_1's rmse: 20306.7\n",
      "[2000]\ttraining's rmse: 16288.7\tvalid_1's rmse: 20294.1\n",
      "[2100]\ttraining's rmse: 16141.9\tvalid_1's rmse: 20278.8\n",
      "[2200]\ttraining's rmse: 16001\tvalid_1's rmse: 20268.9\n",
      "[2300]\ttraining's rmse: 15855.8\tvalid_1's rmse: 20252\n",
      "[2400]\ttraining's rmse: 15709.7\tvalid_1's rmse: 20248\n",
      "[2500]\ttraining's rmse: 15569.3\tvalid_1's rmse: 20242.6\n",
      "[2600]\ttraining's rmse: 15435.3\tvalid_1's rmse: 20234.4\n",
      "[2700]\ttraining's rmse: 15299.5\tvalid_1's rmse: 20226.3\n",
      "[2800]\ttraining's rmse: 15163.5\tvalid_1's rmse: 20224.7\n",
      "[2900]\ttraining's rmse: 15034.2\tvalid_1's rmse: 20223.3\n",
      "[3000]\ttraining's rmse: 14908.8\tvalid_1's rmse: 20219.9\n",
      "[3100]\ttraining's rmse: 14783.2\tvalid_1's rmse: 20222.6\n",
      "[3200]\ttraining's rmse: 14656.6\tvalid_1's rmse: 20220.3\n",
      "[3300]\ttraining's rmse: 14525.7\tvalid_1's rmse: 20208.6\n",
      "[3400]\ttraining's rmse: 14399.7\tvalid_1's rmse: 20209.4\n",
      "[3500]\ttraining's rmse: 14277.9\tvalid_1's rmse: 20215\n",
      "[3600]\ttraining's rmse: 14159.4\tvalid_1's rmse: 20218.2\n",
      "Early stopping, best iteration is:\n",
      "[3386]\ttraining's rmse: 14415.1\tvalid_1's rmse: 20206.8\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22636\tvalid_1's rmse: 23235.5\n",
      "[200]\ttraining's rmse: 20876.1\tvalid_1's rmse: 21733.8\n",
      "[300]\ttraining's rmse: 20117.8\tvalid_1's rmse: 21220.8\n",
      "[400]\ttraining's rmse: 19662.9\tvalid_1's rmse: 20974.7\n",
      "[500]\ttraining's rmse: 19287.2\tvalid_1's rmse: 20823.7\n",
      "[600]\ttraining's rmse: 18976.5\tvalid_1's rmse: 20724\n",
      "[700]\ttraining's rmse: 18703.6\tvalid_1's rmse: 20652\n",
      "[800]\ttraining's rmse: 18480.6\tvalid_1's rmse: 20581.6\n",
      "[900]\ttraining's rmse: 18271.7\tvalid_1's rmse: 20528.9\n",
      "[1000]\ttraining's rmse: 18069\tvalid_1's rmse: 20486.1\n",
      "[1100]\ttraining's rmse: 17866.8\tvalid_1's rmse: 20452.7\n",
      "[1200]\ttraining's rmse: 17682.4\tvalid_1's rmse: 20413\n",
      "[1300]\ttraining's rmse: 17509.4\tvalid_1's rmse: 20385.7\n",
      "[1400]\ttraining's rmse: 17340.5\tvalid_1's rmse: 20359.8\n",
      "[1500]\ttraining's rmse: 17189.8\tvalid_1's rmse: 20344\n",
      "[1600]\ttraining's rmse: 17007.7\tvalid_1's rmse: 20320\n",
      "[1700]\ttraining's rmse: 16846.4\tvalid_1's rmse: 20302.5\n",
      "[1800]\ttraining's rmse: 16696\tvalid_1's rmse: 20282.3\n",
      "[1900]\ttraining's rmse: 16545\tvalid_1's rmse: 20263.6\n",
      "[2000]\ttraining's rmse: 16394\tvalid_1's rmse: 20243.8\n",
      "[2100]\ttraining's rmse: 16244.9\tvalid_1's rmse: 20232.5\n",
      "[2200]\ttraining's rmse: 16108.7\tvalid_1's rmse: 20228.2\n",
      "[2300]\ttraining's rmse: 15968.6\tvalid_1's rmse: 20221.1\n",
      "[2400]\ttraining's rmse: 15827.8\tvalid_1's rmse: 20218.2\n",
      "[2500]\ttraining's rmse: 15681.9\tvalid_1's rmse: 20207.5\n",
      "[2600]\ttraining's rmse: 15540.4\tvalid_1's rmse: 20202.7\n",
      "[2700]\ttraining's rmse: 15401.7\tvalid_1's rmse: 20200.4\n",
      "[2800]\ttraining's rmse: 15277.8\tvalid_1's rmse: 20195.8\n",
      "[2900]\ttraining's rmse: 15137.1\tvalid_1's rmse: 20196.8\n",
      "[3000]\ttraining's rmse: 15009.5\tvalid_1's rmse: 20194.3\n",
      "[3100]\ttraining's rmse: 14877.1\tvalid_1's rmse: 20195\n",
      "[3200]\ttraining's rmse: 14749.9\tvalid_1's rmse: 20187.8\n",
      "[3300]\ttraining's rmse: 14617.9\tvalid_1's rmse: 20189.6\n",
      "[3400]\ttraining's rmse: 14491.3\tvalid_1's rmse: 20184.6\n",
      "[3500]\ttraining's rmse: 14364.3\tvalid_1's rmse: 20177.7\n",
      "[3600]\ttraining's rmse: 14235.8\tvalid_1's rmse: 20168.5\n",
      "[3700]\ttraining's rmse: 14120.3\tvalid_1's rmse: 20163.2\n",
      "[3800]\ttraining's rmse: 14007.9\tvalid_1's rmse: 20156.9\n",
      "[3900]\ttraining's rmse: 13890.4\tvalid_1's rmse: 20153.9\n",
      "[4000]\ttraining's rmse: 13767.2\tvalid_1's rmse: 20157.8\n",
      "[4100]\ttraining's rmse: 13653.8\tvalid_1's rmse: 20152.4\n",
      "[4200]\ttraining's rmse: 13554\tvalid_1's rmse: 20150.3\n",
      "[4300]\ttraining's rmse: 13436.6\tvalid_1's rmse: 20142.9\n",
      "[4400]\ttraining's rmse: 13325.6\tvalid_1's rmse: 20144.7\n",
      "[4500]\ttraining's rmse: 13209.9\tvalid_1's rmse: 20142.5\n",
      "Early stopping, best iteration is:\n",
      "[4276]\ttraining's rmse: 13467.3\tvalid_1's rmse: 20139.8\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22695.6\tvalid_1's rmse: 23075.1\n",
      "[200]\ttraining's rmse: 20863.5\tvalid_1's rmse: 21577.4\n",
      "[300]\ttraining's rmse: 20107.1\tvalid_1's rmse: 21152.3\n",
      "[400]\ttraining's rmse: 19609.7\tvalid_1's rmse: 20958.1\n",
      "[500]\ttraining's rmse: 19251.2\tvalid_1's rmse: 20841.6\n",
      "[600]\ttraining's rmse: 18954.7\tvalid_1's rmse: 20758.8\n",
      "[700]\ttraining's rmse: 18709.9\tvalid_1's rmse: 20722.3\n",
      "[800]\ttraining's rmse: 18479\tvalid_1's rmse: 20681.1\n",
      "[900]\ttraining's rmse: 18255.7\tvalid_1's rmse: 20640.6\n",
      "[1000]\ttraining's rmse: 18050.4\tvalid_1's rmse: 20617.2\n",
      "[1100]\ttraining's rmse: 17863.8\tvalid_1's rmse: 20585.6\n",
      "[1200]\ttraining's rmse: 17674\tvalid_1's rmse: 20561.8\n",
      "[1300]\ttraining's rmse: 17505.1\tvalid_1's rmse: 20549.8\n",
      "[1400]\ttraining's rmse: 17335.3\tvalid_1's rmse: 20534.1\n",
      "[1500]\ttraining's rmse: 17159.9\tvalid_1's rmse: 20512.9\n",
      "[1600]\ttraining's rmse: 17012.7\tvalid_1's rmse: 20494.4\n",
      "[1700]\ttraining's rmse: 16853.2\tvalid_1's rmse: 20485\n",
      "[1800]\ttraining's rmse: 16695.4\tvalid_1's rmse: 20481.3\n",
      "[1900]\ttraining's rmse: 16539.4\tvalid_1's rmse: 20466.8\n",
      "[2000]\ttraining's rmse: 16400.7\tvalid_1's rmse: 20463.9\n",
      "[2100]\ttraining's rmse: 16251.4\tvalid_1's rmse: 20458.8\n",
      "[2200]\ttraining's rmse: 16111.8\tvalid_1's rmse: 20460.3\n",
      "[2300]\ttraining's rmse: 15977.8\tvalid_1's rmse: 20456.4\n",
      "[2400]\ttraining's rmse: 15825.8\tvalid_1's rmse: 20455.2\n",
      "[2500]\ttraining's rmse: 15689.6\tvalid_1's rmse: 20460.5\n",
      "[2600]\ttraining's rmse: 15548.1\tvalid_1's rmse: 20457.4\n",
      "[2700]\ttraining's rmse: 15414\tvalid_1's rmse: 20451.3\n",
      "[2800]\ttraining's rmse: 15275.5\tvalid_1's rmse: 20448.6\n",
      "[2900]\ttraining's rmse: 15150.7\tvalid_1's rmse: 20446.8\n",
      "[3000]\ttraining's rmse: 15021.8\tvalid_1's rmse: 20449.2\n",
      "[3100]\ttraining's rmse: 14893.5\tvalid_1's rmse: 20450.1\n",
      "[3200]\ttraining's rmse: 14776.4\tvalid_1's rmse: 20446.4\n",
      "[3300]\ttraining's rmse: 14647.5\tvalid_1's rmse: 20447.1\n",
      "[3400]\ttraining's rmse: 14529.5\tvalid_1's rmse: 20445.8\n",
      "Early stopping, best iteration is:\n",
      "[3128]\ttraining's rmse: 14854.6\tvalid_1's rmse: 20441.9\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22677.1\tvalid_1's rmse: 23048.3\n",
      "[200]\ttraining's rmse: 20892.2\tvalid_1's rmse: 21628.7\n",
      "[300]\ttraining's rmse: 20130.3\tvalid_1's rmse: 21194.4\n",
      "[400]\ttraining's rmse: 19666.6\tvalid_1's rmse: 20979.1\n",
      "[500]\ttraining's rmse: 19324.6\tvalid_1's rmse: 20862.4\n",
      "[600]\ttraining's rmse: 19012.8\tvalid_1's rmse: 20749\n",
      "[700]\ttraining's rmse: 18744.1\tvalid_1's rmse: 20645.3\n",
      "[800]\ttraining's rmse: 18529.7\tvalid_1's rmse: 20596.8\n",
      "[900]\ttraining's rmse: 18309.2\tvalid_1's rmse: 20535.9\n",
      "[1000]\ttraining's rmse: 18094.4\tvalid_1's rmse: 20490.2\n",
      "[1100]\ttraining's rmse: 17906.4\tvalid_1's rmse: 20449\n",
      "[1200]\ttraining's rmse: 17712\tvalid_1's rmse: 20419.9\n",
      "[1300]\ttraining's rmse: 17531.9\tvalid_1's rmse: 20394.4\n",
      "[1400]\ttraining's rmse: 17367.2\tvalid_1's rmse: 20364.1\n",
      "[1500]\ttraining's rmse: 17194.3\tvalid_1's rmse: 20339.4\n",
      "[1600]\ttraining's rmse: 17034.6\tvalid_1's rmse: 20323.9\n",
      "[1700]\ttraining's rmse: 16862\tvalid_1's rmse: 20300.4\n",
      "[1800]\ttraining's rmse: 16707.8\tvalid_1's rmse: 20287.9\n",
      "[1900]\ttraining's rmse: 16546.9\tvalid_1's rmse: 20262.3\n",
      "[2000]\ttraining's rmse: 16409.8\tvalid_1's rmse: 20255.6\n",
      "[2100]\ttraining's rmse: 16262.8\tvalid_1's rmse: 20236.8\n",
      "[2200]\ttraining's rmse: 16130.9\tvalid_1's rmse: 20232.9\n",
      "[2300]\ttraining's rmse: 15996.2\tvalid_1's rmse: 20231.9\n",
      "[2400]\ttraining's rmse: 15850.5\tvalid_1's rmse: 20216.1\n",
      "[2500]\ttraining's rmse: 15719.2\tvalid_1's rmse: 20208.8\n",
      "[2600]\ttraining's rmse: 15593.3\tvalid_1's rmse: 20205.9\n",
      "[2700]\ttraining's rmse: 15457.8\tvalid_1's rmse: 20195.8\n",
      "[2800]\ttraining's rmse: 15329.9\tvalid_1's rmse: 20196.3\n",
      "[2900]\ttraining's rmse: 15202\tvalid_1's rmse: 20187.4\n",
      "[3000]\ttraining's rmse: 15070.7\tvalid_1's rmse: 20189.4\n",
      "[3100]\ttraining's rmse: 14937\tvalid_1's rmse: 20187.3\n",
      "[3200]\ttraining's rmse: 14806.4\tvalid_1's rmse: 20183.6\n",
      "[3300]\ttraining's rmse: 14691\tvalid_1's rmse: 20181.9\n",
      "[3400]\ttraining's rmse: 14561.2\tvalid_1's rmse: 20177.5\n",
      "[3500]\ttraining's rmse: 14442\tvalid_1's rmse: 20173.6\n",
      "[3600]\ttraining's rmse: 14319.9\tvalid_1's rmse: 20169.1\n",
      "[3700]\ttraining's rmse: 14205.6\tvalid_1's rmse: 20167\n",
      "[3800]\ttraining's rmse: 14078\tvalid_1's rmse: 20167.5\n",
      "[3900]\ttraining's rmse: 13954.1\tvalid_1's rmse: 20171.5\n",
      "[4000]\ttraining's rmse: 13835.2\tvalid_1's rmse: 20176.8\n",
      "Early stopping, best iteration is:\n",
      "[3753]\ttraining's rmse: 14141\tvalid_1's rmse: 20159.7\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22729.3\tvalid_1's rmse: 23099.1\n",
      "[200]\ttraining's rmse: 20955.8\tvalid_1's rmse: 21496.8\n",
      "[300]\ttraining's rmse: 20189.5\tvalid_1's rmse: 20969.9\n",
      "[400]\ttraining's rmse: 19709.2\tvalid_1's rmse: 20708.1\n",
      "[500]\ttraining's rmse: 19359.2\tvalid_1's rmse: 20559.4\n",
      "[600]\ttraining's rmse: 19070\tvalid_1's rmse: 20467.4\n",
      "[700]\ttraining's rmse: 18787.3\tvalid_1's rmse: 20384.6\n",
      "[800]\ttraining's rmse: 18549.7\tvalid_1's rmse: 20332.9\n",
      "[900]\ttraining's rmse: 18328.5\tvalid_1's rmse: 20276.8\n",
      "[1000]\ttraining's rmse: 18143.9\tvalid_1's rmse: 20237.6\n",
      "[1100]\ttraining's rmse: 17969.8\tvalid_1's rmse: 20203\n",
      "[1200]\ttraining's rmse: 17798\tvalid_1's rmse: 20179.1\n",
      "[1300]\ttraining's rmse: 17620\tvalid_1's rmse: 20159.7\n",
      "[1400]\ttraining's rmse: 17448\tvalid_1's rmse: 20138.6\n",
      "[1500]\ttraining's rmse: 17281.8\tvalid_1's rmse: 20110.9\n",
      "[1600]\ttraining's rmse: 17113.7\tvalid_1's rmse: 20098.2\n",
      "[1700]\ttraining's rmse: 16957.2\tvalid_1's rmse: 20077.5\n",
      "[1800]\ttraining's rmse: 16792.8\tvalid_1's rmse: 20071.1\n",
      "[1900]\ttraining's rmse: 16638.9\tvalid_1's rmse: 20061.3\n",
      "[2000]\ttraining's rmse: 16481.1\tvalid_1's rmse: 20046.4\n",
      "[2100]\ttraining's rmse: 16340.2\tvalid_1's rmse: 20035.2\n",
      "[2200]\ttraining's rmse: 16193.3\tvalid_1's rmse: 20029.1\n",
      "[2300]\ttraining's rmse: 16054.5\tvalid_1's rmse: 20024.2\n",
      "[2400]\ttraining's rmse: 15907.5\tvalid_1's rmse: 20006.2\n",
      "[2500]\ttraining's rmse: 15782.8\tvalid_1's rmse: 20000.1\n",
      "[2600]\ttraining's rmse: 15645.8\tvalid_1's rmse: 19996.1\n",
      "[2700]\ttraining's rmse: 15511.3\tvalid_1's rmse: 19997\n",
      "[2800]\ttraining's rmse: 15389\tvalid_1's rmse: 19993.3\n",
      "[2900]\ttraining's rmse: 15264.4\tvalid_1's rmse: 19987.2\n",
      "[3000]\ttraining's rmse: 15141\tvalid_1's rmse: 19984.9\n",
      "[3100]\ttraining's rmse: 15002.2\tvalid_1's rmse: 19983.6\n",
      "[3200]\ttraining's rmse: 14869.6\tvalid_1's rmse: 19986.4\n",
      "[3300]\ttraining's rmse: 14744.2\tvalid_1's rmse: 19988.4\n",
      "Early stopping, best iteration is:\n",
      "[3072]\ttraining's rmse: 15048\tvalid_1's rmse: 19981.7\n"
     ]
    }
   ],
   "source": [
    "importances = pd.DataFrame()\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "models1 = []\n",
    "\n",
    "# use_cols = feature_selection(train_df, use_cols, n_features=1000)\n",
    "\n",
    "for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "    print(f\"Fold {fold_i+1}\")\n",
    "    train_dataset = lgb.Dataset(\n",
    "        train_df.loc[trn_idx, use_cols],\n",
    "        label = train_df.loc[trn_idx, \"Salary\"]\n",
    "    )\n",
    "    valid_dataset = lgb.Dataset(\n",
    "        train_df.loc[val_idx, use_cols],\n",
    "        label = train_df.loc[val_idx, \"Salary\"]\n",
    "    )\n",
    "    model = lgb.train(\n",
    "                lgb_params,\n",
    "                train_dataset,\n",
    "                10000,\n",
    "                valid_sets = [train_dataset, valid_dataset],\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds = 300,\n",
    "                #feval = eval_f1,\n",
    "                #callbacks = [log_callback],\n",
    "    )\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = use_cols\n",
    "    imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])\n",
    "    models1.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20186.5261848146"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_Country__SalaryType</td>\n",
       "      <td>4.573756e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_Country__Employment</td>\n",
       "      <td>4.176125e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_Country__Age</td>\n",
       "      <td>3.225687e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_Country__YearsCodingProf</td>\n",
       "      <td>3.127602e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_Country__YearsCoding</td>\n",
       "      <td>2.958806e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te_Country__ohe_DevType_Student</td>\n",
       "      <td>2.838776e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>te_YearsCodingProf__CurrencySymbol</td>\n",
       "      <td>2.035802e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>te_Country__ohe_Methodology_Agile</td>\n",
       "      <td>1.978364e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te_Country__FormalEducation</td>\n",
       "      <td>1.866648e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>te_SalaryType__CurrencySymbol</td>\n",
       "      <td>1.685397e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>te_Country__ohe_EducationTypes_Contributed_to_...</td>\n",
       "      <td>1.398139e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>te_Currency__Age</td>\n",
       "      <td>1.201738e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>te_YearsCoding__CurrencySymbol</td>\n",
       "      <td>1.127268e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>te_Country__Dependents</td>\n",
       "      <td>1.023981e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>te_Country__ohe_DevType_Engineering_manager</td>\n",
       "      <td>1.015333e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>te_YearsCodingProf__Currency</td>\n",
       "      <td>9.847825e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>te_SalaryType__Age</td>\n",
       "      <td>9.441897e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>te_Country</td>\n",
       "      <td>9.065421e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>te_YearsCodingProf__ohe_DevType_Student</td>\n",
       "      <td>8.507650e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te_Country__ohe_CommunicationTools_Confluence</td>\n",
       "      <td>8.493347e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>te_Country__CareerSatisfaction</td>\n",
       "      <td>7.437338e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>te_CompanySize__YearsCodingProf</td>\n",
       "      <td>7.411947e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>te_YearsCodingProf__SalaryType</td>\n",
       "      <td>6.114947e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>te_Country__CompanySize</td>\n",
       "      <td>5.371661e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>te_CurrencySymbol__ohe_DevType_Student</td>\n",
       "      <td>5.344918e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>te_Currency__SalaryType</td>\n",
       "      <td>5.012666e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>te_YearsCodingProf__ohe_CommunicationTools_Con...</td>\n",
       "      <td>4.972794e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>te_Employment__CurrencySymbol</td>\n",
       "      <td>4.754676e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>te_Country__MilitaryUS</td>\n",
       "      <td>4.471133e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>te_YearsCodingProf__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>4.468932e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature          gain\n",
       "0                              te_Country__SalaryType  4.573756e+08\n",
       "1                              te_Country__Employment  4.176125e+08\n",
       "2                                     te_Country__Age  3.225687e+08\n",
       "3                         te_Country__YearsCodingProf  3.127602e+08\n",
       "4                             te_Country__YearsCoding  2.958806e+08\n",
       "5                     te_Country__ohe_DevType_Student  2.838776e+08\n",
       "6                  te_YearsCodingProf__CurrencySymbol  2.035802e+08\n",
       "7                   te_Country__ohe_Methodology_Agile  1.978364e+08\n",
       "8                         te_Country__FormalEducation  1.866648e+08\n",
       "9                       te_SalaryType__CurrencySymbol  1.685397e+08\n",
       "10  te_Country__ohe_EducationTypes_Contributed_to_...  1.398139e+08\n",
       "11                                   te_Currency__Age  1.201738e+08\n",
       "12                     te_YearsCoding__CurrencySymbol  1.127268e+08\n",
       "13                             te_Country__Dependents  1.023981e+08\n",
       "14        te_Country__ohe_DevType_Engineering_manager  1.015333e+08\n",
       "15                       te_YearsCodingProf__Currency  9.847825e+07\n",
       "16                                 te_SalaryType__Age  9.441897e+07\n",
       "17                                         te_Country  9.065421e+07\n",
       "18            te_YearsCodingProf__ohe_DevType_Student  8.507650e+07\n",
       "19      te_Country__ohe_CommunicationTools_Confluence  8.493347e+07\n",
       "20                     te_Country__CareerSatisfaction  7.437338e+07\n",
       "21                    te_CompanySize__YearsCodingProf  7.411947e+07\n",
       "22                     te_YearsCodingProf__SalaryType  6.114947e+07\n",
       "23                            te_Country__CompanySize  5.371661e+07\n",
       "24             te_CurrencySymbol__ohe_DevType_Student  5.344918e+07\n",
       "25                            te_Currency__SalaryType  5.012666e+07\n",
       "26  te_YearsCodingProf__ohe_CommunicationTools_Con...  4.972794e+07\n",
       "27                      te_Employment__CurrencySymbol  4.754676e+07\n",
       "28                             te_Country__MilitaryUS  4.471133e+07\n",
       "29     te_YearsCodingProf__ohe_LanguageWorkedWith_PHP  4.468932e+07"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2495"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"residual_error\"] = oof_preds - train_df[\"Salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_train2(train_df, use_cols, fold_idx_list, data_type=\"main\"):\n",
    "\n",
    "    importances2 = pd.DataFrame()\n",
    "    oof_preds2 = np.zeros(len(train_df))\n",
    "    models2 = []\n",
    "    \n",
    "    _lgb_params = lgb_params.copy()\n",
    "    _lgb_params[\"max_depth\"] = -1\n",
    "    _lgb_params[\"num_leaves\"] = 128\n",
    "    _lgb_params[\"learning_rate\"] = 0.001\n",
    "    _lgb_params[\"min_data_in_leaf\"] = 10\n",
    "    _lgb_params[\"objective\"] = \"regression\"\n",
    "\n",
    "    for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "        print(f\"Fold {fold_i+1}\")\n",
    "        train_data = train_df.loc[trn_idx]\n",
    "        valid_data = train_df.loc[val_idx]\n",
    "        if data_type == \"main\":\n",
    "            train_data = train_data[train_data.ohe_main_cluster == 1]\n",
    "            valid_data = valid_data[valid_data.ohe_main_cluster == 1]\n",
    "        elif data_type == \"not_main\":\n",
    "            train_data = train_data[train_data.ohe_main_cluster == 0]\n",
    "            valid_data = valid_data[valid_data.ohe_main_cluster == 0]\n",
    "        train_dataset = lgb.Dataset(\n",
    "            train_data[use_cols],\n",
    "            label = train_data[\"residual_error\"]\n",
    "        )\n",
    "        valid_dataset = lgb.Dataset(\n",
    "            valid_data[use_cols],\n",
    "            label = valid_data[\"residual_error\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    _lgb_params,\n",
    "                    train_dataset,\n",
    "                    3000,\n",
    "                    valid_sets = [train_dataset, valid_dataset],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 300,\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        importances2 = pd.concat([importances2, imp_df], axis=0, sort=False)\n",
    "        models2.append(model)\n",
    "    return models2, oof_preds2, importances2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22243.4\tvalid_1's rmse: 22304.9\n",
      "[200]\ttraining's rmse: 21929.1\tvalid_1's rmse: 22321.2\n",
      "[300]\ttraining's rmse: 21623.4\tvalid_1's rmse: 22332.8\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's rmse: 22470.1\tvalid_1's rmse: 22297.5\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22217.2\tvalid_1's rmse: 22432.1\n",
      "[200]\ttraining's rmse: 21910.5\tvalid_1's rmse: 22438.5\n",
      "[300]\ttraining's rmse: 21611.2\tvalid_1's rmse: 22446.8\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's rmse: 22523.2\tvalid_1's rmse: 22423.1\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22094.2\tvalid_1's rmse: 22930.4\n",
      "[200]\ttraining's rmse: 21790.9\tvalid_1's rmse: 22935.8\n",
      "[300]\ttraining's rmse: 21492.2\tvalid_1's rmse: 22944.5\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 22389.8\tvalid_1's rmse: 22918.8\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22158.8\tvalid_1's rmse: 22679.4\n",
      "[200]\ttraining's rmse: 21851.7\tvalid_1's rmse: 22687.4\n",
      "[300]\ttraining's rmse: 21553.8\tvalid_1's rmse: 22693.9\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 22467.3\tvalid_1's rmse: 22672.3\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 22258.2\tvalid_1's rmse: 22254.5\n",
      "[200]\ttraining's rmse: 21948.6\tvalid_1's rmse: 22259\n",
      "[300]\ttraining's rmse: 21644.6\tvalid_1's rmse: 22271.8\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's rmse: 22557.9\tvalid_1's rmse: 22245.5\n"
     ]
    }
   ],
   "source": [
    "models2, oof_preds2, importances2 = lgb_train2(train_df, use_cols, fold_idx_list, data_type=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 18148.7\tvalid_1's rmse: 18686.7\n",
      "[200]\ttraining's rmse: 17911.2\tvalid_1's rmse: 18691.3\n",
      "[300]\ttraining's rmse: 17682.5\tvalid_1's rmse: 18694.1\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 18389.3\tvalid_1's rmse: 18681.4\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 18214.8\tvalid_1's rmse: 18447.2\n",
      "[200]\ttraining's rmse: 17981.3\tvalid_1's rmse: 18457.1\n",
      "[300]\ttraining's rmse: 17756.8\tvalid_1's rmse: 18468.3\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's rmse: 18451.8\tvalid_1's rmse: 18436.2\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 18174.5\tvalid_1's rmse: 18606.6\n",
      "[200]\ttraining's rmse: 17943.1\tvalid_1's rmse: 18610.2\n",
      "[300]\ttraining's rmse: 17721.2\tvalid_1's rmse: 18612.4\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's rmse: 18395.1\tvalid_1's rmse: 18602.5\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[100]\ttraining's rmse: 18268.6\tvalid_1's rmse: 18253.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-44b7b6c76a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodels2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moof_preds2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_train2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_idx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"not_main\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-8bbee974bc9d>\u001b[0m in \u001b[0;36mlgb_train2\u001b[0;34m(train_df, use_cols, fold_idx_list, data_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"residual_error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[0;32m---> 32\u001b[0;31m         model = lgb.train(\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0m_lgb_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1974\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models2, oof_preds2, importances2 = lgb_train2(train_df, use_cols, fold_idx_list, data_type=\"not_main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.zeros(len(test_df))\n",
    "\n",
    "for model in models:\n",
    "    test_pred += model.predict(test_df[use_cols]) / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67772.21736985,  91906.65505641,  89335.72472625, ...,\n",
       "        87460.2147288 ,  81660.45977467, 117499.75140813])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input/submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\"Salary\"] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_df.to_csv(\"../predict/024_col_shuffle_20186.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
