{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train_df, test_df):\n",
    "    \n",
    "    ###########################\n",
    "    # Functions of preprocess\n",
    "    ###########################\n",
    "    def get_multi_cat_cols(train_df):\n",
    "        tmp = train_df.iloc[:1000]\n",
    "        multi_cols = []\n",
    "        for c in train_df.columns:\n",
    "            sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "            if sep_num > 10:\n",
    "                multi_cols.append(c)\n",
    "        return multi_cols\n",
    "\n",
    "    def add_rank_feature(df):\n",
    "        rank_prefix_list = [\n",
    "            \"AssessBenefits\",\n",
    "            \"AssessJob\",\n",
    "            \"JobContactPriorities\",\n",
    "            \"JobEmailPriorities\",\n",
    "            \"AdsPriorities\",\n",
    "        ]\n",
    "        for prefix in tqdm(rank_prefix_list):\n",
    "            rank_cols = [c for c in df.columns if prefix in c]\n",
    "            col_pairs = itertools.combinations(rank_cols, 2)\n",
    "            for col_a, col_b in col_pairs:\n",
    "                df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "        return df\n",
    "\n",
    "    def get_basic_importance_cols(use_num=50):\n",
    "        # basicなモデルのimportanceを読み込み\n",
    "        importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "        imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "        return imp_feats\n",
    "\n",
    "    def make_agg_feature(train_df, test_df):\n",
    "        imp_feats = get_basic_importance_cols(use_num=50)\n",
    "        imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "        imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "        print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "        #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "        all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "        for cat_col in tqdm(imp_cat_cols):\n",
    "            for nume_col in imp_nume_cols:\n",
    "                # one-hotは同じカテゴリの場合がある\n",
    "                if cat_col == nume_col:\n",
    "                    continue\n",
    "                all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "                all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "                all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "                all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "                all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "                all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                    all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "        train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "        test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "        del all_df\n",
    "        gc.collect()\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=True)\n",
    "    def target_encoding_s(train_df, test_df):\n",
    "        te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "\n",
    "        smooth = 100\n",
    "        for c in tqdm(te_cols):\n",
    "            new_col = \"te_\" + c\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                salary_mean = train_df.loc[trn_idx, \"Salary\"].mean()\n",
    "                mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].agg([\"mean\", \"count\"])\n",
    "                alpha = mean_val[\"count\"].map(lambda x: x if x < smooth else smooth) / smooth\n",
    "                mean_val[\"mean\"] = mean_val[\"mean\"] * alpha + salary_mean * (1 - alpha)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val[\"mean\"])\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val[\"mean\"]) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        return train_df, test_df\n",
    "\n",
    "    @feature_cache(reset=True)\n",
    "    def multiple_target_encoding_s(train_df, test_df):\n",
    "         # multiple target encoding\n",
    "        multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "        imp_feats = get_basic_importance_cols(use_num=30)\n",
    "        multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "        combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "        smooth = 100\n",
    "        for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "            new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "            train_df[new_col] = 0\n",
    "            test_df[new_col] = 0\n",
    "            train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "            test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "            for trn_idx, val_idx in fold_idx_list:\n",
    "                salary_mean = train_df.loc[trn_idx, \"Salary\"].mean()\n",
    "                mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].agg([\"mean\", \"count\"])\n",
    "                alpha = mean_val[\"count\"].map(lambda x: x if x < smooth else smooth) / smooth\n",
    "                mean_val[\"mean\"] = mean_val[\"mean\"] * alpha + salary_mean * (1 - alpha)\n",
    "                train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val[\"mean\"])\n",
    "                test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val[\"mean\"]) / len(fold_idx_list)\n",
    "            train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "            test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "            del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "            gc.collect()\n",
    "        return train_df, test_df   \n",
    "    \n",
    "    ################################\n",
    "    # Columns infomation\n",
    "    ################################\n",
    "    original_cols = train_df.columns.tolist()\n",
    "    multi_cat_cols = get_multi_cat_cols(train_df)\n",
    "\n",
    "    nume_cols = [\n",
    "        c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "        if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "    ]\n",
    "\n",
    "    cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]\n",
    "\n",
    "    non_basic_nume_cols = []\n",
    "    non_basic_cat_cols = []\n",
    "\n",
    "    ################################\n",
    "    #  Make feature\n",
    "    ################################    \n",
    "    \n",
    "    # rank feature\n",
    "    train_df = add_rank_feature(train_df)\n",
    "    test_df = add_rank_feature(test_df)\n",
    "\n",
    "    # multi -category encoding \n",
    "    for c in tqdm(multi_cat_cols):\n",
    "        binarizer = MultiLabelBinarizer()\n",
    "        train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "        train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "        test_arr = binarizer.transform(test_multi_srs)\n",
    "        feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "        train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "        test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "        all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "        train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "        train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "        test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "        # ohe_featureはcategoryとnumerical両方として扱う\n",
    "        nume_cols += feat_cols\n",
    "        cat_cols += feat_cols\n",
    "        # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "        # SVD\n",
    "        svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "        all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "        train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "        test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # simple category encoding\n",
    "    for c in cat_cols:\n",
    "        train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "        test_df[c] = uniques.get_indexer(test_df[c])\n",
    "    \n",
    "    # reduce memory\n",
    "    # numerical cols\n",
    "    for c in nume_cols:\n",
    "        if train_df[c].nunique() > 1000:\n",
    "            train_df[c] = train_df[c].astype(np.float32)\n",
    "            test_df[c] = test_df[c].astype(np.float32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.float16)\n",
    "            test_df[c] = test_df[c].astype(np.float16)\n",
    "    # category cols\n",
    "    for c in cat_cols:\n",
    "        if train_df[c].max() > 32767:\n",
    "            train_df[c] = train_df[c].astype(np.int32)\n",
    "            test_df[c] = test_df[c].astype(np.int32)\n",
    "        else:\n",
    "            train_df[c] = train_df[c].astype(np.int16)\n",
    "            test_df[c] = test_df[c].astype(np.int16)\n",
    "    \n",
    "    # change columns name\n",
    "    train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "    test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]\n",
    "   \n",
    "    # aggregate feature\n",
    "    train_df, test_df = make_agg_feature(train_df, test_df)\n",
    "\n",
    "    # make train/validation index list for target encoding\n",
    "    folds = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "    fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"Salary\"])]\n",
    "    \n",
    "    # target encoding\n",
    "    train_df, test_df = target_encoding_s(train_df, test_df)\n",
    "\n",
    "    # multiple category target encoding \n",
    "    train_df, test_df = multiple_target_encoding_s(train_df, test_df)\n",
    "    \n",
    "    # make use columns list\n",
    "    use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\"]]\n",
    "    print(len(use_cols))\n",
    "    \n",
    "    return train_df, test_df, use_cols, fold_idx_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df, test_df, use_cols, fold_idx_list):\n",
    "\n",
    "    lgb_params = {\n",
    "                'objective': 'poisson',\n",
    "                \"metric\": \"rmse\",\n",
    "                \"verbosity\": -1,\n",
    "                \"boosting\": \"gbdt\",\n",
    "                'learning_rate': 0.01,\n",
    "                'num_leaves': 64,\n",
    "                'min_data_in_leaf': 80, \n",
    "                'max_depth': 4,\n",
    "                \"bagging_freq\": 5,\n",
    "                \"bagging_fraction\": 0.8,\n",
    "                \"lambda_l1\": 0.5,\n",
    "                \"lambda_l2\": 0.5,\n",
    "                \"feature_fraction\": 0.1,\n",
    "                \"seed\": 2020,\n",
    "                \"num_threads\": -1,\n",
    "                \"max_bins\": 30\n",
    "    }\n",
    "    def feature_selection(train_df, use_cols, n_features=1000):\n",
    "        df = train_df.sample(30000, random_state=2020)\n",
    "        train_dataset = lgb.Dataset(\n",
    "            df.loc[:, use_cols],\n",
    "            label = df.loc[:, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    2000,\n",
    "                    valid_sets = [train_dataset],\n",
    "                    verbose_eval=200,\n",
    "                    early_stopping_rounds = None,\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "        return select_features\n",
    "    \n",
    "    importances = pd.DataFrame()\n",
    "    oof_preds = np.zeros(len(train_df))\n",
    "    models = []\n",
    "\n",
    "    # use_cols = feature_selection(train_df, use_cols, n_features=1000)\n",
    "\n",
    "    for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "        print(f\"Fold {fold_i+1}\")\n",
    "        train_dataset = lgb.Dataset(\n",
    "            train_df.loc[trn_idx, use_cols],\n",
    "            label = train_df.loc[trn_idx, \"Salary\"]\n",
    "        )\n",
    "        valid_dataset = lgb.Dataset(\n",
    "            train_df.loc[val_idx, use_cols],\n",
    "            label = train_df.loc[val_idx, \"Salary\"]\n",
    "        )\n",
    "        model = lgb.train(\n",
    "                    lgb_params,\n",
    "                    train_dataset,\n",
    "                    30000,\n",
    "                    valid_sets = [train_dataset, valid_dataset],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 500,\n",
    "                    #feval = eval_f1,\n",
    "                    #callbacks = [log_callback],\n",
    "        )\n",
    "        imp_df = pd.DataFrame()\n",
    "        imp_df['feature'] = use_cols\n",
    "        imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "        importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "\n",
    "        oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])\n",
    "        models.append(model)\n",
    "\n",
    "    oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "    print(f\"OOF Score: {oof_score}\")\n",
    "    \n",
    "    display(\n",
    "        importances.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:50]\n",
    "    )\n",
    "\n",
    "    return train_df, test_df, models, oof_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_df, models, use_cols, oof_score):\n",
    "    test_pred = np.zeros(len(test_df))\n",
    "    for model in models:\n",
    "        test_pred += model.predict(test_df[use_cols]) / len(models)\n",
    "    sub_df = pd.read_csv(\"../input/submit.csv\")\n",
    "    sub_df[\"Salary\"] = test_pred\n",
    "    sub_df.to_csv(f\"../predict/{model_title}_{oof_score}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EndPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_title = \"037_smooth_te\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a827337df874dac8e5703dd9fefeb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0cc363e4eb49419e5bc701ad50439c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866430239faa4a389f1bc4ca4b78d23d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861c824c81fe4e75a574339a34d128da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b905b9057f472bba79c0c7e7928d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=229.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0a7dcd1020487aa1c373e1bbeb8fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2659\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df, use_cols, fold_idx_list = preprocess(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22817.3\tvalid_1's rmse: 23158\n",
      "[1000]\ttraining's rmse: 21000.1\tvalid_1's rmse: 21757.2\n",
      "[1500]\ttraining's rmse: 20230.1\tvalid_1's rmse: 21310.2\n",
      "[2000]\ttraining's rmse: 19742.7\tvalid_1's rmse: 21075.6\n",
      "[2500]\ttraining's rmse: 19363.8\tvalid_1's rmse: 20915.8\n",
      "[3000]\ttraining's rmse: 19044.5\tvalid_1's rmse: 20798.2\n",
      "[3500]\ttraining's rmse: 18767.7\tvalid_1's rmse: 20715.5\n",
      "[4000]\ttraining's rmse: 18518.6\tvalid_1's rmse: 20654.9\n",
      "[4500]\ttraining's rmse: 18285.8\tvalid_1's rmse: 20598.9\n",
      "[5000]\ttraining's rmse: 18067.4\tvalid_1's rmse: 20552.3\n",
      "[5500]\ttraining's rmse: 17857.1\tvalid_1's rmse: 20518.2\n",
      "[6000]\ttraining's rmse: 17667.7\tvalid_1's rmse: 20486.1\n",
      "[6500]\ttraining's rmse: 17482.8\tvalid_1's rmse: 20457.6\n",
      "[7000]\ttraining's rmse: 17310.1\tvalid_1's rmse: 20437.6\n",
      "[7500]\ttraining's rmse: 17138.4\tvalid_1's rmse: 20414.6\n",
      "[8000]\ttraining's rmse: 16967.5\tvalid_1's rmse: 20393.8\n",
      "[8500]\ttraining's rmse: 16802.3\tvalid_1's rmse: 20376.5\n",
      "[9000]\ttraining's rmse: 16635.6\tvalid_1's rmse: 20358.9\n",
      "[9500]\ttraining's rmse: 16484.3\tvalid_1's rmse: 20342.7\n",
      "[10000]\ttraining's rmse: 16333.6\tvalid_1's rmse: 20331.2\n",
      "[10500]\ttraining's rmse: 16186.5\tvalid_1's rmse: 20318.9\n",
      "[11000]\ttraining's rmse: 16041.8\tvalid_1's rmse: 20306.3\n",
      "[11500]\ttraining's rmse: 15900\tvalid_1's rmse: 20302\n",
      "[12000]\ttraining's rmse: 15762.3\tvalid_1's rmse: 20293.3\n",
      "[12500]\ttraining's rmse: 15623.5\tvalid_1's rmse: 20289.4\n",
      "[13000]\ttraining's rmse: 15487.3\tvalid_1's rmse: 20282.8\n",
      "[13500]\ttraining's rmse: 15348.4\tvalid_1's rmse: 20274.3\n",
      "[14000]\ttraining's rmse: 15216.6\tvalid_1's rmse: 20267.4\n",
      "[14500]\ttraining's rmse: 15084\tvalid_1's rmse: 20260.5\n",
      "[15000]\ttraining's rmse: 14959.4\tvalid_1's rmse: 20255.4\n",
      "[15500]\ttraining's rmse: 14829\tvalid_1's rmse: 20256.9\n",
      "Early stopping, best iteration is:\n",
      "[15253]\ttraining's rmse: 14894.5\tvalid_1's rmse: 20254\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22792.5\tvalid_1's rmse: 23370.4\n",
      "[1000]\ttraining's rmse: 21026.3\tvalid_1's rmse: 21847.7\n",
      "[1500]\ttraining's rmse: 20283.2\tvalid_1's rmse: 21295.8\n",
      "[2000]\ttraining's rmse: 19799.5\tvalid_1's rmse: 21011.3\n",
      "[2500]\ttraining's rmse: 19431.8\tvalid_1's rmse: 20837\n",
      "[3000]\ttraining's rmse: 19126.8\tvalid_1's rmse: 20716.2\n",
      "[3500]\ttraining's rmse: 18852.1\tvalid_1's rmse: 20615.3\n",
      "[4000]\ttraining's rmse: 18603.3\tvalid_1's rmse: 20532.8\n",
      "[4500]\ttraining's rmse: 18377\tvalid_1's rmse: 20463.6\n",
      "[5000]\ttraining's rmse: 18161.7\tvalid_1's rmse: 20414.7\n",
      "[5500]\ttraining's rmse: 17963.6\tvalid_1's rmse: 20369.4\n",
      "[6000]\ttraining's rmse: 17774\tvalid_1's rmse: 20326.7\n",
      "[6500]\ttraining's rmse: 17592.8\tvalid_1's rmse: 20294.3\n",
      "[7000]\ttraining's rmse: 17420\tvalid_1's rmse: 20261.2\n",
      "[7500]\ttraining's rmse: 17251.7\tvalid_1's rmse: 20238.9\n",
      "[8000]\ttraining's rmse: 17085\tvalid_1's rmse: 20212.6\n",
      "[8500]\ttraining's rmse: 16916.5\tvalid_1's rmse: 20186.9\n",
      "[9000]\ttraining's rmse: 16759.3\tvalid_1's rmse: 20170.2\n",
      "[9500]\ttraining's rmse: 16607.8\tvalid_1's rmse: 20157.6\n",
      "[10000]\ttraining's rmse: 16455.4\tvalid_1's rmse: 20141.6\n",
      "[10500]\ttraining's rmse: 16308.4\tvalid_1's rmse: 20127.2\n",
      "[11000]\ttraining's rmse: 16156.9\tvalid_1's rmse: 20114.2\n",
      "[11500]\ttraining's rmse: 16015.5\tvalid_1's rmse: 20104.9\n",
      "[12000]\ttraining's rmse: 15877.2\tvalid_1's rmse: 20089.5\n",
      "[12500]\ttraining's rmse: 15734.1\tvalid_1's rmse: 20078.6\n",
      "[13000]\ttraining's rmse: 15595.4\tvalid_1's rmse: 20067\n",
      "[13500]\ttraining's rmse: 15458.9\tvalid_1's rmse: 20056\n",
      "[14000]\ttraining's rmse: 15324.5\tvalid_1's rmse: 20050.2\n",
      "[14500]\ttraining's rmse: 15193\tvalid_1's rmse: 20040.8\n",
      "[15000]\ttraining's rmse: 15063.3\tvalid_1's rmse: 20036.7\n",
      "[15500]\ttraining's rmse: 14934.4\tvalid_1's rmse: 20031.6\n",
      "[16000]\ttraining's rmse: 14808\tvalid_1's rmse: 20030\n",
      "[16500]\ttraining's rmse: 14683.8\tvalid_1's rmse: 20026.9\n",
      "[17000]\ttraining's rmse: 14562.3\tvalid_1's rmse: 20025.3\n",
      "[17500]\ttraining's rmse: 14440.1\tvalid_1's rmse: 20021.4\n",
      "Early stopping, best iteration is:\n",
      "[17396]\ttraining's rmse: 14467.1\tvalid_1's rmse: 20020.7\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22829.7\tvalid_1's rmse: 23096.4\n",
      "[1000]\ttraining's rmse: 21026.7\tvalid_1's rmse: 21622.5\n",
      "[1500]\ttraining's rmse: 20276.1\tvalid_1's rmse: 21179.7\n",
      "[2000]\ttraining's rmse: 19771\tvalid_1's rmse: 20966.5\n",
      "[2500]\ttraining's rmse: 19383.8\tvalid_1's rmse: 20842.8\n",
      "[3000]\ttraining's rmse: 19070.1\tvalid_1's rmse: 20748.9\n",
      "[3500]\ttraining's rmse: 18789.6\tvalid_1's rmse: 20675.3\n",
      "[4000]\ttraining's rmse: 18541.7\tvalid_1's rmse: 20627.1\n",
      "[4500]\ttraining's rmse: 18317.8\tvalid_1's rmse: 20586.3\n",
      "[5000]\ttraining's rmse: 18106.4\tvalid_1's rmse: 20546.7\n",
      "[5500]\ttraining's rmse: 17908.8\tvalid_1's rmse: 20516.1\n",
      "[6000]\ttraining's rmse: 17718.4\tvalid_1's rmse: 20490.1\n",
      "[6500]\ttraining's rmse: 17534.5\tvalid_1's rmse: 20468.9\n",
      "[7000]\ttraining's rmse: 17362.2\tvalid_1's rmse: 20454.9\n",
      "[7500]\ttraining's rmse: 17192.8\tvalid_1's rmse: 20440.6\n",
      "[8000]\ttraining's rmse: 17029.7\tvalid_1's rmse: 20429.1\n",
      "[8500]\ttraining's rmse: 16869.8\tvalid_1's rmse: 20418.2\n",
      "[9000]\ttraining's rmse: 16713.2\tvalid_1's rmse: 20410.2\n",
      "[9500]\ttraining's rmse: 16562.4\tvalid_1's rmse: 20402.7\n",
      "[10000]\ttraining's rmse: 16415.1\tvalid_1's rmse: 20393.3\n",
      "[10500]\ttraining's rmse: 16268.2\tvalid_1's rmse: 20385.9\n",
      "[11000]\ttraining's rmse: 16128.4\tvalid_1's rmse: 20378.3\n",
      "[11500]\ttraining's rmse: 15988.5\tvalid_1's rmse: 20376\n",
      "[12000]\ttraining's rmse: 15849.6\tvalid_1's rmse: 20368.1\n",
      "[12500]\ttraining's rmse: 15717.3\tvalid_1's rmse: 20363.7\n",
      "[13000]\ttraining's rmse: 15582.3\tvalid_1's rmse: 20360.2\n",
      "[13500]\ttraining's rmse: 15446.4\tvalid_1's rmse: 20359.4\n",
      "[14000]\ttraining's rmse: 15311.5\tvalid_1's rmse: 20353.8\n",
      "[14500]\ttraining's rmse: 15178.1\tvalid_1's rmse: 20352.1\n",
      "[15000]\ttraining's rmse: 15048\tvalid_1's rmse: 20349.9\n",
      "Early stopping, best iteration is:\n",
      "[14812]\ttraining's rmse: 15096.1\tvalid_1's rmse: 20348\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22807\tvalid_1's rmse: 23224.2\n",
      "[1000]\ttraining's rmse: 21001.8\tvalid_1's rmse: 21833.8\n",
      "[1500]\ttraining's rmse: 20241\tvalid_1's rmse: 21394.1\n",
      "[2000]\ttraining's rmse: 19756.7\tvalid_1's rmse: 21152.1\n",
      "[2500]\ttraining's rmse: 19388.6\tvalid_1's rmse: 21004.2\n",
      "[3000]\ttraining's rmse: 19077\tvalid_1's rmse: 20890\n",
      "[3500]\ttraining's rmse: 18800.9\tvalid_1's rmse: 20798.2\n",
      "[4000]\ttraining's rmse: 18549.7\tvalid_1's rmse: 20714.9\n",
      "[4500]\ttraining's rmse: 18324.6\tvalid_1's rmse: 20655\n",
      "[5000]\ttraining's rmse: 18111.2\tvalid_1's rmse: 20606.2\n",
      "[5500]\ttraining's rmse: 17919.4\tvalid_1's rmse: 20559.2\n",
      "[6000]\ttraining's rmse: 17726.3\tvalid_1's rmse: 20515.9\n",
      "[6500]\ttraining's rmse: 17549.3\tvalid_1's rmse: 20480.9\n",
      "[7000]\ttraining's rmse: 17377.1\tvalid_1's rmse: 20453.9\n",
      "[7500]\ttraining's rmse: 17210.4\tvalid_1's rmse: 20428.8\n",
      "[8000]\ttraining's rmse: 17047.9\tvalid_1's rmse: 20403.1\n",
      "[8500]\ttraining's rmse: 16886.4\tvalid_1's rmse: 20377.5\n",
      "[9000]\ttraining's rmse: 16733.7\tvalid_1's rmse: 20357.8\n",
      "[9500]\ttraining's rmse: 16576.9\tvalid_1's rmse: 20338.1\n",
      "[10000]\ttraining's rmse: 16427.5\tvalid_1's rmse: 20321.1\n",
      "[10500]\ttraining's rmse: 16286.8\tvalid_1's rmse: 20308.3\n",
      "[11000]\ttraining's rmse: 16141.8\tvalid_1's rmse: 20295.4\n",
      "[11500]\ttraining's rmse: 16007.1\tvalid_1's rmse: 20283.5\n",
      "[12000]\ttraining's rmse: 15864.7\tvalid_1's rmse: 20274.5\n",
      "[12500]\ttraining's rmse: 15731.8\tvalid_1's rmse: 20264.9\n",
      "[13000]\ttraining's rmse: 15600.6\tvalid_1's rmse: 20259.4\n",
      "[13500]\ttraining's rmse: 15473.7\tvalid_1's rmse: 20251.4\n",
      "[14000]\ttraining's rmse: 15349.3\tvalid_1's rmse: 20241.2\n",
      "[14500]\ttraining's rmse: 15218.7\tvalid_1's rmse: 20237.2\n",
      "[15000]\ttraining's rmse: 15091.4\tvalid_1's rmse: 20231.2\n",
      "[15500]\ttraining's rmse: 14968.2\tvalid_1's rmse: 20226.6\n",
      "[16000]\ttraining's rmse: 14841.4\tvalid_1's rmse: 20222.6\n",
      "[16500]\ttraining's rmse: 14720.9\tvalid_1's rmse: 20219.7\n",
      "[17000]\ttraining's rmse: 14599.1\tvalid_1's rmse: 20215\n",
      "[17500]\ttraining's rmse: 14479.5\tvalid_1's rmse: 20210.8\n",
      "[18000]\ttraining's rmse: 14363.2\tvalid_1's rmse: 20208.6\n",
      "[18500]\ttraining's rmse: 14244\tvalid_1's rmse: 20208.5\n",
      "Early stopping, best iteration is:\n",
      "[18254]\ttraining's rmse: 14301.9\tvalid_1's rmse: 20207.3\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's rmse: 22856.3\tvalid_1's rmse: 23206.2\n",
      "[1000]\ttraining's rmse: 21074.6\tvalid_1's rmse: 21586.5\n",
      "[1500]\ttraining's rmse: 20317.9\tvalid_1's rmse: 21052.4\n",
      "[2000]\ttraining's rmse: 19836.2\tvalid_1's rmse: 20775.5\n",
      "[2500]\ttraining's rmse: 19466.5\tvalid_1's rmse: 20605\n",
      "[3000]\ttraining's rmse: 19148.1\tvalid_1's rmse: 20482.7\n",
      "[3500]\ttraining's rmse: 18865.2\tvalid_1's rmse: 20387.4\n",
      "[4000]\ttraining's rmse: 18619.2\tvalid_1's rmse: 20314.3\n",
      "[4500]\ttraining's rmse: 18396.9\tvalid_1's rmse: 20263.2\n",
      "[5000]\ttraining's rmse: 18179.8\tvalid_1's rmse: 20218.4\n",
      "[5500]\ttraining's rmse: 17983.8\tvalid_1's rmse: 20181.7\n",
      "[6000]\ttraining's rmse: 17798.7\tvalid_1's rmse: 20147.7\n",
      "[6500]\ttraining's rmse: 17622.3\tvalid_1's rmse: 20124.2\n",
      "[7000]\ttraining's rmse: 17450.6\tvalid_1's rmse: 20093.9\n",
      "[7500]\ttraining's rmse: 17284.2\tvalid_1's rmse: 20076.6\n",
      "[8000]\ttraining's rmse: 17123.8\tvalid_1's rmse: 20058.2\n",
      "[8500]\ttraining's rmse: 16965.5\tvalid_1's rmse: 20038.4\n",
      "[9000]\ttraining's rmse: 16812.2\tvalid_1's rmse: 20025.4\n",
      "[9500]\ttraining's rmse: 16666.2\tvalid_1's rmse: 20012.6\n",
      "[10000]\ttraining's rmse: 16514.7\tvalid_1's rmse: 20000.9\n",
      "[10500]\ttraining's rmse: 16368.1\tvalid_1's rmse: 19991.3\n",
      "[11000]\ttraining's rmse: 16222.6\tvalid_1's rmse: 19983.2\n",
      "[11500]\ttraining's rmse: 16081.3\tvalid_1's rmse: 19980.9\n",
      "[12000]\ttraining's rmse: 15945.7\tvalid_1's rmse: 19973.1\n",
      "[12500]\ttraining's rmse: 15809.9\tvalid_1's rmse: 19964\n",
      "[13000]\ttraining's rmse: 15675.6\tvalid_1's rmse: 19956.6\n",
      "[13500]\ttraining's rmse: 15538.7\tvalid_1's rmse: 19952.4\n",
      "[14000]\ttraining's rmse: 15408.5\tvalid_1's rmse: 19951.7\n",
      "[14500]\ttraining's rmse: 15283.9\tvalid_1's rmse: 19945.6\n",
      "[15000]\ttraining's rmse: 15154.2\tvalid_1's rmse: 19941.4\n",
      "[15500]\ttraining's rmse: 15028.2\tvalid_1's rmse: 19938.1\n",
      "[16000]\ttraining's rmse: 14905.2\tvalid_1's rmse: 19935.3\n",
      "[16500]\ttraining's rmse: 14785\tvalid_1's rmse: 19932.5\n",
      "[17000]\ttraining's rmse: 14659.6\tvalid_1's rmse: 19925.9\n",
      "Early stopping, best iteration is:\n",
      "[16981]\ttraining's rmse: 14664.5\tvalid_1's rmse: 19925.7\n",
      "OOF Score: 20151.728125954905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>te_Country__YearsCodingProf</td>\n",
       "      <td>1.660569e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>te_Country__Age</td>\n",
       "      <td>1.550587e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>te_Country__ohe_DevType_Student</td>\n",
       "      <td>1.343538e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>te_Country__Employment</td>\n",
       "      <td>1.152539e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>te_Country__SalaryType</td>\n",
       "      <td>1.119585e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te_SalaryType__CurrencySymbol</td>\n",
       "      <td>1.025642e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>te_YearsCodingProf__Currency</td>\n",
       "      <td>1.025031e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>te_Country__YearsCoding</td>\n",
       "      <td>9.210646e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>te_Country__FormalEducation</td>\n",
       "      <td>8.065189e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>te_YearsCodingProf__CurrencySymbol</td>\n",
       "      <td>7.495321e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>te_Country__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>7.074788e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>te_Country__ohe_Methodology_Agile</td>\n",
       "      <td>6.598958e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>te_Country__Dependents</td>\n",
       "      <td>5.604206e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>te_Country__CompanySize</td>\n",
       "      <td>4.995398e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>te_Currency__SalaryType</td>\n",
       "      <td>4.933285e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>te_YearsCoding__CurrencySymbol</td>\n",
       "      <td>4.605433e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>te_Country__ohe_CommunicationTools_Confluence</td>\n",
       "      <td>4.524147e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>te_Country__CareerSatisfaction</td>\n",
       "      <td>3.965976e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>te_CurrencySymbol__ohe_DevType_Student</td>\n",
       "      <td>3.769976e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>te_Country__ohe_EducationTypes_Contributed_to_...</td>\n",
       "      <td>3.690249e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>te_Employment__CurrencySymbol</td>\n",
       "      <td>3.376009e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>te_YearsCodingProf__ohe_LanguageWorkedWith_PHP</td>\n",
       "      <td>3.141563e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>te_Country__OperatingSystem</td>\n",
       "      <td>3.114241e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>te_YearsCodingProf__ohe_CommunicationTools_Con...</td>\n",
       "      <td>3.071560e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>te_Country__ohe_DevType_Engineering_manager</td>\n",
       "      <td>3.065103e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>te_CompanySize__YearsCodingProf</td>\n",
       "      <td>2.912644e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>te_YearsCodingProf__CareerSatisfaction</td>\n",
       "      <td>2.879450e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>te_YearsCodingProf__OperatingSystem</td>\n",
       "      <td>2.876237e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>te_Country__Currency</td>\n",
       "      <td>2.775366e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>te_Country__CurrencySymbol</td>\n",
       "      <td>2.661635e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>te_YearsCodingProf__MilitaryUS</td>\n",
       "      <td>2.581569e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>te_YearsCodingProf__SalaryType</td>\n",
       "      <td>2.570992e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>te_Country__MilitaryUS</td>\n",
       "      <td>2.540334e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>te_Currency__Age</td>\n",
       "      <td>2.389064e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>te_Currency__ohe_DevType_Student</td>\n",
       "      <td>2.193922e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>te_YearsCodingProf__ohe_RaceEthnicity_White_or...</td>\n",
       "      <td>2.157546e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>te_Country</td>\n",
       "      <td>2.030404e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>te_YearsCoding__Currency</td>\n",
       "      <td>1.984338e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>te_Country__ohe_RaceEthnicity_White_or_of_Euro...</td>\n",
       "      <td>1.808092e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>te_SalaryType__Age</td>\n",
       "      <td>1.648653e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>te_Employment__Currency</td>\n",
       "      <td>1.624609e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>te_Employment__SalaryType</td>\n",
       "      <td>1.595433e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>te_FormalEducation__YearsCodingProf</td>\n",
       "      <td>1.593386e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>te_YearsCoding__OperatingSystem</td>\n",
       "      <td>1.542171e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>te_YearsCodingProf__ohe_Methodology_Agile</td>\n",
       "      <td>1.540161e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>te_Employment__YearsCodingProf</td>\n",
       "      <td>1.529742e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>te_CurrencySymbol__Age</td>\n",
       "      <td>1.510214e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>te_YearsCodingProf__Age</td>\n",
       "      <td>1.415387e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>te_YearsCodingProf__ohe_DevType_Student</td>\n",
       "      <td>1.415361e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>agg_std_Country_ohe_Methodology_Agile</td>\n",
       "      <td>1.215135e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature          gain\n",
       "0                         te_Country__YearsCodingProf  1.660569e+09\n",
       "1                                     te_Country__Age  1.550587e+09\n",
       "2                     te_Country__ohe_DevType_Student  1.343538e+09\n",
       "3                              te_Country__Employment  1.152539e+09\n",
       "4                              te_Country__SalaryType  1.119585e+09\n",
       "5                       te_SalaryType__CurrencySymbol  1.025642e+09\n",
       "6                        te_YearsCodingProf__Currency  1.025031e+09\n",
       "7                             te_Country__YearsCoding  9.210646e+08\n",
       "8                         te_Country__FormalEducation  8.065189e+08\n",
       "9                  te_YearsCodingProf__CurrencySymbol  7.495321e+08\n",
       "10             te_Country__ohe_LanguageWorkedWith_PHP  7.074788e+08\n",
       "11                  te_Country__ohe_Methodology_Agile  6.598958e+08\n",
       "12                             te_Country__Dependents  5.604206e+08\n",
       "13                            te_Country__CompanySize  4.995398e+08\n",
       "14                            te_Currency__SalaryType  4.933285e+08\n",
       "15                     te_YearsCoding__CurrencySymbol  4.605433e+08\n",
       "16      te_Country__ohe_CommunicationTools_Confluence  4.524147e+08\n",
       "17                     te_Country__CareerSatisfaction  3.965976e+08\n",
       "18             te_CurrencySymbol__ohe_DevType_Student  3.769976e+08\n",
       "19  te_Country__ohe_EducationTypes_Contributed_to_...  3.690249e+08\n",
       "20                      te_Employment__CurrencySymbol  3.376009e+08\n",
       "21     te_YearsCodingProf__ohe_LanguageWorkedWith_PHP  3.141563e+08\n",
       "22                        te_Country__OperatingSystem  3.114241e+08\n",
       "23  te_YearsCodingProf__ohe_CommunicationTools_Con...  3.071560e+08\n",
       "24        te_Country__ohe_DevType_Engineering_manager  3.065103e+08\n",
       "25                    te_CompanySize__YearsCodingProf  2.912644e+08\n",
       "26             te_YearsCodingProf__CareerSatisfaction  2.879450e+08\n",
       "27                te_YearsCodingProf__OperatingSystem  2.876237e+08\n",
       "28                               te_Country__Currency  2.775366e+08\n",
       "29                         te_Country__CurrencySymbol  2.661635e+08\n",
       "30                     te_YearsCodingProf__MilitaryUS  2.581569e+08\n",
       "31                     te_YearsCodingProf__SalaryType  2.570992e+08\n",
       "32                             te_Country__MilitaryUS  2.540334e+08\n",
       "33                                   te_Currency__Age  2.389064e+08\n",
       "34                   te_Currency__ohe_DevType_Student  2.193922e+08\n",
       "35  te_YearsCodingProf__ohe_RaceEthnicity_White_or...  2.157546e+08\n",
       "36                                         te_Country  2.030404e+08\n",
       "37                           te_YearsCoding__Currency  1.984338e+08\n",
       "38  te_Country__ohe_RaceEthnicity_White_or_of_Euro...  1.808092e+08\n",
       "39                                 te_SalaryType__Age  1.648653e+08\n",
       "40                            te_Employment__Currency  1.624609e+08\n",
       "41                          te_Employment__SalaryType  1.595433e+08\n",
       "42                te_FormalEducation__YearsCodingProf  1.593386e+08\n",
       "43                    te_YearsCoding__OperatingSystem  1.542171e+08\n",
       "44          te_YearsCodingProf__ohe_Methodology_Agile  1.540161e+08\n",
       "45                     te_Employment__YearsCodingProf  1.529742e+08\n",
       "46                             te_CurrencySymbol__Age  1.510214e+08\n",
       "47                            te_YearsCodingProf__Age  1.415387e+08\n",
       "48            te_YearsCodingProf__ohe_DevType_Student  1.415361e+08\n",
       "49              agg_std_Country_ohe_Methodology_Agile  1.215135e+08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df, models, oof_score = train(train_df, test_df, use_cols, fold_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_df, models, use_cols, oof_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
