{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_columns\", 300)\n",
    "pd.set_option(\"max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_cache(reset=False):\n",
    "    def _feature_cache(func):\n",
    "        def wrapper(train_df, test_df, *args):\n",
    "            func_name = func.__name__\n",
    "            train_feat_path = Path(\"../feature\") / f\"train_{func_name}.pkl\"\n",
    "            test_feat_path = Path(\"../feature\") / f\"test_{func_name}.pkl\"\n",
    "            # if feature exists, load feature\n",
    "            if train_feat_path.exists() and test_feat_path.exists() and not reset:\n",
    "                train_feats = pd.read_pickle(train_feat_path).reset_index(drop=True)\n",
    "                test_feats = pd.read_pickle(test_feat_path).reset_index(drop=True)\n",
    "                train_df = pd.concat([train_df, train_feats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_feats], axis=1)\n",
    "            # if not exists, make feature and save as pickle\n",
    "            else:\n",
    "                before_cols = train_df.columns.tolist()\n",
    "                train_df, test_df = func(train_df, test_df, *args)\n",
    "                after_cols = train_df.columns.tolist()\n",
    "                new_cols = [c for c in after_cols if c not in before_cols]\n",
    "                train_feats = train_df[new_cols]\n",
    "                test_feats = test_df[new_cols]\n",
    "                train_feats.to_pickle(train_feat_path)\n",
    "                test_feats.to_pickle(test_feat_path)            \n",
    "            return train_df, test_df\n",
    "        return wrapper\n",
    "\n",
    "    return _feature_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_cat_cols(train_df):\n",
    "    tmp = train_df.iloc[:1000]\n",
    "    multi_cols = []\n",
    "    for c in train_df.columns:\n",
    "        sep_num = tmp[c].astype(str).fillna(\"\").str.contains(\";\").sum()\n",
    "        if sep_num > 10:\n",
    "            multi_cols.append(c)\n",
    "    return multi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_cols = train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cat_cols = get_multi_cat_cols(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nume_cols = [\n",
    "    c for c in list(np.setdiff1d(original_cols, multi_cat_cols))\n",
    "    if c not in [\"Salary\", \"No\"] and \"float\" in train_df[c].dtype.name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [c for c in train_df.columns if c not in multi_cat_cols + nume_cols + [\"Salary\", \"No\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_basic_nume_cols = []\n",
    "non_basic_cat_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 65, 40, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_cols), len(cat_cols), len(nume_cols), len(multi_cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rank_feature(df):\n",
    "    rank_prefix_list = [\n",
    "        \"AssessBenefits\",\n",
    "        \"AssessJob\",\n",
    "        \"JobContactPriorities\",\n",
    "        \"JobEmailPriorities\",\n",
    "        \"AdsPriorities\",\n",
    "    ]\n",
    "    for prefix in tqdm(rank_prefix_list):\n",
    "        rank_cols = [c for c in df.columns if prefix in c]\n",
    "        col_pairs = itertools.combinations(rank_cols, 2)\n",
    "        for col_a, col_b in col_pairs:\n",
    "            df[f\"rank_diff_{prefix}_{col_a}_{col_b}\"] = (df[col_a] - df[col_b]) / np.log2(df[[col_a, col_b]].max(axis=1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51800100a10a4b48b520b25b37673df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88910daab0b4105aa52145479ed6747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df = add_rank_feature(train_df)\n",
    "test_df = add_rank_feature(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-category encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f40975e3d604fde9e552c9ebab9128c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for c in tqdm(multi_cat_cols):\n",
    "    binarizer = MultiLabelBinarizer()\n",
    "    train_multi_srs = train_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "    test_multi_srs = test_df[c].map(lambda x: x.split(\";\") if x is not np.nan else [])\n",
    "    train_arr = binarizer.fit_transform(train_multi_srs)\n",
    "    test_arr = binarizer.transform(test_multi_srs)\n",
    "    feat_cols = [f\"ohe_{c}_{val}\" for val in binarizer.classes_]\n",
    "    train_feat_df = pd.DataFrame(train_arr, columns=feat_cols, dtype=np.int8)\n",
    "    test_feat_df = pd.DataFrame(test_arr, columns=feat_cols, dtype=np.int8)\n",
    "    all_feat_df = pd.concat([train_feat_df, test_feat_df], axis=0, ignore_index=True)\n",
    "    train_feat_df[f\"sum_answer_{c}\"] = (train_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "    test_feat_df[f\"sum_answer_{c}\"] = (test_df[c].str.count(\";\") + 1).fillna(-1).astype(np.int8)\n",
    "    train_df = pd.concat([train_df, train_feat_df], axis=1)\n",
    "    test_df = pd.concat([test_df, test_feat_df], axis=1)\n",
    "    # ohe_featureはcategoryとnumerical両方として扱う\n",
    "    nume_cols += feat_cols\n",
    "    cat_cols += feat_cols\n",
    "    # non_basic_nume_cols.append(f\"sum_answer_{c}\")\n",
    "    # SVD\n",
    "    svd = TruncatedSVD(n_components=2, random_state=2020)\n",
    "    all_svd_feats = pd.DataFrame(svd.fit_transform(all_feat_df), columns=[f\"svd_{c}_{ix}\" for ix in range(2)])\n",
    "    train_df = pd.concat([train_df, all_svd_feats.iloc[:len(train_df)]], axis=1)\n",
    "    test_df = pd.concat([test_df, all_svd_feats.iloc[len(train_df):].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple-category encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df[c], uniques = pd.factorize(train_df[c], sort=True)\n",
    "    test_df[c] = uniques.get_indexer(test_df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce data memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in nume_cols:\n",
    "    if train_df[c].nunique() > 1000:\n",
    "        train_df[c] = train_df[c].astype(np.float32)\n",
    "        test_df[c] = test_df[c].astype(np.float32)\n",
    "    else:\n",
    "        train_df[c] = train_df[c].astype(np.float16)\n",
    "        test_df[c] = test_df[c].astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    if train_df[c].max() > 32767:\n",
    "        train_df[c] = train_df[c].astype(np.int32)\n",
    "        test_df[c] = test_df[c].astype(np.int32)\n",
    "    else:\n",
    "        train_df[c] = train_df[c].astype(np.int16)\n",
    "        test_df[c] = test_df[c].astype(np.int16)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33857, 659), (11259, 658))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Category Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in train_df.columns]\n",
    "test_df.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in test_df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_importance_cols(use_num=50):\n",
    "    # basicなモデルのimportanceを読み込み\n",
    "    importance_df = pd.read_csv(\"../data/importance/003_importance.csv\")\n",
    "    imp_feats = importance_df[\"feature\"].iloc[:use_num].tolist()\n",
    "    return imp_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agg_feature(train_df, test_df):\n",
    "    imp_feats = get_basic_importance_cols(use_num=50)\n",
    "    imp_cat_cols = [c for c in cat_cols if c in imp_feats] + non_basic_cat_cols\n",
    "    imp_nume_cols = [c for c in nume_cols if c in imp_feats] + non_basic_nume_cols\n",
    "    print(f\"use cat col: {len(imp_cat_cols)}  nume col: {len(imp_nume_cols)}\")\n",
    "    #imp_nume_cols += [c for c in train_df.columns if c[:8] == \"sum_answ\"]\n",
    "    all_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "    for cat_col in tqdm(imp_cat_cols):\n",
    "        for nume_col in imp_nume_cols:\n",
    "            # one-hotは同じカテゴリの場合がある\n",
    "            if cat_col == nume_col:\n",
    "                continue\n",
    "            all_df[f\"agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"mean\").astype(np.float32)\n",
    "            all_df[f\"agg_std_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"std\").astype(np.float32)\n",
    "            all_df[f\"agg_max_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"max\").astype(np.float32)\n",
    "            all_df[f\"agg_min_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df.groupby(cat_col)[nume_col].transform(\"min\").astype(np.float32)\n",
    "            all_df[f\"diff_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df[nume_col] - all_df[f\"agg_mean_{cat_col}_{nume_col}\"]\n",
    "            all_df[f\"rel_agg_mean_{cat_col}_{nume_col}\"] = \\\n",
    "                all_df[nume_col] / (1 + all_df[f\"agg_mean_{cat_col}_{nume_col}\"])\n",
    "    train_df = all_df.iloc[:len(train_df)].reset_index(drop=True)\n",
    "    test_df = all_df.iloc[len(train_df):].reset_index(drop=True)\n",
    "    del all_df\n",
    "    gc.collect()\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cat col: 27  nume col: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d141cadc33174756a48f0e11e0f9761f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=27.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = make_agg_feature(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make fold index(for target encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "fold_idx_list = [(trn_idx, val_idx) for trn_idx, val_idx in folds.split(train_df, train_df[\"Salary\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@feature_cache(reset=False)\n",
    "def target_encoding(train_df, test_df):\n",
    "    te_cols = [c for c in train_df.columns if c in cat_cols]\n",
    "    for c in tqdm(te_cols):\n",
    "        new_col = \"te_\" + c\n",
    "        train_df[new_col] = 0\n",
    "        test_df[new_col] = 0\n",
    "        for trn_idx, val_idx in fold_idx_list:\n",
    "            mean_val = train_df.loc[trn_idx].groupby(c)[\"Salary\"].mean().astype(np.float32)\n",
    "            train_df.loc[val_idx, new_col] = train_df.loc[val_idx, c].map(mean_val)\n",
    "            test_df.loc[:, new_col] += test_df.loc[:, c].map(mean_val) / len(fold_idx_list)\n",
    "        train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "        test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = target_encoding(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@feature_cache(reset=True)\n",
    "def multiple_target_encoding(train_df, test_df):\n",
    "     # multiple target encoding\n",
    "    multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "    imp_feats = get_basic_importance_cols(use_num=30)\n",
    "    multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "    combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "    for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "        new_col = \"te_\" + col_a + \"__\" + col_b\n",
    "        train_df[new_col] = 0\n",
    "        test_df[new_col] = 0\n",
    "        train_df[\"tmp\"] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "        test_df[\"tmp\"] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "        for trn_idx, val_idx in fold_idx_list:\n",
    "            mean_val = train_df.loc[trn_idx].groupby(\"tmp\")[\"Salary\"].mean().astype(np.float32)\n",
    "            train_df.loc[val_idx, new_col] = train_df.loc[val_idx, \"tmp\"].map(mean_val)\n",
    "            test_df.loc[:, new_col] += test_df.loc[:, \"tmp\"].map(mean_val) / len(fold_idx_list)\n",
    "        train_df[new_col] = train_df[new_col].astype(np.float32)\n",
    "        test_df[new_col] = test_df[new_col].astype(np.float32)\n",
    "        del train_df[\"tmp\"], test_df[\"tmp\"]\n",
    "        gc.collect()\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@feature_cache(reset=True)\n",
    "def multiple_cat_encoding(train_df, test_df):\n",
    "     # multiple cat encoding\n",
    "    multi_te_cols = [c for c in train_df.columns if c in cat_cols or c[:4] == \"ohe_\"]\n",
    "    imp_feats = get_basic_importance_cols(use_num=30)\n",
    "    multi_te_cols = [c for c in multi_te_cols if c in imp_feats]\n",
    "    combi_multi_te_cols = list(itertools.combinations(multi_te_cols, 2))   \n",
    "\n",
    "    for col_a, col_b in tqdm(combi_multi_te_cols):\n",
    "        new_col = \"multi_cat_\" + col_a + \"__\" + col_b\n",
    "        train_df[new_col] = train_df[col_a].fillna(\"\").astype(str) + train_df[col_b].fillna(\"\").astype(str)\n",
    "        test_df[new_col] = test_df[col_a].fillna(\"\").astype(str) + test_df[col_b].fillna(\"\").astype(str)\n",
    "        cat_cols.append(new_col)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47f8a88d30d4b06941898595366f704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = multiple_cat_encoding(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2430\n"
     ]
    }
   ],
   "source": [
    "use_cols = [c for c in train_df.columns if c not in multi_cat_cols + [\"Salary\", \"No\"]]\n",
    "print(len(use_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "            'objective': 'poisson',\n",
    "            \"metric\": \"rmse\",\n",
    "            \"verbosity\": -1,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            'learning_rate': 0.05,\n",
    "            'num_leaves': 64,\n",
    "            'min_data_in_leaf': 80, \n",
    "            'max_depth': 4,\n",
    "            \"bagging_freq\": 5,\n",
    "            \"bagging_fraction\": 0.8,\n",
    "            \"lambda_l1\": 0.5,\n",
    "            \"lambda_l2\": 0.5,\n",
    "            \"feature_fraction\": 0.1,\n",
    "            \"seed\": 2020,\n",
    "            \"num_threads\": -1,\n",
    "            \"max_bins\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = {\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"task_type\": \"CPU\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"depth\": 6,\n",
    "    \"colsample_bylevel\": 0.8,\n",
    "    \"iterations\": 10000,\n",
    "    \"random_seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train_df, use_cols, n_features=1000):\n",
    "    df = train_df.sample(30000, random_state=2020)\n",
    "    train_dataset = lgb.Dataset(\n",
    "        df.loc[:, use_cols],\n",
    "        label = df.loc[:, \"Salary\"]\n",
    "    )\n",
    "    model = lgb.train(\n",
    "                lgb_params,\n",
    "                train_dataset,\n",
    "                2000,\n",
    "                valid_sets = [train_dataset],\n",
    "                verbose_eval=200,\n",
    "                early_stopping_rounds = None,\n",
    "    )\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = use_cols\n",
    "    imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "    select_features = imp_df.sort_values([\"gain\"], ascending=False).iloc[: n_features][\"feature\"].tolist()\n",
    "    return select_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "0:\tlearn: 41671.1511514\ttest: 41066.4073865\tbest: 41066.4073865 (0)\ttotal: 506ms\tremaining: 1h 24m 16s\n",
      "100:\tlearn: 20601.1315442\ttest: 21311.2904685\tbest: 21311.2904685 (100)\ttotal: 45.7s\tremaining: 1h 14m 36s\n",
      "200:\tlearn: 19319.7505599\ttest: 20865.0931211\tbest: 20865.0931211 (200)\ttotal: 1m 32s\tremaining: 1h 14m 58s\n",
      "300:\tlearn: 18564.3512618\ttest: 20692.0062656\tbest: 20692.0062656 (300)\ttotal: 2m 22s\tremaining: 1h 16m 34s\n",
      "400:\tlearn: 18013.0827392\ttest: 20628.7453003\tbest: 20628.7453003 (400)\ttotal: 3m 10s\tremaining: 1h 15m 52s\n",
      "500:\tlearn: 17473.8216589\ttest: 20571.9296605\tbest: 20571.9296605 (500)\ttotal: 3m 56s\tremaining: 1h 14m 46s\n",
      "600:\tlearn: 16995.0482253\ttest: 20532.8757976\tbest: 20532.8757976 (600)\ttotal: 4m 43s\tremaining: 1h 13m 58s\n",
      "700:\tlearn: 16511.7876243\ttest: 20518.1746307\tbest: 20507.7168733 (673)\ttotal: 5m 32s\tremaining: 1h 13m 30s\n",
      "800:\tlearn: 16093.3298080\ttest: 20486.7920163\tbest: 20486.7920163 (800)\ttotal: 6m 21s\tremaining: 1h 13m 6s\n",
      "900:\tlearn: 15737.3429686\ttest: 20500.2907301\tbest: 20486.2385157 (801)\ttotal: 7m 16s\tremaining: 1h 13m 23s\n",
      "1000:\tlearn: 15346.4139786\ttest: 20492.4219900\tbest: 20481.4891910 (978)\ttotal: 8m 4s\tremaining: 1h 12m 39s\n",
      "1100:\tlearn: 14999.9450130\ttest: 20470.4138871\tbest: 20466.3089256 (1075)\ttotal: 8m 53s\tremaining: 1h 11m 55s\n",
      "1200:\tlearn: 14655.3445337\ttest: 20449.2838798\tbest: 20448.1575079 (1194)\ttotal: 9m 41s\tremaining: 1h 10m 57s\n",
      "1300:\tlearn: 14351.0274694\ttest: 20446.1531536\tbest: 20442.8369582 (1282)\ttotal: 10m 29s\tremaining: 1h 10m 6s\n",
      "1400:\tlearn: 14037.5003310\ttest: 20435.9991763\tbest: 20435.9991763 (1400)\ttotal: 11m 16s\tremaining: 1h 9m 13s\n",
      "1500:\tlearn: 13736.2965723\ttest: 20436.4900305\tbest: 20426.3603722 (1434)\ttotal: 12m 5s\tremaining: 1h 8m 27s\n",
      "1600:\tlearn: 13433.8889646\ttest: 20433.1866832\tbest: 20426.3603722 (1434)\ttotal: 12m 54s\tremaining: 1h 7m 41s\n",
      "1700:\tlearn: 13139.6188111\ttest: 20429.7472947\tbest: 20426.3603722 (1434)\ttotal: 13m 44s\tremaining: 1h 7m 4s\n",
      "1800:\tlearn: 12844.4031699\ttest: 20442.2747034\tbest: 20426.3603722 (1434)\ttotal: 14m 34s\tremaining: 1h 6m 20s\n",
      "1900:\tlearn: 12552.4388487\ttest: 20454.4956922\tbest: 20426.3603722 (1434)\ttotal: 15m 24s\tremaining: 1h 5m 39s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 20426.36037\n",
      "bestIteration = 1434\n",
      "\n",
      "Shrink model to first 1435 iterations.\n",
      "Fold 2\n",
      "0:\tlearn: 41465.8364377\ttest: 41563.0441263\tbest: 41563.0441263 (0)\ttotal: 423ms\tremaining: 1h 10m 25s\n",
      "100:\tlearn: 20578.9251852\ttest: 21349.9191605\tbest: 21349.9191605 (100)\ttotal: 48.4s\tremaining: 1h 19m 4s\n",
      "200:\tlearn: 19382.1348651\ttest: 20857.6577624\tbest: 20857.6577624 (200)\ttotal: 1m 46s\tremaining: 1h 26m 43s\n",
      "300:\tlearn: 18612.3874238\ttest: 20660.7338103\tbest: 20660.7338103 (300)\ttotal: 2m 34s\tremaining: 1h 23m 7s\n",
      "400:\tlearn: 18020.9659629\ttest: 20559.2029965\tbest: 20558.1496494 (399)\ttotal: 3m 33s\tremaining: 1h 25m 1s\n",
      "500:\tlearn: 17442.8475555\ttest: 20482.5175455\tbest: 20481.1254843 (489)\ttotal: 4m 23s\tremaining: 1h 23m 14s\n",
      "600:\tlearn: 16963.1112983\ttest: 20430.2237289\tbest: 20430.2237289 (600)\ttotal: 5m 11s\tremaining: 1h 21m 5s\n",
      "700:\tlearn: 16500.0120152\ttest: 20399.8062543\tbest: 20398.3816755 (699)\ttotal: 5m 59s\tremaining: 1h 19m 22s\n",
      "800:\tlearn: 16116.9464496\ttest: 20388.6315745\tbest: 20387.7966353 (791)\ttotal: 6m 48s\tremaining: 1h 18m 7s\n",
      "900:\tlearn: 15722.2194619\ttest: 20340.8152801\tbest: 20340.8152801 (900)\ttotal: 7m 36s\tremaining: 1h 16m 52s\n",
      "1000:\tlearn: 15367.4915585\ttest: 20338.1069680\tbest: 20325.2341579 (974)\ttotal: 8m 25s\tremaining: 1h 15m 44s\n",
      "1100:\tlearn: 15000.5878610\ttest: 20312.7289613\tbest: 20309.8899013 (1080)\ttotal: 9m 14s\tremaining: 1h 14m 44s\n",
      "1200:\tlearn: 14626.6730031\ttest: 20298.2802356\tbest: 20296.8621212 (1199)\ttotal: 10m 3s\tremaining: 1h 13m 38s\n",
      "1300:\tlearn: 14325.5659334\ttest: 20288.3793666\tbest: 20287.1546498 (1266)\ttotal: 10m 52s\tremaining: 1h 12m 41s\n",
      "1400:\tlearn: 13996.6940945\ttest: 20281.4132769\tbest: 20276.4188984 (1388)\ttotal: 11m 40s\tremaining: 1h 11m 41s\n",
      "1500:\tlearn: 13702.4019490\ttest: 20284.5851584\tbest: 20276.4188984 (1388)\ttotal: 12m 29s\tremaining: 1h 10m 43s\n",
      "1600:\tlearn: 13423.2863661\ttest: 20277.4529818\tbest: 20275.4609719 (1539)\ttotal: 13m 17s\tremaining: 1h 9m 45s\n",
      "1700:\tlearn: 13147.4923388\ttest: 20275.8729590\tbest: 20273.2258683 (1621)\ttotal: 14m 6s\tremaining: 1h 8m 48s\n",
      "1800:\tlearn: 12873.5941318\ttest: 20272.3350257\tbest: 20269.7436497 (1783)\ttotal: 14m 56s\tremaining: 1h 8m\n",
      "1900:\tlearn: 12610.6338854\ttest: 20283.2475941\tbest: 20269.7436497 (1783)\ttotal: 15m 46s\tremaining: 1h 7m 11s\n",
      "2000:\tlearn: 12332.9697599\ttest: 20276.2107538\tbest: 20269.7436497 (1783)\ttotal: 16m 37s\tremaining: 1h 6m 26s\n",
      "2100:\tlearn: 12088.2818430\ttest: 20270.7761723\tbest: 20269.7436497 (1783)\ttotal: 17m 29s\tremaining: 1h 5m 46s\n",
      "2200:\tlearn: 11840.9406611\ttest: 20271.2577204\tbest: 20264.0783437 (2141)\ttotal: 18m 20s\tremaining: 1h 4m 58s\n",
      "2300:\tlearn: 11604.9984708\ttest: 20285.1980707\tbest: 20264.0783437 (2141)\ttotal: 19m 10s\tremaining: 1h 4m 9s\n",
      "2400:\tlearn: 11366.7260647\ttest: 20288.7867203\tbest: 20264.0783437 (2141)\ttotal: 20m\tremaining: 1h 3m 19s\n",
      "2500:\tlearn: 11132.5487965\ttest: 20297.5448928\tbest: 20264.0783437 (2141)\ttotal: 20m 49s\tremaining: 1h 2m 27s\n",
      "2600:\tlearn: 10905.0655469\ttest: 20295.5961591\tbest: 20264.0783437 (2141)\ttotal: 21m 40s\tremaining: 1h 1m 38s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 20264.07834\n",
      "bestIteration = 2141\n",
      "\n",
      "Shrink model to first 2142 iterations.\n",
      "Fold 3\n",
      "0:\tlearn: 41510.3879753\ttest: 41729.5508063\tbest: 41729.5508063 (0)\ttotal: 497ms\tremaining: 1h 22m 50s\n",
      "100:\tlearn: 20616.0411104\ttest: 21432.5492433\tbest: 21432.5492433 (100)\ttotal: 53.1s\tremaining: 1h 26m 45s\n",
      "200:\tlearn: 19502.3788358\ttest: 21037.6211131\tbest: 21037.6211131 (200)\ttotal: 1m 43s\tremaining: 1h 24m 8s\n",
      "300:\tlearn: 18714.2534207\ttest: 20858.0929452\tbest: 20856.0190073 (299)\ttotal: 2m 34s\tremaining: 1h 22m 45s\n",
      "400:\tlearn: 18088.2079500\ttest: 20781.0177003\tbest: 20781.0177003 (400)\ttotal: 3m 26s\tremaining: 1h 22m 13s\n",
      "500:\tlearn: 17498.6090610\ttest: 20707.2630054\tbest: 20706.6215572 (489)\ttotal: 4m 25s\tremaining: 1h 23m 52s\n",
      "600:\tlearn: 16986.9320466\ttest: 20654.3400318\tbest: 20654.3400318 (600)\ttotal: 5m 30s\tremaining: 1h 26m 12s\n",
      "700:\tlearn: 16542.7712834\ttest: 20613.8636944\tbest: 20607.2724473 (675)\ttotal: 6m 28s\tremaining: 1h 25m 52s\n",
      "800:\tlearn: 16127.3595275\ttest: 20575.3646119\tbest: 20574.9797871 (799)\ttotal: 7m 19s\tremaining: 1h 24m 9s\n",
      "900:\tlearn: 15731.1831818\ttest: 20544.4976846\tbest: 20543.1782327 (899)\ttotal: 8m 8s\tremaining: 1h 22m 14s\n",
      "1000:\tlearn: 15366.9998951\ttest: 20515.6925600\tbest: 20515.6925600 (1000)\ttotal: 8m 58s\tremaining: 1h 20m 40s\n",
      "1100:\tlearn: 15020.8394348\ttest: 20506.8599892\tbest: 20505.5162726 (1082)\ttotal: 9m 48s\tremaining: 1h 19m 16s\n",
      "1200:\tlearn: 14659.7150880\ttest: 20500.1142844\tbest: 20498.3101460 (1196)\ttotal: 10m 38s\tremaining: 1h 17m 56s\n",
      "1300:\tlearn: 14347.7524422\ttest: 20526.0756163\tbest: 20498.3101460 (1196)\ttotal: 11m 27s\tremaining: 1h 16m 35s\n",
      "1400:\tlearn: 14019.1023096\ttest: 20527.7243843\tbest: 20498.3101460 (1196)\ttotal: 12m 16s\tremaining: 1h 15m 22s\n",
      "1500:\tlearn: 13712.1434809\ttest: 20523.5463043\tbest: 20498.3101460 (1196)\ttotal: 13m 6s\tremaining: 1h 14m 12s\n",
      "1600:\tlearn: 13401.2220268\ttest: 20512.0483241\tbest: 20498.3101460 (1196)\ttotal: 13m 55s\tremaining: 1h 13m 3s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 20498.31015\n",
      "bestIteration = 1196\n",
      "\n",
      "Shrink model to first 1197 iterations.\n",
      "Fold 4\n",
      "0:\tlearn: 41464.1136662\ttest: 41471.6656450\tbest: 41471.6656450 (0)\ttotal: 467ms\tremaining: 1h 17m 46s\n",
      "100:\tlearn: 20681.4106731\ttest: 21339.2895152\tbest: 21339.2895152 (100)\ttotal: 47.8s\tremaining: 1h 18m 6s\n",
      "200:\tlearn: 19495.4423658\ttest: 20879.1747704\tbest: 20879.1747704 (200)\ttotal: 1m 38s\tremaining: 1h 19m 45s\n",
      "300:\tlearn: 18699.1454960\ttest: 20713.1773447\tbest: 20713.1773447 (300)\ttotal: 2m 28s\tremaining: 1h 19m 44s\n",
      "400:\tlearn: 18048.7331571\ttest: 20579.0881529\tbest: 20577.9482607 (399)\ttotal: 3m 26s\tremaining: 1h 22m 22s\n",
      "500:\tlearn: 17461.7310788\ttest: 20510.2008358\tbest: 20508.5770405 (493)\ttotal: 4m 18s\tremaining: 1h 21m 42s\n",
      "600:\tlearn: 16961.0045952\ttest: 20455.0783063\tbest: 20455.0783063 (600)\ttotal: 5m 7s\tremaining: 1h 20m 13s\n",
      "700:\tlearn: 16518.1098687\ttest: 20422.7788774\tbest: 20422.7763979 (699)\ttotal: 5m 55s\tremaining: 1h 18m 41s\n",
      "800:\tlearn: 16158.5872958\ttest: 20396.0850156\tbest: 20393.3886312 (794)\ttotal: 6m 46s\tremaining: 1h 17m 45s\n",
      "900:\tlearn: 15828.9726064\ttest: 20362.1687305\tbest: 20359.0445993 (882)\ttotal: 7m 38s\tremaining: 1h 17m 7s\n",
      "1000:\tlearn: 15453.3019194\ttest: 20341.4707938\tbest: 20338.3709790 (994)\ttotal: 8m 30s\tremaining: 1h 16m 25s\n",
      "1100:\tlearn: 15067.0464851\ttest: 20319.5796447\tbest: 20318.6403680 (1097)\ttotal: 9m 21s\tremaining: 1h 15m 41s\n",
      "1200:\tlearn: 14779.1360267\ttest: 20323.7582615\tbest: 20315.9733857 (1165)\ttotal: 10m 13s\tremaining: 1h 14m 54s\n",
      "1300:\tlearn: 14462.6625348\ttest: 20317.7262631\tbest: 20315.7272561 (1258)\ttotal: 11m 5s\tremaining: 1h 14m 9s\n",
      "1400:\tlearn: 14175.6742444\ttest: 20310.6417519\tbest: 20307.3786688 (1334)\ttotal: 12m\tremaining: 1h 13m 44s\n",
      "1500:\tlearn: 13881.3566887\ttest: 20308.4409226\tbest: 20302.5481050 (1453)\ttotal: 12m 57s\tremaining: 1h 13m 22s\n",
      "1600:\tlearn: 13561.3034023\ttest: 20303.5751690\tbest: 20299.8929022 (1560)\ttotal: 13m 54s\tremaining: 1h 12m 58s\n",
      "1700:\tlearn: 13276.9357555\ttest: 20289.8047854\tbest: 20288.2936424 (1685)\ttotal: 14m 51s\tremaining: 1h 12m 30s\n",
      "1800:\tlearn: 13001.2116757\ttest: 20273.0198938\tbest: 20266.8585024 (1787)\ttotal: 15m 48s\tremaining: 1h 11m 59s\n",
      "1900:\tlearn: 12722.7915046\ttest: 20280.5887846\tbest: 20266.8585024 (1787)\ttotal: 16m 46s\tremaining: 1h 11m 29s\n",
      "2000:\tlearn: 12468.3092233\ttest: 20274.5146071\tbest: 20266.8585024 (1787)\ttotal: 17m 45s\tremaining: 1h 10m 59s\n",
      "2100:\tlearn: 12220.5362188\ttest: 20273.7325867\tbest: 20266.8585024 (1787)\ttotal: 18m 37s\tremaining: 1h 10m 1s\n",
      "2200:\tlearn: 11976.2301979\ttest: 20252.2541974\tbest: 20250.8950807 (2187)\ttotal: 19m 28s\tremaining: 1h 9m\n",
      "2300:\tlearn: 11720.9296340\ttest: 20254.9192164\tbest: 20249.2401664 (2223)\ttotal: 20m 16s\tremaining: 1h 7m 51s\n",
      "2400:\tlearn: 11453.5019439\ttest: 20254.8064603\tbest: 20249.2401664 (2223)\ttotal: 21m 5s\tremaining: 1h 6m 44s\n",
      "2500:\tlearn: 11220.8484118\ttest: 20258.2273848\tbest: 20249.2401664 (2223)\ttotal: 21m 54s\tremaining: 1h 5m 42s\n",
      "2600:\tlearn: 10965.2494648\ttest: 20261.8819440\tbest: 20249.2401664 (2223)\ttotal: 22m 44s\tremaining: 1h 4m 42s\n",
      "2700:\tlearn: 10741.0718682\ttest: 20260.6180861\tbest: 20249.2401664 (2223)\ttotal: 23m 34s\tremaining: 1h 3m 43s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 20249.24017\n",
      "bestIteration = 2223\n",
      "\n",
      "Shrink model to first 2224 iterations.\n",
      "Fold 5\n",
      "0:\tlearn: 41451.8632347\ttest: 41631.6806187\tbest: 41631.6806187 (0)\ttotal: 418ms\tremaining: 1h 9m 41s\n",
      "100:\tlearn: 20687.2329627\ttest: 21032.3478518\tbest: 21032.3478518 (100)\ttotal: 1m 2s\tremaining: 1h 42m 48s\n",
      "200:\tlearn: 19384.1902397\ttest: 20526.6209025\tbest: 20526.6209025 (200)\ttotal: 2m 19s\tremaining: 1h 53m 8s\n",
      "300:\tlearn: 18618.2315836\ttest: 20383.6173384\tbest: 20383.6173384 (300)\ttotal: 3m 38s\tremaining: 1h 57m 20s\n",
      "400:\tlearn: 18070.2165576\ttest: 20322.1007603\tbest: 20322.1007603 (400)\ttotal: 4m 42s\tremaining: 1h 52m 37s\n",
      "500:\tlearn: 17496.9551337\ttest: 20263.8890023\tbest: 20263.8890023 (500)\ttotal: 5m 30s\tremaining: 1h 44m 30s\n",
      "600:\tlearn: 17003.1391174\ttest: 20221.3865484\tbest: 20213.1763290 (588)\ttotal: 6m 19s\tremaining: 1h 38m 58s\n",
      "700:\tlearn: 16572.6582197\ttest: 20201.7793434\tbest: 20195.6811790 (688)\ttotal: 7m 9s\tremaining: 1h 35m 2s\n",
      "800:\tlearn: 16131.5298433\ttest: 20175.5046956\tbest: 20170.4148105 (784)\ttotal: 7m 59s\tremaining: 1h 31m 51s\n",
      "900:\tlearn: 15781.9264531\ttest: 20171.5011295\tbest: 20167.9994166 (857)\ttotal: 8m 47s\tremaining: 1h 28m 51s\n",
      "1000:\tlearn: 15455.0085756\ttest: 20159.7547327\tbest: 20149.4584772 (986)\ttotal: 9m 37s\tremaining: 1h 26m 29s\n",
      "1100:\tlearn: 15086.1473536\ttest: 20147.9743729\tbest: 20142.5152497 (1091)\ttotal: 10m 24s\tremaining: 1h 24m 4s\n",
      "1200:\tlearn: 14740.7467924\ttest: 20149.0556525\tbest: 20142.5152497 (1091)\ttotal: 11m 12s\tremaining: 1h 22m 7s\n",
      "1300:\tlearn: 14387.2505208\ttest: 20144.8599002\tbest: 20142.5152497 (1091)\ttotal: 12m 2s\tremaining: 1h 20m 29s\n",
      "1400:\tlearn: 14080.8073161\ttest: 20143.4619729\tbest: 20140.7644365 (1391)\ttotal: 12m 52s\tremaining: 1h 19m 1s\n",
      "1500:\tlearn: 13815.1110890\ttest: 20156.1824973\tbest: 20140.7644365 (1391)\ttotal: 13m 43s\tremaining: 1h 17m 42s\n",
      "1600:\tlearn: 13524.5801453\ttest: 20153.3837574\tbest: 20140.7644365 (1391)\ttotal: 14m 34s\tremaining: 1h 16m 27s\n",
      "1700:\tlearn: 13238.4000868\ttest: 20160.8004281\tbest: 20140.7644365 (1391)\ttotal: 15m 26s\tremaining: 1h 15m 18s\n",
      "1800:\tlearn: 12967.6642200\ttest: 20150.3566203\tbest: 20140.7644365 (1391)\ttotal: 16m 20s\tremaining: 1h 14m 21s\n",
      "Stopped by overfitting detector  (500 iterations wait)\n",
      "\n",
      "bestTest = 20140.76444\n",
      "bestIteration = 1391\n",
      "\n",
      "Shrink model to first 1392 iterations.\n"
     ]
    }
   ],
   "source": [
    "importances = pd.DataFrame()\n",
    "oof_preds = np.zeros(len(train_df))\n",
    "models = []\n",
    "\n",
    "cat_cols = [c for c in cat_cols if c in train_df.columns]\n",
    "\n",
    "# use_cols = feature_selection(train_df, use_cols, n_features=1000)\n",
    "\n",
    "for fold_i, (trn_idx, val_idx) in enumerate(fold_idx_list):\n",
    "    print(f\"Fold {fold_i+1}\")\n",
    "    \"\"\"\n",
    "    train_dataset = lgb.Dataset(\n",
    "        train_df.loc[trn_idx, use_cols],\n",
    "        label = train_df.loc[trn_idx, \"Salary\"]\n",
    "    )\n",
    "    valid_dataset = lgb.Dataset(\n",
    "        train_df.loc[val_idx, use_cols],\n",
    "        label = train_df.loc[val_idx, \"Salary\"]\n",
    "    )\n",
    "    model = lgb.train(\n",
    "                lgb_params,\n",
    "                train_dataset,\n",
    "                10000,\n",
    "                valid_sets = [train_dataset, valid_dataset],\n",
    "                verbose_eval=100,\n",
    "                early_stopping_rounds = 300,\n",
    "                #feval = eval_f1,\n",
    "                #callbacks = [log_callback],\n",
    "    )\n",
    "    imp_df = pd.DataFrame()\n",
    "    imp_df['feature'] = use_cols\n",
    "    imp_df['gain'] = model.feature_importance(importance_type=\"gain\")\n",
    "    importances = pd.concat([importances, imp_df], axis=0, sort=False)\n",
    "    \n",
    "    oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])\n",
    "    \"\"\"\n",
    "    model = CatBoostRegressor(**catboost_params)\n",
    "    model.fit(\n",
    "            train_df.loc[trn_idx, use_cols],\n",
    "            train_df.loc[trn_idx, \"Salary\"],\n",
    "            cat_features=cat_cols,\n",
    "            eval_set=(train_df.loc[val_idx, use_cols], train_df.loc[val_idx, \"Salary\"]),\n",
    "            early_stopping_rounds=500,\n",
    "            verbose=100,\n",
    "            use_best_model=True\n",
    "    )\n",
    "    \n",
    "    models.append(model)\n",
    "    oof_preds[val_idx] = model.predict(train_df.loc[val_idx, use_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20314.852723215634"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_score = np.sqrt(mean_squared_error(train_df[\"Salary\"], oof_preds))\n",
    "oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2d13fd4a0bc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gain\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6502\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6504\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   6505\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6506\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.2/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feature'"
     ]
    }
   ],
   "source": [
    "importances.groupby(\"feature\")[\"gain\"].mean().sort_values(ascending=False).reset_index().iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2430"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(use_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.zeros(len(test_df))\n",
    "\n",
    "for model in models:\n",
    "    test_pred += model.predict(test_df[use_cols]) / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 67890.20160401,  91554.22959848,  88610.23518969, ...,\n",
       "        91560.44032754,  79679.88518819, 113623.13125534])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv(\"../input/submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[\"Salary\"] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"../predict/025_catboost_20314.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('3.8.2': pyenv)",
   "language": "python",
   "name": "python38264bit382pyenv0bf26b16ab884472b54c5411cc1e5c03"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
